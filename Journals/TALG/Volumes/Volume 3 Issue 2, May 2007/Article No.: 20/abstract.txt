Given a sequenceS&equals;s1s2…snof integers smaller thanr&equals;O(polylog(n)), we show howScan be represented usingnH0(S) &plus;o(n) bits, so that we can know anysq, as well as answerrankandselectqueries onS, in constant time.H0(S) is the zero-order empirical entropy ofSandnH0(S) provides an information-theoretic lower bound to the bit storage of any sequenceSvia a fixed encoding of its symbols. This extends previous results on binary sequences, and improves previous results on general sequences where those queries are answered inO(logr) time. For largerr, we can still representSinnH0(S) &plus;o(nlogr) bits and answer queries inO(logr/log logn) time.Another contribution of this article is to show how to combine our compressed representation of integer sequences with a compression boosting technique to designcompressed full-text indexesthat scale well with the size of the input alphabet Σ. Specifically, we design a variant of the FM-index that indexes a stringT[1,n] withinnHk(T) &plus;o(n) bits of storage, whereHk(T) is thekth-order empirical entropy ofT. This space bound holds simultaneously for allk≤ α log&verbar;Σ&verbar;n, constant 0 < α < 1, and &verbar;Σ&verbar; &equals;O(polylog(n)). This index counts the occurrences of an arbitrary patternP[1,p] as a substring ofTinO(p) time; it locates each pattern occurrence inO(log1&plus;&epsiv;n) time for any constant 0 < &epsiv; < 1; and reports a text substring of length &ell; inO(&ell; &plus; log1&plus;&epsiv;n) time.Compared to all previous works, our index is the first that removes the alphabet-size dependance from all query times, in particular, counting time is linear in the pattern length. Still, our index uses essentially the same space of thekth-order entropy of the textT, which is the best space obtained in previous work. We can also handle larger alphabets of size &verbar;Σ&verbar; &equals;O(nβ), for any 0 < β < 1, by payingo(nlog&verbar;Σ&verbar;) extra space and multiplying all query times byO(log &verbar;Σ&verbar;/log logn).