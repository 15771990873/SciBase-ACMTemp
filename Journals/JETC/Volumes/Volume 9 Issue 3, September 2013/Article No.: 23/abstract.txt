For sub-65nm technology nodes, Negative Bias Temperature Instability (NBTI) has become a primary limiting factor of circuit lifetime. During the past few years, researchers have spent considerable effort on accurate modeling and characterization of circuit delay degradation caused by NBTI at different design levels. The search for techniques and methodologies which can aid in effectively minimizing the NBTI effect on circuit delay is still underway. In this work, we present the usage of node criticality computation to drive NBTI-aware timing analysis and optimization. Circuits that have undergone this optimization flow show strong resistance to NBTI delay degradation. For the first time, this work proposes a node criticality computation algorithm under an NBTI-aware timing analysis and optimization framework. Our work provides answers to the following yet unaddressed questions: (a) what is the definition of node criticality in a circuit under the NBTI effect&quest; (b) how do we identify the critical nodes that, once protected, will be immune to NBTI timing degradation&quest; and (c) what are the NBTI effect attenuation approaches&quest; Experimental results indicate that by protecting the critical nodes found by our proposed methodology, circuit delay degradation can be reduced by up to 50&percnt;. Combined with peak temperature reduction, the delay degradation can be be further improved.