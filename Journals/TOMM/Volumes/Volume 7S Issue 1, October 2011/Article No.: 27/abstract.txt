Photos are a special way to tell stories of our best memories and moments. The representation of those photos in appealing physical photo books is highly appreciated by many people. Today, many photos are shared via social networking sites, where people upload their photos and share their stories with their friends. The members of social networks comment on each other's photos, add tags or descriptions and upload new photos of the same events to their albums. While the media of different personal events are available on the social network, there is no easy way to collect and bundle them into a story and print this story as a photo book. We propose an approach to automatically detect media elements that match a query (where, when, what, who) in the user's social network and intelligently arrange and compose them into a printable photo book. We combine content analysis of text and images to automatically and semi-automatically select photos of a specific story. We calculate the probabilities of each two photos to belong to the same event using an Expectation-Maximization algorithm that we propose in order to be able to retrieve them easily when receiving the user queries, and we address the differences between our model and other models that use similar proposed algorithms. People's tags and the interaction between the users and the photos as well as other semantic information are exploited to select important photos that are suitable to create the photo book. The selected photos and derived semantics are then employed to automatically create an appealing layout for the photo book.