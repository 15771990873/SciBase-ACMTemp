Augmented reality (AR) aims to render the world that users see and overlay information that reflects the real physical dynamics. The digital view could be potentially projected near the Point-of-Interest (POI) in a way that makes the virtual view attached to the POI even when the camera moves. Achieving smooth support for movements is a subject of extensive studies. One of the key problems is where the augmented information should be added to the field of vision in real time. Existing solutions either leverage GPS location for rendering outdoor AR views (hundreds of kilometers away) or rely on image markers for small-scale presentation (only for the marker region). To realize AR applications under various scales and dynamics, we propose a suite of algorithms for fine-grained AR view tracking to improve the accuracy of attitude and displacement estimation, reduce the drift, eliminate the marker, and lower the computation cost. Instead of requiring extremely high, accurate, absolute locations, we propose multimodal solutions according to mobility levels without additional hardware requirement. Experimental results demonstrate significantly less error in projecting and tracking the AR view. These results are expected to make users excited to explore their surroundings with enriched content.