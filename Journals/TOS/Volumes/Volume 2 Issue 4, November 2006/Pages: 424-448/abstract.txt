Minimizing the amount of data that must be stored and managed is a key goal for any storage architecture that purports to be scalable. One way to achieve this goal is to avoid maintaining duplicate copies of the same data. Eliminating redundant data at the source by not writing data which has already been stored not only reduces storage overheads, but can also improve bandwidth utilization. For these reasons, in the face of today's exponentially growing data volumes, redundant data elimination techniques have assumed critical significance in the design of modern storage systems.Intelligent object partitioning techniques identify data that isnewwhen objects are updated, and transfer only these chunks to a storage server. In this article, we propose a new object partitioning technique, calledfingerdiff, that improves upon existing schemes in several important respects. Most notably,fingerdiffdynamically chooses a partitioning strategy for a data object based on its similarities with previously stored objects in order to improve storage and bandwidth utilization. We present a detailed evaluation offingerdiff, and other existing object partitioning schemes, using a set of real-world workloads. We show that for these workloads, the duplicate elimination strategies employed byfingerdiffimprove storage utilization on average by 25&percnt;, and bandwidth utilization on average by 40&percnt; over comparable techniques.