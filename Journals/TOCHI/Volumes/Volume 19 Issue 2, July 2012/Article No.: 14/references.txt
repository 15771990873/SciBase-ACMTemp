Absar, R. and Guastavino, C.2008. Usability of non-speech sounds in user interfaces. InProceedings of the International Conference on Auditory Display (ICAD’08).
Tue Haste Andersen , Shumin Zhai, “Writing with music”: Exploring the use of auditory feedback in gesture interfaces, ACM Transactions on Applied Perception (TAP), v.7 n.3, p.1-24, June 2010[doi>10.1145/1773965.1773968]
Barry Arons, SpeechSkimmer: a system for interactively skimming recorded speech, ACM Transactions on Computer-Human Interaction (TOCHI), v.4 n.1, p.3-38, March 1997[doi>10.1145/244754.244758]
D. Beck , J. Elkerton, Development and evaluation of direct manipulation lists (poster session), ACM SIGCHI Bulletin, v.20 n.3, p.72-78, Jan. 1989[doi>10.1145/67900.67913]
Meera M. Blattner , Denise A. Sumikawa , Robert M. Greenberg, Earcons and icons: their structure and common design principles, Human-Computer Interaction, v.4 n.1, p.11-44, March 1989[doi>10.1207/s15327051hci0401_1]
Mark A. Blythe , Kees Overbeeke , Andrew F. Monk , Peter C. Wright, Funology: from usability to enjoyment, Kluwer Academic Publishers, Norwell, MA, 2005
Brewster, S. A.1997. Using non-speech sound to overcome information overload.Displays. 17, 179--189.
Stephen Brewster, Overcoming the Lack of Screen Space on Mobile Computers, Personal and Ubiquitous Computing, v.6 n.3, p.188-205, May 2002[doi>10.1007/s007790200019]
Brewster, S. A. 2008. Chapter13: Nonspeech auditory output. InThe Human Computer Interaction Handbook, A. Sears and J. Jacko Eds., Lawrence Erlbaum Associates, New York, 247--264.
Stephen A Brewster , Peter G Cryer, Maximising screen-space on mobile computing devices, CHI '99 Extended Abstracts on Human Factors in Computing Systems, May 15-20, 1999, Pittsburgh, Pennsylvania[doi>10.1145/632716.632855]
Brewster, S. A., Wright, P. C., and Edwards, A. D. N.1992. A detailed investigation into the effectiveness of earcons. InProceedings of the 1st International Conference on Auditory Display (ICAD’94). 471--478.
Stephen A. Brewster , Veli-Pekka Räty , Atte Kortekangas, Earcons as a Method of Providing Navigational Cues in a Menu Hierarchy, Proceedings of HCI on People and Computers XI, p.169-183, January 1996
Brewster, S. A., Leplâtre, G., and Crease, M. G.1998. Using non-speech sounds in mobile computing devices. InProceedings of the 1st Workshop on Human Computer Interaction with Mobile Devices.
Stephen Brewster , Joanna Lumsden , Marek Bell , Malcolm Hall , Stuart Tasker, Multimodal 'eyes-free' interaction techniques for wearable devices, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2003, Ft. Lauderdale, Florida, USA[doi>10.1145/642611.642694]
Broadbent, D. E.1977. The hidden preattentive processes.Amer. Psych. 32, 2, 109--118.
Davison, B. D. and Walker, B. N.2008. AudioPlusWidgets: Bringing sound to software widgets and interface components. InProceedings of the International Conference on Auditory Display (ICAD’08).
Dingler, T., Lindsay, J., and Walker, B. N. 2008. Learnability of sound cues for environmental features: Auditory icons, earcons, spearcons, and speech. InProceedings of the International Conference on Auditory Display (ICAD’08).
Alistair D. N. Edwards, Soundtrack: an auditory interface for blind users, Human-Computer Interaction, v.4 n.1, p.45-66, March 1989[doi>10.1207/s15327051hci0401_2]
Edworthy, J.1998. Does sound help us to work better with machines? A commentary on Rauterberg’s paper ‘About the importance of auditory alarms during the operation of a plant simulator’.Interact. Comput. 10, 401--409.
Fisk, A. D. and Kirlik, A.1996. Practical relevance and age-related research: Can theory advance without practice? InAging and Skilled Performance: Advances in Theory and Application, W. A. Rogers, A. D. Fisk, and N. Walker Eds., Erlbaum, NJ, 1--15.
William W. Gaver, Auditory icons: using sound in computer interfaces, Human-Computer Interaction, v.2 n.2, p.167-177, June 1986[doi>10.1207/s15327051hci0202_3]
William W. Gaver, The SonicFinder: an interface that uses auditory icons, Human-Computer Interaction, v.4 n.1, p.67-94, March 1989[doi>10.1207/s15327051hci0401_3]
Stuart Goose , Carsten Möller, A 3D audio only interactive Web browser: using spatialization to convey hypermedia document structure, Proceedings of the seventh ACM international conference on Multimedia (Part 1), p.363-371, October 30-November 05, 1999, Orlando, Florida, USA[doi>10.1145/319463.319649]
Hart, S. G.2006. NASA-Task Load Index (NASA-TLX); 20 years later. InProceedings of the Human Factors and Ergonomics Society 50th Annual Meeting (HFES’06).
Helle, S., Leplâtre, G., Marila, J., and Laine, P.2001. Menu sonification in a mobile phone: A prototype study. InProceedings of the International Conference on Auditory Display (ICAD’01).
Myounghoon Jeon , Bruce N. Walker, Spindex (Speech Index) Improves Auditory Menu Acceptance and Navigation Performance, ACM Transactions on Accessible Computing (TACCESS), v.3 n.3, p.1-26, April 2011[doi>10.1145/1952383.1952385]
Myoung Hoon Jeon , Dae Yol Na , Jung Hee Ahn , Ji Young Hong, User segmentation & UI optimization through mobile phone log analysis, Proceedings of the 10th international conference on Human computer interaction with mobile devices and services, September 02-05, 2008, Amsterdam, The Netherlands[doi>10.1145/1409240.1409326]
Myounghoon Jeon , Benjamin K. Davison , Michael A. Nees , Jeff Wilson , Bruce N. Walker, Enhanced auditory menu cues improve dual task performance and are preferred with in-vehicle technologies, Proceedings of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications, September 21-22, 2009, Essen, Germany[doi>10.1145/1620509.1620528]
Shaun K. Kane , Jeffrey P. Bigham , Jacob O. Wobbrock, Slide rule: making mobile touch screens accessible to blind people using multi-touch interaction techniques, Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility, October 13-15, 2008, Halifax, Nova Scotia, Canada[doi>10.1145/1414471.1414487]
Klante, P.2004. Auditory interaction objects for mobile applications. InProceedings of the 7th International Conference on Work with Computing Systems (WWCS’04).
Kramer, G.1994. An introduction to auditory display. InAuditory Display: Sonification, Audification, and Auditory Interfaces, G. Kramer Ed., Addison-Wesley, 1--77.
Lee, J. and Spence, C.2008a. Feeling what you hear: Task-irrelevant sounds modulate tactile perception delivered via a touch screen.J. Multimodal User Interfaces 2, 3--4, 1783--7677.
Ju-Hwan Lee , Charles Spence, Spatiotemporal Visuotactile Interaction, Proceedings of the 6th international conference on Haptics: Perception, Devices and Scenarios, June 10-13, 2008, Madrid, Spain[doi>10.1007/978-3-540-69057-3_104]
Leplâtre, G. and Brewster, S. A.2000. Designing non-speech sounds to support navigation in mobile phone menus. InProceedings of the International Conference on Auditory Display (ICAD’00). 190--199.
Leplâtre, G. and McGregor, I.2004. How to tackle auditory interface aesthetics? Discussion and case study. InProceedings of the International Conference on Auditory Display (ICAD’04).
Kevin A. Li , Patrick Baudisch , Ken Hinckley, Blindsight: eyes-free access to mobile phones, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2008, Florence, Italy[doi>10.1145/1357054.1357273]
Marila, J.2002. Experimental comparison of complex and simple sounds in menu and hierarchy sonification. InProceedings of the International Conference on Auditory Display (ICAD’00).
Sarah Morley , Helen Petrie , Anne-Marie O'Neill , Peter McNally, Auditory navigation in hyperspace: design and evaluation of a non-visual hypermedia system for blind users, Proceedings of the third international ACM conference on Assistive technologies, p.100-107, April 15-17, 1998, Marina del Rey, California, USA[doi>10.1145/274497.274516]
Elizabeth D. Mynatt, Transforming graphical interfaces into auditory interfaces for blind users, Human-Computer Interaction, v.12 n.1, p.7-45, March 1997[doi>10.1207/s15327051hci1201&2_2]
Elizabeth D. Mynatt , Gerhard Weber, Nonvisual presentation of graphical user interfaces: contrasting two approaches, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.166-172, April 24-28, 1994, Boston, Massachusetts, USA[doi>10.1145/191666.191732]
Nees, M. A. and Walker, B. N.2009. Auditory interfaces and sonification. InThe Universal Access Handbook, C. Stephanidis Ed., CRC Press Taylor & Francis, 507--521.
Norman, D. A.2004.Emotional Design. Basic Books, New York.
Norman, D. A.2007.The Design of Future Things. Basic Books, New York.
Donald A. Norman , Jakob Nielsen, Gestural interfaces: a step backward in usability, interactions, v.17 n.5, September + October 2010[doi>10.1145/1836216.1836228]
Kent L. Norman , Ben Shneiderman, The Psychology of Menu Selection: Designing Cognitive Control at the Human/Computer Interface, Greenwood Publishing Group Inc., Westport, CT, 1991
Oh, J. W., Park, J. H., Jo, J. H., Lee, C., and Yun, M. H.2007. Development of a kansei analysis system on the physical user interface. InProceedings of the Korean Conference on Human Computer Interaction.
Palladino, D. K. and Walker, B. N.2007. Learning rates for auditory menus enhanced with spearcons versus earcons. InProceedings of the International Conference on Auditory Display (ICAD’07). 274--279.
Palladino, D. K. and Walker, B. N.2008a. Efficiency of spearcon-enhanced navigation of one dimensional electronic menus. InProceedings of the International Conference on Auditory Display (ICAD’08).
Palladino, D. K. and Walker, B. N.2008b. Navigation efficiency of two dimensional auditory menus using spearcon enhancements. InProceedings of the Annual Meeting of the Human Factors and Ergonomics Society (HFES’08). 1262--1266.
Antti Pirhonen , Stephen Brewster , Christopher Holguin, Gestural and audio metaphors as a means of control for mobile devices, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 20-25, 2002, Minneapolis, Minnesota, USA[doi>10.1145/503376.503428]
Matthew J. Pitts , Mark A. Williams , Tom Wellings , Alex Attridge, Assessing subjective response to haptic feedback in automotive touchscreens, Proceedings of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications, September 21-22, 2009, Essen, Germany[doi>10.1145/1620509.1620512]
T. V. Raman, Auditory User Interfaces: Toward the Speaking Computer, Kluwer Academic Publishers, Norwell, MA, 1997
Russell, D. C. and Bryan, R.2009. To touch or not to touch: A brief guide for designing or selecting touch screen computers and touch software for consumer use. InProceedings of the Human Factors and Ergonomics Society 53rd Annual Meeting (HFES’09). 980--984.
Sanders, M. S. and McCormick, E. J.1993. Chapter 11: Controls and data entry devices. InHuman Factors in Engineering and Design, M. S. Sanders and E. J. McCormick Eds., McGraw-Hill, Inc, New York, 334--382.
Nitin Sawhney , Chris Schmandt, Nomadic radio: speech and audio interaction for contextual messaging in nomadic environments, ACM Transactions on Computer-Human Interaction (TOCHI), v.7 n.3, p.353-383, Sept. 2000[doi>10.1145/355324.355327]
Treisman, A. M. and Gelade, G.1980. A feature-integration theory of attention.Cogn. Psych. 12, 97--136.
Treisman, A. M. and Gormican, S.1988. Feature analysis in early vision: Evidence from search asymmetries,Psych. Rev. 95, 1, 15--48.
Vargas, M. L. M. and Anderson, S.2003. Combining speech and earcons to assist menu navigation. InProceedings of the International Conference on Auditory Display (ICAD’03).
Bruce N. Walker , Anya Kogan, Spearcon Performance and Preference for Auditory Menus on a Mobile Phone, Proceedings of the 5th International on ConferenceUniversal Access in Human-Computer Interaction. Part II: Intelligent and Ubiquitous Interaction Environments, July 19-24, 2009, San Diego, CA[doi>10.1007/978-3-642-02710-9_49]
Walker, B. N. and Kramer, G.2004. Ecological psychoacoustics and auditory displays: Hearing, grouping, and meaning making. InEcological Psychoacoustics, J. G. Neuhoff Ed., Academic Press, New York, 150--175.
Walker, B. N. and Kramer, G. 2006. Auditory displays, alarms, and auditory interfaces. InInternational Encyclopedia of Ergonomics and Human Factors2nd Ed., W. Karwowski Ed., CRC Press, New York, 1021--1025.
Walker, B. N., and Nees, M. A.2012. Theory of sonification. InHandbook of Sonification. T. Hermann, A. Hunt, and J. Neuhoff Eds., Academic Press: New York, 9--39.
Walker, B. N., Nance, A., and Lindsay, J.2006. Spearcons: Speech-based earcons improve navigation performance in auditory menus. InProceedings of the International Conference on Auditory Display (ICAD’06).95--98.
Walker, B. N., Lindsay, J., Nance, A., Nakano, Y., Palladino, D. K., Dingler, T., and Jeon, M.in press. Spearcons (Speech-based earcons) improve navigation performance in advanced auditory menus.Human Factors.
Jeff Wilson , Bruce N. Walker , Jeffrey Lindsay , Craig Cambias , Frank Dellaert, SWAN: System for Wearable Audio Navigation, Proceedings of the 2007 11th IEEE International Symposium on Wearable Computers, p.1-8, October 11-13, 2007[doi>10.1109/ISWC.2007.4373786]
Pavani Yalla , Bruce N. Walker, Advanced auditory menus: design and evaluation of auditory scroll bars, Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility, October 13-15, 2008, Halifax, Nova Scotia, Canada[doi>10.1145/1414471.1414492]
Shengdong Zhao , Pierre Dragicevic , Mark Chignell , Ravin Balakrishnan , Patrick Baudisch, Earpod: eyes-free menu selection using touch input and reactive audio feedback, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 28-May 03, 2007, San Jose, California, USA[doi>10.1145/1240624.1240836]
