Androutsopoulos, I., Koutsias, J., Chandrinos, K., Paliouras, G., and Spyropoulos, C. 2000a. An evaluation of naive Bayesian anti-spam filtering. In Proceedings of the Workshop on Machine Learning in the New Information Age, 11th European Conference on Machine Learning (ECML 2000), G. Potamias, V. Moustakis, and M. van Someren, Eds. Barcelona, Spain, 9--17.
Ion Androutsopoulos , John Koutsias , Konstantinos V. Chandrinos , Constantine D. Spyropoulos, An experimental comparison of naive Bayesian and keyword-based anti-spam filtering with personal e-mail messages, Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, p.160-167, July 24-28, 2000, Athens, Greece[doi>10.1145/345508.345569]
Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Sakkis, G., Spyropoulos, C., and Stamatopoulos, P. 2000c. Learning to filter spam e-mail: A comparison of a naive Bayesian and a memory-based approach. In Proceedings of the Workshop on Machine Learning and Textual Information Access, 4th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2000) (Lyon, France), H. Zaragoza, P. Gallinari, and M. Rajman, Eds. 1--13.
Adam L. Berger , Vincent J. Della Pietra , Stephen A. Della Pietra, A maximum entropy approach to natural language processing, Computational Linguistics, v.22 n.1, p.39-71, March 1996
Xavier Carreras , Lluís Màrquez, Boosting trees for clause splitting, Proceedings of the 2001 workshop on Computational Natural Language Learning, p.1-3, July 06-07, 2001, Toulouse, France[doi>10.3115/1117822.1117839]
Cohen, W. 1996. Learning rules that classify e-mail. In Spring Symposium on Machine Learning in Information Access (Stanford, CA).
Corinna Cortes , Vladimir Vapnik, Support-Vector Networks, Machine Learning, v.20 n.3, p.273-297, Sept. 1995[doi>10.1023/A:1022627411411]
Daelemans, W., Zavrel, J., van der Sloot, K., and van den Bosch, A. 1999. TIMBL: Tilburg memory-based learner---version 4.3 reference guide.
Stephen Della Pietra , Vincent Della Pietra , John Lafferty, Inducing Features of Random Fields, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.19 n.4, p.380-393, April 1997[doi>10.1109/34.588021]
Thomas G. Dietterich, Approximate statistical tests for comparing supervised classification learning algorithms, Neural Computation, v.10 n.7, p.1895-1923, Oct. 1998[doi>10.1162/089976698300017197]
Thomas G. Dietterich, An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization, Machine Learning, v.40 n.2, p.139-157, Aug. 2000[doi>10.1023/A:1007607513941]
H. Drucker , Donghui Wu , V. N. Vapnik, Support vector machines for spam categorization, IEEE Transactions on Neural Networks, v.10 n.5, p.1048-1054, September 1999[doi>10.1109/72.788645]
Fano, R. 1961. Transmission of Information. MIT Press, Cambridge, MA.
Freund, Y. and Schapire, R. 1999. A short introduction to boosting. J. Japan. Soc. Artif. Intel. 14, 5, 771--780; 11, 5, 771--780.
Freund, Y. and Schapire, R. E. 1996. Experiments with a new boosting algorithm. In International Conference on Machine Learning, 148--156.
Jaynes, E. 1983. Papers on Probability, Statistics, and Statistical Physics. D. Reidel, Dordrecht.
Thorsten Joachims, Making large-scale support vector machine learning practical, Advances in kernel methods: support vector learning, MIT Press, Cambridge, MA, 1999
Thorsten Joachims, Text Categorization with Suport Vector Machines: Learning with Many Relevant Features, Proceedings of the 10th European Conference on Machine Learning, p.137-142, April 21-23, 1998
Kolcz, A. and Alspector, J. 2001. SVM-based filtering of e-mail spam with content-specific misclassification costs. In Proceedings of the TextDM'01 Workshop on Text Mining---held at the 2001 IEEE International Conference on Data Mining.
Lebanon, G. and Lafferty, J. 2001. Boosting and maximum likelihood for exponential models. In Advances in Neural Information Processing Systems.
David D. Lewis, Evaluating and optimizing autonomous text classification systems, Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, p.246-254, July 09-13, 1995, Seattle, Washington, USA[doi>10.1145/215206.215366]
David D. Lewis, Naive (Bayes) at Forty: The Independence Assumption in Information Retrieval, Proceedings of the 10th European Conference on Machine Learning, p.4-15, April 21-23, 1998
D. C. Liu , J. Nocedal, On the limited memory BFGS method for large scale optimization, Mathematical Programming: Series A and B, v.45 n.3, p.503-528, Dec. 1989[doi>10.1007/BF01589116]
McCallum, A. and Nigam, K. 1998. A comparison of event models for naive bayes text classification. In AAAI-98 Workshop on Learning for Text Categorization.
Nigam, K., Lafferty, J., and McCallum, A. 1999. Using maximum entropy for text classification. In IJCAI-99 Workshop on Machine Learning for Information Filtering.
Orasan, C. and Krishnamurthy, R. 2002. A corpus-based investigation of junk emails. In Language Resources and Evaluation Conference (LREC- 2002) (Las Palmas, Spain).
Pantel, P. and Lin, D. 1998. Spamcop: A spam classification & organization program. In Learning for Text Categorization: Papers from the 1998 Workshop. AAAI Technical Report WS-98-05, Madison, WI.
Platt, J. C. 1999. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In Advances in Large Margin Classifiers, A. Smola, P. Bartlett, B. Schlkopf, and D. Schuurmans, Eds. MIT Press, Cambridge, MA, 61--74.
Adwait Ratnaparkhi , Mitchell P. Marcus, Maximum entropy models for natural language ambiguity resolution, University of Pennsylvania, Philadelphia, PA, 1998
Rosenfeld, R. 1996. A maximum entropy approach to adaptive statistical language modeling. Computer, Speech and Language1996 10, 187--228. Long version: Carnegie Mellon Tech. Rep. CMU-CS-94-138.
Sahami, M., Dumais, S., Heckerman, D., and Horvitz, E. 1998. A Bayesian approach to filtering junk e-mail. In Learning for Text Categorization: Papers from the 1998 Workshop. AAAI Technical Report WS-98-05, Madison, WI.
Robert E. Schapire , Yoram Singer, BoosTexter: A Boosting-based Systemfor Text Categorization, Machine Learning, v.39 n.2-3, p.135-168, May-June 2000[doi>10.1023/A:1007649029923]
Karl-Michael Schneider, A comparison of event models for Naive Bayes anti-spam e-mail filtering, Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics, April 12-17, 2003, Budapest, Hungary[doi>10.3115/1067807.1067848]
Fabrizio Sebastiani, Machine learning in automated text categorization, ACM Computing Surveys (CSUR), v.34 n.1, p.1-47, March 2002[doi>10.1145/505282.505283]
Vladimir N. Vapnik, The nature of statistical learning theory, Springer-Verlag New York, Inc., New York, NY, 1995
Yiming Yang , Christopher G. Chute, An example-based mapping method for text categorization and retrieval, ACM Transactions on Information Systems (TOIS), v.12 n.3, p.252-277, July 1994[doi>10.1145/183422.183424]
Yiming Yang , Xin Liu, A re-examination of text categorization methods, Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, p.42-49, August 15-19, 1999, Berkeley, California, USA[doi>10.1145/312624.312647]
Yiming Yang , Jan O. Pedersen, A Comparative Study on Feature Selection in Text Categorization, Proceedings of the Fourteenth International Conference on Machine Learning, p.412-420, July 08-12, 1997
Zhang, L. and Yao, T. 2003. Filtering junk mail with a maximum entropy model. In Proceeding of 20th International Conference on Computer Processing of Oriental Languages (ICCPOL03), 446--453.
