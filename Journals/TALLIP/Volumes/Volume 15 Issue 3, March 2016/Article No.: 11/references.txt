Ebru Arsoy, Stanley F. Chen, Bhuvana Ramabhadran, and Abhinav Sethy. 2013. Converting neural network language models into back-off language models for efficient decoding in automatic speech recognition. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing (ICASSP’13). IEEE, 8242--8246.
Ebru Arisoy , Stanley F. Chen , Bhuvana Ramabhadran , Abhinav Sethy, Converting Neural Network Language Models into Back-off Language Models for Efficient Decoding in Automatic Speech Recognition, IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), v.22 n.1, p.184-192, January 2014[doi>10.1109/TASLP.2013.2286919]
Michael Auli, Michel Galley, Chris Quirk, and Geoffrey Zweig. 2013. Joint language and translation modeling with recurrent neural networks. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Seattle, Washington, 1044--1054.
Yoshua Bengio , Réjean Ducharme , Pascal Vincent , Christian Janvin, A neural probabilistic language model, The Journal of Machine Learning Research, 3, 3/1/2003
Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J. Och, and Jeffrey Dean. 2007. Large language models in machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL). Association for Computational Linguistics. 858--867.
Ciprian Chelba, Thorsten Brants, Will Neveitt, and Peng Xu. 2010. Study on interaction between entropy pruning and kneser-ney smoothing. In Proceedings of The Annual Conference of the International Speech Communication Association. 2242--2245.
Stanley F. Chen , Joshua Goodman, An empirical study of smoothing techniques for language modeling, Proceedings of the 34th annual meeting on Association for Computational Linguistics, p.310-318, June 24-27, 1996, Santa Cruz, California[doi>10.3115/981863.981904]
Stanley F. Chen , Joshua Goodman, An empirical study of smoothing techniques for language modeling, Computer Speech and Language, v.13 n.4, p.359-394, October 1999[doi>10.1006/csla.1999.0128]
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder--decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 1724--1734.
Anoop Deoras, Tomas Mikolov, Stefan Kombrink, Martin Karafiát, and Sanjeev Khudanpur. 2011. Variational approximation of long-span language models for LVCSR. In Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP’11). IEEE, 5532--5535. DOI:http://dx.doi.org/10.1109/ICASSP.2011.5947612
Jacob Devlin, Rabih Zbib, Zhongqiang Huang, Thomas Lamar, Richard Schwartz, and John Makhoul. 2014. Fast and robust neural network joint models for statistical machine translation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1370--1380.
Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, and Takehito Utsuro. 2010. Overview of the patent translation task at the NTCIR-8 workshop. In Proceedings of the 8th NTCIR Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering and Cross-Lingual Information Access. 293--302.
Jianfeng Gao, Xiaodong He, Wen-tau Yih, and Li Deng. 2014. Learning continuous phrase representations for translation modeling. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 699--709.
Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, and Benjamin K. Tsou. 2011. Overview of the patent machine translation task at the NTCIR-9 workshop. In Proceedings of NTCIR-9 Workshop Meeting. 559--578.
Michael Gutmann and Aapo Hyvärinen. 2010. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the International Conference on Artificial Intelligence and Statistics. 297--304.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H. Clark, and Philipp Koehn. 2013. Scalable modified Kneser-Ney language model estimation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 690--696.
Zhongqiang Huang, Jacob Devlin, and Spyros Matsoukas. 2013. BBN’s systems for the Chinese-English sub-task of the NTCIR-10 PatentMT evaluation. In Proceedings of NII Testbeds and Community for Information Access Research (NTCIR’10).
Zhongye Jia and Hai Zhao. 2014. A joint graph model for Pinyin-to-Chinese conversion with typo correction. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. 1512--1523.
Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent continuous translation models. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. 1700--1709.
Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Dekang Lin and Dekai Wu (Eds.). 388--395.
Philipp Koehn , Franz Josef Och , Daniel Marcu, Statistical phrase-based translation, Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, p.48-54, May 27-June 01, 2003, Edmonton, Canada[doi>10.3115/1073445.1073462]
Stanislas Lauly, Hugo Larochelle, Mitesh Khapra, Balaraman Ravindran, Vikas C. Raykar, and Amrita Saha. 2014. An autoencoder approach to learning bilingual word representations. In Advances in Neural Information Processing Systems. 1853--1861.
Hai-Son Le, I. Oparin, A. Allauzen, J. Gauvain, and F. Yvon. 2011. Structured output layer neural network language model. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP’11). 5524--5527. DOI:http://dx.doi.org/10.1109/ICASSP.2011.5947610
Peng Li, Yang Liu, Maosong Sun, Tatsuya Izuha, and Dakun Zhang. 2014. A neural reordering model for phrase-based translation. In Proceedings of, the 25th International Conference on Computational Linguistics: Technical Papers (COLING 2014), 1897--1907. http://www.aclweb.org/anthology/C14-1179.
lemao Liu, Taro Watanabe, Eiichiro Sumita, and Tiejun Zhao. 2013. Additive neural networks for statistical machine translation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 791--801.
Shujie Liu, Nan Yang, Mu Li, and Ming Zhou. 2014. A recursive recurrent neural network for statistical machine translation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1491--1500.
Xuezhe Ma and Hai Zhao. 2012. Fourth-order dependency parsing. In Proceedings of the 24th International Conference on Computational Linguistics. 785--796.
Tomas Mikolov, Anoop Deoras, Daniel Povey, Lukas Burget, and Jan Cernock. 2011. Strategies for training large scale neural network language models. In Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP’11). 196--201.
Tomas Mikolov, Martin Karafiát, Lukas Burget, Jan Cernockỳ, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model. In Proceedings of the Annual Conference of the International Speech Communication Association. 1045--1048.
Andriy Mnih and Geoffrey E. Hinton. 2008. A scalable hierarchical distributed language model. In Advances in Neural Information Processing Systems 21, D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou (Eds.). 1081--1088.
Vinod Nair and Geoffrey E. Hinton. 2010. Rectified linear units improve restricted Boltzmann machines. In Proceedings of the 27th International Conference on Machine Learning (ICML’10). 807--814.
Jan Niehues and Alex Waibel. 2012. Continuous space language models using restricted Boltzmann machines. In Proceedings of the International Workshop for Spoken Language Translation (IWSLT’12). 311--318.
Franz Josef Och, Minimum error rate training in statistical machine translation, Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, p.160-167, July 07-12, 2003, Sapporo, Japan[doi>10.3115/1075096.1075117]
Franz Josef Och , Hermann Ney, A systematic comparison of various statistical alignment models, Computational Linguistics, v.29 n.1, p.19-51, March 2003[doi>10.1162/089120103321337421]
Kishore Papineni , Salim Roukos , Todd Ward , Wei-Jing Zhu, BLEU: a method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, July 07-12, 2002, Philadelphia, Pennsylvania[doi>10.3115/1073083.1073135]
Xiaochang Peng and Daniel Gildea. 2014. Type-based MCMC for sampling tree fragments from forests. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP’14). 1735--1745.
Brian Roark, Cyril Allauzen, and Michael Riley. 2013. Smoothed marginal distribution constraints for language modeling. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL). 43--52.
Holger Schwenk, Continuous space language models, Computer Speech and Language, v.21 n.3, p.492-518, July, 2007[doi>10.1016/j.csl.2006.09.003]
Holger Schwenk. 2010. Continuous-space language models for statistical machine translation. The Prague Bulletin of Mathematical Linguistics (2010), 137--146.
Holger Schwenk , Daniel Dchelotte , Jean-Luc Gauvain, Continuous space language models for statistical machine translation, Proceedings of the COLING/ACL on Main conference poster sessions, p.723-730, July 17-18, 2006, Sydney, Australia
Holger Schwenk , Anthony Rousseau , Mohammed Attik, Large, pruned or continuous space language models on a GPU for statistical machine translation, Proceedings of the NAACL-HLT 2012 Workshop: Will We Ever Really Replace the N-gram Model? On the Future of Language Modeling for HLT, p.11-19, June 08-08, 2012, Montreal, Canada
V. Siivola , T. Hirsimaki , S. Virpioja, On Growing and Pruning Kneser–Ney Smoothed-Gram Models, IEEE Transactions on Audio, Speech, and Language Processing, v.15 n.5, p.1617-1624, July 2007[doi>10.1109/TASL.2007.896666]
Le Hai Son , Alexandre Allauzen , Guillaume Wisniewski , François Yvon, Training continuous space language models: some practical issues, Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, p.778-788, October 09-11, 2010, Cambridge, Massachusetts
Le Hai Son , Alexandre Allauzen , François Yvon, Continuous space translation models with neural networks, Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, June 03-08, 2012, Montreal, Canada
Andreas Stolcke. 1998. Entropy-based pruning of backoff language models. In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop. 270--274.
Andreas Stolcke. 2002. SRILM—An extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing, 257--286.
Andreas Stolcke, Jing Zheng, Wen Wang, and Victor Abrash. 2011. SRILM at sixteen: Update and outlook. In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop.
Martin Sundermeyer, Tamer Alkhouli, Joern Wuebker, and Hermann Ney. 2014. Translation modeling with bidirectional recurrent neural networks. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 14--25.
Ashish Vaswani, Yinggong Zhao, Victoria Fossum, and David Chiang. 2013. Decoding with large-scale neural language models improves translation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. 1387--1392.
Rui Wang, Masao Utiyama, Isao Goto, Eiichro Sumita, Hai Zhao, and Bao-Liang Lu. 2013. Converting continuous-space language models into N-gram language models for statistical machine translation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. 845--850.
Rui Wang, Hai Zhao, and Bao Liang Lu. 2015a. English to Chinese translation: How Chinese character matters?. In Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation, 274--284.
Rui Wang, Hai Zhao, Bao Liang Lu, Masao Utiyama, and Eiichiro Sumita. 2014. Neural network based bilingual language model growing for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. 189--195.
Rui Wang , Hai Zhao , Bao-Liang Lu , Masao Utiyama , Eiichiro Sumita, Bilingual continuous-space language model growing for statistical machine translation, IEEE Transactions on Audio, Speech, and Language Processing, v.23 n.7, p.1209-1220, July 2015[doi>10.1109/TASLP.2015.2425220]
Xiaolin Wang, Masao Utiyama, Andrew Finch, and Eiichiro Sumita. 2014. Empirical study of unsupervised Chinese word segmentation methods for SMT on large-scale corpora. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 752--758. http://www.aclweb.org/anthology/P14-2122.
Qiongkai Xu and Hai Zhao. 2012. Using deep linguistic features for finding deceptive opinion spam. In Proceedings of the 24th International Conference on Computational Linguistics. 1341--1350.
Omar F. Zaidan. 2009. Z-MERT: A fully configurable open source tool for minimum error rate training of machine translation systems. The Prague Bulletin of Mathematical Linguistics 91 (2009), 79--88.
Jingyi Zhang, Masao Utiyama, Eiichiro Sumita, and Hai Zhao. 2014. Learning hierarchical translation spans. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. 183--188.
Jingyi Zhang , Hai Zhao, Improving function word alignment with frequency and syntactic information, Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, August 03-09, 2013, Beijing, China
Hai Zhao, Character-level dependencies in Chinese: usefulness and learning, Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, p.879-887, March 30-April 03, 2009, Athens, Greece
Hai Zhao , Wenliang Chen , Chunyu Kit, Semantic dependency parsing of NomBank and PropBank: an efficient integrated approach via a large-scale feature selection, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1, August 06-07, 2009, Singapore
Hai Zhao , Yan Song , Chunyu Kit , Guodong Zhou, Cross language dependency parsing using a bilingual lexicon, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1, August 02-07, 2009, Suntec, Singapore
Hai Zhao , Masao Utiyama , Eiichiro Sumita , Bao-Liang Lu, An empirical study on word segmentation for chinese machine translation, Proceedings of the 14th international conference on Computational Linguistics and Intelligent Text Processing, March 24-30, 2013, Samos, Greece[doi>10.1007/978-3-642-37256-8_21]
Will Y. Zou, Richard Socher, Daniel Cer, and Christopher D. Manning. 2013. Bilingual word embeddings for phrase-based machine translation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, 1393--1398.
