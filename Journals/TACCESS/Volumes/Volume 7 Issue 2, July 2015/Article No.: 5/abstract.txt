This article presents an experiment with seniors and people with visual impairment in a voice-controlled smart home using the Sweet-Homesystem. The experiment shows some weaknesses in automatic speech recognition that must be addressed, as well as the need for better adaptation to the user and the environment. Users were disturbed by the rigid structure of the grammar and were eager to adapt it to their own preferences. Surprisingly, while no humanoid aspect was introduced in the system, the senior participants were inclined to embody the system. Despite these aspects to improve, the system has been favorably assessed as diminishing most participant fears related to the loss of autonomy.