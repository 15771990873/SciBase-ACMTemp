Lisa Anthony , Quincy Brown , Jaye Nias , Berthel Tate, Examining the need for visual feedback during gesture interaction on mobile touchscreen devices for kids, Proceedings of the 12th International Conference on Interaction Design and Children, p.157-164, June 24-27, 2013, New York, New York, USA[doi>10.1145/2485760.2485775]
Shiri Azenkot , Jacob O. Wobbrock , Sanjana Prasain , Richard E. Ladner, Input finger detection for nonvisual touch screen text entry inPerkinput, Proceedings of Graphics Interface 2012, May 28-30, 2012, Toronto, Ontario, Canada
Olivier Bau , Wendy E. Mackay, OctoPocus: a dynamic guide for learning gesture-based command sets, Proceedings of the 21st annual ACM symposium on User interface software and technology, October 19-22, 2008, Monterey, CA, USA[doi>10.1145/1449715.1449724]
Matthew N. Bonner , Jeremy T. Brudvik , Gregory D. Abowd , W. Keith Edwards, No-look notes: accessible eyes-free multi-touch text entry, Proceedings of the 8th international conference on Pervasive Computing, May 17-20, 2010, Helsinki, Finland[doi>10.1007/978-3-642-12654-3_24]
L. M. Brown and S. A. Brewster. 2003. Drawing by ear: Interpreting sonified line graphs. In Proceedings of the International Conference on Auditory Display.
G. A. Calvert, P. C. Hansen, S. D. Iversen, and M. J. Brammer. 2001. Detection of audio-visual integration sites in humans by application of electrophysiological criteria to the BOLD effect. Neuroimage 14, 2 (2001), 427--438.
Andrew Crossan , Stephen Brewster, Multimodal Trajectory Playback for Teaching Shape Information and Trajectories to Visually Impaired Computer Users, ACM Transactions on Accessible Computing (TACCESS), v.1 n.2, p.1-34, October 2008[doi>10.1145/1408760.1408766]
Brian Frey , Caleb Southern , Mario Romero, Brailletouch: mobile texting for the visually impaired, Proceedings of the 6th international conference on Universal access in human-computer interaction: context diversity, July 09-14, 2011, Orlando, FL
Tiago Guerreiro , Paulo Lagoá , Hugo Nicolau , Daniel Gonçalves , Joaquim A. Jorge, From Tapping to Touching: Making Touch Screens Accessible to Blind Users, IEEE MultiMedia, v.15 n.4, p.48-50, October 2008[doi>10.1109/MMUL.2008.88]
Susumu Harada , Hironobu Takagi , Chieko Asakawa, On the audio representation of radial direction, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada[doi>10.1145/1978942.1979354]
E. Hoggan and S. Brewster. 2012. Non-speech auditory and crossmodal output. In The Human-Computer Interaction Handbook, Julie A. Jacko and Andrew Sears (Eds.). L. Erlbaum Associates Inc., Hillsdale, NJ, 220--239.
H. M. Kamel, P. Roth, and R. R. Sinha. 2001. Graphics and user's exploration via simple sonics (GUESS): Providing interrelational representation of objects in a non-visual environment. In Proceedings of the 7th International Conference on Auditory Display.
Shaun K. Kane , Jeffrey P. Bigham , Jacob O. Wobbrock, Slide rule: making mobile touch screens accessible to blind people using multi-touch interaction techniques, Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility, October 13-15, 2008, Halifax, Nova Scotia, Canada[doi>10.1145/1414471.1414487]
Shaun K. Kane , Meredith Ringel Morris , Annuska Z. Perkins , Daniel Wigdor , Richard E. Ladner , Jacob O. Wobbrock, Access overlays: improving non-visual access to large touch screens for blind users, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA[doi>10.1145/2047196.2047232]
Shaun K. Kane , Jacob O. Wobbrock , Richard E. Ladner, Usable gestures for blind people: understanding preference and performance, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada[doi>10.1145/1978942.1979001]
P. O. Kristensson , L. C. Denby, Continuous recognition and visualization of pen strokes and touch-screen gestures, Proceedings of the Eighth Eurographics Symposium on Sketch-Based Interfaces and Modeling, August 05-07, 2011, Vancouver, British Columbia, Canada[doi>10.1145/2021164.2021181]
Barbara Leporini , Maria Claudia Buzzi , Marina Buzzi, Interacting with mobile devices via VoiceOver: usability and accessibility issues, Proceedings of the 24th Australian Computer-Human Interaction Conference, p.339-348, November 26-30, 2012, Melbourne, Australia[doi>10.1145/2414536.2414591]
Min Lin , Rich Goldman , Kathleen J. Price , Andrew Sears , Julie Jacko, How do people tap when walking? An empirical investigation of nomadic data entry, International Journal of Human-Computer Studies, v.65 n.9, p.759-769, September, 2007[doi>10.1016/j.ijhcs.2007.04.001]
N. Noble and B. Martin. 2006. Shape discovering using tactile guidance. In Proceedings of the 6th International Conference on EuroHaptics.
Donald A. Norman, Natural user interfaces are not natural, interactions, v.17 n.3, May + June 2010[doi>10.1145/1744161.1744163]
Uran Oh , Shaun K. Kane , Leah Findlater, Follow that sound: using sonification and corrective verbal feedback to teach touchscreen gestures, Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility, p.1-8, October 21-23, 2013, Bellevue, Washington[doi>10.1145/2513383.2513455]
Pekka Parhi , Amy K. Karlson , Benjamin B. Bederson, Target size study for one-handed thumb use on small touchscreen devices, Proceedings of the 8th conference on Human-computer interaction with mobile devices and services, September 12-15, 2006, Helsinki, Finland[doi>10.1145/1152215.1152260]
Beryl Plimmer , Peter Reid , Rachel Blagojevic , Andrew Crossan , Stephen Brewster, Signing on the tactile line: A multimodal system for teaching handwriting to blind children, ACM Transactions on Computer-Human Interaction (TOCHI), v.18 n.3, p.1-29, July 2011[doi>10.1145/1993060.1993067]
Jing Su , Alyssa Rosenzweig , Ashvin Goel , Eyal de Lara , Khai N. Truong, Timbremap: enabling the visually-impaired to use maps on touch-enabled devices, Proceedings of the 12th international conference on Human computer interaction with mobile devices and services, September 07-10, 2010, Lisbon, Portugal[doi>10.1145/1851600.1851606]
B. N. Walker, J. Lindsay, and S. Lab. 2005. Navigation performance in a virtual environment with bonephones. In Proceedings of the International Conference on Auditory Display. 260--263.
B. N. Walker , L. M. Mauney, Universal Design of Auditory Graphs: A Comparison of Sonification Mappings for Visually Impaired and Sighted Listeners, ACM Transactions on Accessible Computing (TACCESS), v.2 n.3, p.1-16, March 2010[doi>10.1145/1714458.1714459]
Koji Yatani , Nikola Banovic , Khai Truong, SpaceSense: representing geographical information to visually impaired people using spatial tactile feedback, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA[doi>10.1145/2207676.2207734]
Koji Yatani , Khai Nhut Truong, SemFeel: a user interface with semantic tactile feedback for mobile touch-screen devices, Proceedings of the 22nd annual ACM symposium on User interface software and technology, October 04-07, 2009, Victoria, BC, Canada[doi>10.1145/1622176.1622198]
Haixia Zhao , Catherine Plaisant , Ben Shneiderman , Jonathan Lazar, Data Sonification for Users with Visual Impairment: A Case Study with Georeferenced Data, ACM Transactions on Computer-Human Interaction (TOCHI), v.15 n.1, p.1-28, May 2008[doi>10.1145/1352782.1352786]
