Perceptual evaluation is still the most common method in clinical practice for diagnosing and following the progression of the condition of people with speech disorders. Although a number of studies have addressed the acoustic analysis of speech productions exhibiting impairments, additional descriptive analysis is required to manage interperson variability, considering speakers with the same condition or across different conditions. In this context, this article investigates automatic speech processing approaches dedicated to the detection and localization of abnormal acoustic phenomena in speech signal produced by people with speech disorders. This automatic process aims at enhancing the manual investigation of human experts while at the same time reducing the extent of their intervention by calling their attention to specific parts of the speech considered as atypical from an acoustical point of view.Two different approaches are proposed in this article. The first approach models only the normal speech, whereas the second models both normal and dysarthric speech. Both approaches are evaluated following two strategies: one consists of a strict phone comparison between a human annotation of abnormal phones and the automatic output, while the other uses a “one-phone delay” for the comparison.The experimental evaluation of both approaches for the task of detecting acoustic anomalies was conducted on two different corpora composed of French dysarthric speakers and control speakers. These approaches obtain very encouraging results and their potential for clinical uses with different types of dysarthria and neurological diseases is quite promising.