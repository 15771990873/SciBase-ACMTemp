Motion capture (mocap) technology is an efficient method for digitizing art performances, and is becoming increasingly popular in the preservation and dissemination of dance performances. Although technically the captured data can be of very high quality, dancing allows stylistic variations and improvisations that cannot be easily identified. The majority of motion analysis algorithms are based on ad-hoc quantitative metrics, thus do not usually provide insights on style qualities of a performance. In this work, we present a framework based on the principles of Laban Movement Analysis (LMA) that aims to identify style qualities in dance motions. The proposed algorithm uses a feature space that aims to capture the four LMA components (Body, Effort, Shape, Space), and can be subsequently used for motion comparison and evaluation. We have designed and implemented a prototype virtual reality simulator for teaching folk dances in which users can preview dance segments performed by a 3D avatar and repeat them. The userâ€™s movements are captured and compared to the folk dance template motions; then, intuitive feedback is provided to the user based on the LMA components. The results demonstrate the effectiveness of our system, opening new horizons for automatic motion and dance evaluation processes.