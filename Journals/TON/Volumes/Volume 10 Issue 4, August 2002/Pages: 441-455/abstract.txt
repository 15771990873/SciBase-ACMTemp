The problem of document replacement in web caches has received much attention in recent research, and it has been shown that the eviction rule "replace the least recently used document" performs poorly in web caches. Instead, it has been shown that using a combination of several criteria, such as the recentness and frequency of use, the size, and the cost of fetching a document, leads to a sizable improvement in hit rate and latency reduction. However, in order to implement these novel schemes, one needs to maintain complicated data structures. We propose randomized algorithms for approximating any existing web-cache replacement scheme and thereby avoid the need for any data structures.At document-replacement times, the randomized algorithm samplesNdocuments from the cache and replaces the least useful document from the sample, where usefulness is determined according to the criteria mentioned above. The nextM<Nleast useful documents are retained for the succeeding iteration. When the next replacement is to be performed, the algorithm obtainsN---Mnew samples from the cache and replaces the least useful document from theN---Mnew samples and theMpreviously retained. Using theory and simulations, we analyze the algorithm and find that it matches the performance of existing document replacement schemes for values ofNandMas low as 8 and 2 respectively. Interestingly, we find that retaining a small number of samples from one iteration to the next leads to an exponential improvement in performance as compared to retaining no samples at all.