Anton Batliner , Stefan Steidl , Dino Seppi , Björn Schuller, Segmenting into adequate units for automatic recognition of emotion-related episodes: a speech-based approach, Advances in Human-Computer Interaction, 2010, p.1-15, January 2010[doi>10.1155/2010/782802]
Anton Batliner , Stefan Steidl , Björn Schuller , Dino Seppi , Thurid Vogt , Johannes Wagner , Laurence Devillers , Laurence Vidrascu , Vered Aharonson , Loic Kessous , Noam Amir, Whodunnit - Searching for the most important feature types signalling emotion-related user states in speech, Computer Speech and Language, v.25 n.1, p.4-28, January, 2011[doi>10.1016/j.csl.2009.12.003]
Burkhardt, F., Paeschke, A., Rolfes, M., Sendlmeier, W., and Weiss, B. 2005. A database of german emotional speech. In Proceedings of the Interspeech Conference. 1517--1520.
Busso, C., Lee, S., and Narayanan, S. S. 2007. Using neutral speech models for emotional speech analysis. In Proceedings of the Interspeech Conference. 2225--2228.
George Caridakis , Lori Malatesta , Loic Kessous , Noam Amir , Amaryllis Raouzaiou , Kostas Karpouzis, Modeling naturalistic affective states via facial and vocal expressions recognition, Proceedings of the 8th international conference on Multimodal interfaces, November 02-04, 2006, Banff, Alberta, Canada[doi>10.1145/1180995.1181029]
Chih-Chung Chang , Chih-Jen Lin, LIBSVM: A library for support vector machines, ACM Transactions on Intelligent Systems and Technology (TIST), v.2 n.3, p.1-27, April 2011[doi>10.1145/1961189.1961199]
Cohen, J., Cohen, P., West, S. G., and Aiken, L. S. 2003. Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 2nd ed. Lawrence Erlbaum Associates, Hillsdale, NJ.
Cowie, R., Douglas-Cowie, E., Savvidou, S., McMahon, E., Sawey, M., and Schröder, M. 2000. Feeltrace: an instrument for recording perceived emotion in real time. In Proceedings of the ISCA Workshop on Speech and Emotion. 19--24.
Laurence Devillers , Laurence Vidrascu , Lori Lamel, 2005 Special Issue: Challenges in real-life emotion annotation and machine learning based detection, Neural Networks, v.18 n.4, p.407-422, May 2005[doi>10.1016/j.neunet.2005.03.007]
Ellen Douglas-Cowie , Roddy Cowie , Ian Sneddon , Cate Cox , Orla Lowry , Margaret Mcrorie , Jean-Claude Martin , Laurence Devillers , Sarkis Abrilian , Anton Batliner , Noam Amir , Kostas Karpouzis, The HUMAINE Database: Addressing the Collection and Annotation of Naturalistic and Induced Emotional Data, Proceedings of the 2nd international conference on Affective Computing and Intelligent Interaction, September 12-14, 2007, Lisbon, Portugal[doi>10.1007/978-3-540-74889-2_43]
Ellen Douglas-Cowie , Roddy Cowie , Ian Sneddon , Cate Cox , Orla Lowry , Margaret Mcrorie , Jean-Claude Martin , Laurence Devillers , Sarkis Abrilian , Anton Batliner , Noam Amir , Kostas Karpouzis, The HUMAINE Database: Addressing the Collection and Annotation of Naturalistic and Induced Emotional Data, Proceedings of the 2nd international conference on Affective Computing and Intelligent Interaction, September 12-14, 2007, Lisbon, Portugal[doi>10.1007/978-3-540-74889-2_43]
Ekman, P. and Friesen, W. V. 1975. Unmasking the Face: A Guide to Recognizing Emotions from Facial Expressions. Prentice Hall, Englewood Cliffs, NJ.
Eyben, F., Wöllmer, M., Graves, A., Schuller, B., Douglas-Cowie, E., and Cowie, R. 2010a. On-line emotion recognition in a 3-d activation-valence-time continuum using acoustic and linguistic cues. J. Multimodal User Interfaces 3, 1-2, 7--19.
Florian Eyben , Martin Wöllmer , Björn Schuller, Opensmile: the munich versatile and fast open-source audio feature extractor, Proceedings of the international conference on Multimedia, October 25-29, 2010, Firenze, Italy[doi>10.1145/1873951.1874246]
Eyben, F., Wöllmer, M., Valster, M., Gunes, H., Schuller, B., and Pantic, M. 2011. String-based audiovisual fusion of behavioural events for the assessment of dimensional affect. In Proceedings FG Conference (to appear).
Fernandez, S., Graves, A., and Schmidhuber, J. 2008. Phoneme recognition in timit with blstm-ctc. Tech. rep., IDSIA.
Fontaine, J. R. J., Scherer, K. R., Roesch, E. B., and Ellsworth, P. C. 2007. The world of emotions is not two-dimensional. Psychol. Sci. 18, 2, 1050--1057.
N. Fragopanagos , J. G. Taylor, 2005 Special Issue: Emotion recognition in human-computer interaction, Neural Networks, v.18 n.4, p.389-405, May 2005[doi>10.1016/j.neunet.2005.03.006]
Glowinski, D., Camurri, A., Volpe, G., Dael, N., and Scherer, K. 2008. Technique for automatic emotion recognition by body gesture analysis. In Proceedings of Computer Vision and Pattern Recognition Workshops. 1--6.
Alex Graves , Santiago Fernández , Jürgen Schmidhuber, Bidirectional LSTM networks for improved phoneme classification and recognition, Proceedings of the 15th international conference on Artificial neural networks: formal models and their applications, September 11-15, 2005, Warsaw, Poland
Alex Graves , Jürgen Schmidhuber, 2005 Special Issue: Framewise phoneme classification with bidirectional LSTM and other neural network architectures, Neural Networks, v.18 n.5-6, p.602-610, June 2005[doi>10.1016/j.neunet.2005.06.042]
Grimm, M., Kroschel, K., and Narayanan, S. 2007a. Support vector regression for automatic recognition of spontaneous emotions in speech. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing (ICASSP). Vol. 4. IEEE.
Michael Grimm , Kristian Kroschel , Emily Mower , Shrikanth Narayanan, Primitives-based evaluation and estimation of emotions in speech, Speech Communication, v.49 n.10-11, p.787-800, October, 2007[doi>10.1016/j.specom.2007.01.010]
Gunes, H. and Pantic, M. 2010a. Automatic, dimensional and continuous emotion recognition. Int. J. Synth. Emot. 1, 1, 68--99.
Hatice Gunes , Maja Pantic, Automatic measurement of affect in dimensional and continuous spaces: why, what, and how?, Proceedings of the 7th International Conference on Methods and Techniques in Behavioral Research, p.1-5, August 24-27, 2010, Eindhoven, Netherlands[doi>10.1145/1931344.1931356]
Hatice Gunes , Maja Pantic, Dimensional emotion prediction from spontaneous head gestures for interaction with sensitive artificial listeners, Proceedings of the 10th international conference on Intelligent virtual agents, September 20-22, 2010, Philadelphia, PA
Hall, M. A. 1998. Correlation-based feature subset selection for machine learning. Ph.D. thesis, University of Waikato, Hamilton, New Zealand.
Hochreiter, S., Bengio, Y., Frasconi, P., and Schmidhuber, J. 2001. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies. In A Field Guide to Dynamical Recurrent Neural Networks, S. C. Kremer and J. F. Kolen, Eds., IEEE Press.
Sepp Hochreiter , Jürgen Schmidhuber, Long Short-Term Memory, Neural Computation, v.9 n.8, p.1735-1780, November 15, 1997[doi>10.1162/neco.1997.9.8.1735]
Spiros V. Ioannou , Amaryllis T. Raouzaiou , Vasilis A. Tzouvaras , Theofilos P. Mailis , Kostas C. Karpouzis , Stefanos D. Kollias, 2005 Special Issue: Emotion recognition through facial expression analysis based on a neurofuzzy network, Neural Networks, v.18 n.4, p.423-435, May 2005[doi>10.1016/j.neunet.2005.03.004]
Lee, C., Busso, C., Lee, S., and Narayanan, S. 2009. Modeling mutual influence of interlocutor emotion states in dyadic spoken interactions. In Proceedings of the Interspeech Conference. 1983--1986.
Jeroen Lichtenauer , Jie Shen , Michel Valstar , Maja Pantic, Cost-effective solution to synchronised audio-visual data capture using multiple sensors, Image and Vision Computing, v.29 n.10, p.666-680, September, 2011[doi>10.1016/j.imavis.2011.07.004]
McKeown, G., Valstar, M. F., Pantic, M., and Cowie, R. 2010. The semaine corpus of emotionally coloured character interactions. In Proceedings of the ICME Conference. IEEE, 1--6.
Metallinou, A., Katsamanis, A., Wang, Y., and Narayanan, S. S. 2011. Tracking changes in continuous emotion states using body language and prosodic cues. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing. IEEE, 2288--2291.
E. Mower , M. J. Matarić , S. Narayanan, A Framework for Automatic Human Emotion Classification Using Emotion Profiles, IEEE Transactions on Audio, Speech, and Language Processing, v.19 n.5, p.1057-1070, July 2011[doi>10.1109/TASL.2010.2076804]
Mower, E. and Narayanan, S. S. 2011. A hierarchical static-dynamic framework for emotion classification. In Proceedings of International Conference on Acoustics, Speech and Signal Processing. IEEE, 2372--2375.
Mihalis A. Nicolaou , Hatice Gunes , Maja Pantic, Audio-Visual Classification and Fusion of Spontaneous Affective Data in Likelihood Space, Proceedings of the 2010 20th International Conference on Pattern Recognition, p.3695-3699, August 23-26, 2010[doi>10.1109/ICPR.2010.900]
Oudeyer Pierre-Yves, The production and recognition of emotions in speech: features and algorithms, International Journal of Human-Computer Studies, v.59 n.1-2, p.157-183, July 2003[doi>10.1016/S1071-5819(02)00141-6]
Juan Antonio Pérez-Ortiz , Felix A. Gers , Douglas Eck , Jürgen Schmidhuber, Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets, Neural Networks, v.16 n.2, p.241-250, March 2003[doi>10.1016/S0893-6080(02)00219-8]
Peters, C. and O'Sullivan, C. 2002. Synthetic vision and memory for autonomous virtual humans. Comput. Graph. Forum 21, 4, 743--753.
Riedmiller, M. and Braun, H. 1993. A direct adaptive method for faster backpropagation learning: The rprop algorithm. In Proceedings of the IEEE International Conference on Neural Networks. 586--591.
Schmidt, E. M. and Kim, Y. E. 2010. Prediction of time-varying musical mood distributions from audio. In Proceedings of the International Society for Music Information Retrieval Conference.
Björn Schuller , Anton Batliner , Stefan Steidl , Dino Seppi, Recognising realistic emotions and affect in speech: State of the art and lessons learnt from the first challenge, Speech Communication, v.53 n.9-10, p.1062-1087, November, 2011[doi>10.1016/j.specom.2011.01.011]
Björn Schuller , Ronald Müller , Florian Eyben , Jürgen Gast , Benedikt Hörnler , Martin Wöllmer , Gerhard Rigoll , Anja Höthker , Hitoshi Konosu, Being bored? Recognising natural interest by extensive audiovisual integration for real-life application, Image and Vision Computing, v.27 n.12, p.1760-1774, November, 2009[doi>10.1016/j.imavis.2009.02.013]
Schuller, B., Reiter, S., and Rigoll, G. 2006. Evolutionary feature generation in speech emotion recognition. In Proceedings of the International Conference on Multimedia and Expo (ICME). 5--8.
Schuller, B. and Rigoll, G. 2006. Timing levels in segment-based speech emotion recognition. In Proceedings of the Interspeech Conference. 1818--1821.
Schuller, B., Rigoll, G., and Lang, M. 2003. Hidden markov model-based speech emotion recognition. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing. Vol. II. IEEE, 1--4.
Schuller, B., Seppi, D., Batliner, A., Maier, A., and Steidl, S. 2007a. Towards more reality in the recognition of emotional speech. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing. Vol. IV. IEEE, 941--944.
Schuller, B., Steidl, S., and Batliner, A. 2009b. The INTERSPEECH 2009 emotion challenge. In Proceedings of the Interspeech Conference. 312--315.
Schuller, B., Steidl, S., Batliner, A., Burkhardt, F., Devillers, L., Müller, C., and Narayanan, S. 2010b. The interspeech 2010 paralinguistic challenge. In Proceedings of the Interspeech Conference. 2794--2797.
Schuller, B., Steidl, S., Batliner, A., Schiel, F., and Krajewski, J. 2011. The interspeech 2011 speaker state challenge. In Proceedings of the Interspeech Conference.
Schuller, B., Vlasenko, B., Eyben, F., Rigoll, G., and Wendemuth, A. 2009c. Acoustic emotion recognition: A benchmark comparison of performances. In Proceedings of the ASRU Conference. IEEE.
Bjorn Schuller , Bogdan Vlasenko , Florian Eyben , Martin Wollmer , Andre Stuhlsatz , Andreas Wendemuth , Gerhard Rigoll, Cross-Corpus Acoustic Emotion Recognition: Variances and Strategies, IEEE Transactions on Affective Computing, v.1 n.2, p.119-131, July 2010[doi>10.1109/T-AFFC.2010.8]
Schuller, B., Vlasenko, B., Minguez, R., Rigoll, G., and Wendemuth, A. 2007b. Comparing one and two-stage acoustic modeling in the recognition of emotion in speech. In Proceedings of the Automatic Speech Recognition and Understanding Workshop. 596--600.
Schuller, B., Wimmer, M., Mösenlechner, L., Kern, C., Arsic, D., and Rigoll, G. 2008. Brute-Forcing hierarchical functionals for paralinguistics: A waste of feature space&quest; In Proceedings of the International Conference on Acoustics, Speech and Signal Processing. 4501--4504.
Schuller, B., Zaccarelli, R., Rollet, N., and Devillers, L. 2010d. Cinemo a french spoken language resource for complex emotions: Facts and baselines. In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC).
M. Schuster , K.K. Paliwal, Bidirectional recurrent neural networks, IEEE Transactions on Signal Processing, v.45 n.11, p.2673-2681, November 1997[doi>10.1109/78.650093]
Steidl, S. 2009. Automatic Classification of Emotion-Related User States in Spontaneous Children's Speech. Logos, Berlin.
Steidl, S., Schuller, B., Batliner, A., and Seppi, D. 2009. The hinterland of emotions: Facing the open-microphone challenge. In Proceedings of the 4th International HUMAINE Association Conference on Affective Computing and Intelligent Interaction (ACII). Vol. I. IEEE, 690--697.
Streit, M., Batliner, A., and Portele, T. 2006. Emotions analysis and emotion-handling subdialogues. In SmartKom: Foundations of Multimodal Dialogue Systems, W. Wahlster, Ed., Springer, 317--332.
Bogdan Vlasenko , Björn Schuller , Andreas Wendemuth , Gerhard Rigoll, Frame vs. Turn-Level: Emotion Recognition from Speech Considering Static and Dynamic Processing, Proceedings of the 2nd international conference on Affective Computing and Intelligent Interaction, September 12-14, 2007, Lisbon, Portugal[doi>10.1007/978-3-540-74889-2_13]
Vlasenko, B. and Wendemuth, A. 2007. Tuning hidden markov model for speech emotion recognition. In Proceedings of DAGA 33rd German Annual Conference on Acoustics.
Vogt, T. and Andre, E. 2005. Comparing feature sets for acted and spontaneous speech in view of automatic emotion recognition. In Proceedings of the ICME Conference. 474--477.
Werbos, P. 1990. Backpropagation through time: What it does and how to do it. Proc. IEEE 78, 1550--1560.
Ian H. Witten , Eibe Frank, Data Mining: Practical Machine Learning Tools and Techniques, Second Edition (Morgan Kaufmann Series in Data Management Systems), Morgan Kaufmann Publishers Inc., San Francisco, CA, 2005
Wöllmer, M., Eyben, F., Reiter, S., Schuller, B., Cox, C., Douglas-Cowie, E., and Cowie, R. 2008. Abandoning emotion classes - Towards continuous emotion recognition with modelling of long-range dependencies. In Proceedings of the Interspeech Conference. 597--600.
Wöllmer, M., Eyben, F., Schuller, B., Douglas-Cowie, E., and Cowie, R. 2009. Data-driven clustering in emotional space for affect recognition using discriminatively trained LSTM networks. In Proceedings of Interspeech Conference. 1595--1598.
Wöllmer, M., Metallinou, A., Eyben, F., Schuller, B., and Narayanan, S. 2010a. Context-sensitive multimodal emotion recognition from speech and facial expression using bidirectional lstm modeling. In Proceedings of Interspeech Conference. 2362--2365.
Wöllmer, M., Schuller, B., Eyben, F., and Rigoll, G. 2010b. Combining long short-term memory and dynamic bayesian networks for incremental emotion-sensitive artificial listening. IEEE J. Select. Topics Signal Process. 4, 5, 867--881.
Wu, D., Parsons, T., Mower, E., and Narayanan, S. S. 2010a. Speech emotion estimation in 3d space. In Proceedings of the ICME Conference. 737--742.
Wu, D., Parsons, T., and Narayanan, S. S. 2010b. Acoustic feature analysis in speech emotion primitives estimation. In Proceedings of the Interspeech Conference. 785--788.
Paul V. Yee , Simon Haykin, Regularized radial basis functional networks: theory and applications, John Wiley & Sons, Inc., New York, NY, 2001
Zhihong Zeng , Maja Pantic , Glenn I. Roisman , Thomas S. Huang, A Survey of Affect Recognition Methods: Audio, Visual, and Spontaneous Expressions, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.31 n.1, p.39-58, January 2009[doi>10.1109/TPAMI.2008.52]
