Rare event simulation is an important area of simulation theory, producing algorithms that can significantly reduce the simulation time when analyzing problems that involve rare events. However, existing rare event simulation techniques are rather restrictive, i.e., applicable only to systems with modest complexity. In this paper, we first develop a Markov chain transformation theory that can redistribute steady-state probabilities in a finite-size discrete-time Markov chain in an arbitrary and controlled manner. We descriptively name the theoretical procedure “direct probability redistribution” (DPR). In the second part of the paper, we develop DPR theory into a simulation algorithm that uses trajectory splitting to realize the DPR effect without knowledge of the  transition probability matrix, thus allowing for easy application to systems with realistic complexity. DPR-based splitting can significantly reduce the simulation time by increasing the visitng frequency of rare states, and it avoids the problems associated with the decreasing likelihood ratio, which can be a limitation in conventional Importance Sampling techniques. The main advantage of the DPR-based simulation technique over existing splitting techniques is that DPR does not impose any restrictions on the state transitions and it provides asymptotically unbiased estimates even if the rare event set overlaps many splitting partitions. We conclude by providing examples where DPR-based simulation has been successfully applied to nontrivial queuing problems, including a system with flow  control.