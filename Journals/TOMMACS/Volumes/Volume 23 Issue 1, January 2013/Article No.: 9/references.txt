Ackley, D. H., Hinton, G., and Sejnowski, T. 1985. A learning algorithm for Boltzmann machines.Cog. Sci. 9, 147--169.
Andrieu, C. and Robert, C. 2001. Controlled MCMC for optimal sampling. Tech. rep. 0125, Cahiers de Mathematiques du Ceremade, Universite Paris-Dauphine.
Barahona, F. 1982. On the computational complexity of Ising spin glass models.J. Phys. A: Math. Gen. 15,10, 3241.
Berg, B. A. and Neuhaus, T. 1991. Multicanonical algorithms for first order phase transitions.Phys. Lett. B 267,2, 249--253.
Bertsekas, D. P. 1982. Projected Newton methods for optimization problems with simple constraints.SIAM J. Contr. Optimiz. 20,2, 221--246.
Besag, J. 1974. Spatial interaction and the statistical analysis of lattice systems.J. Roy. Statist. Soc., Ser. B 36, 192--236.
Bian, Z., Chudak, F., Macready, W. G., and Rose, G. 2011. The Ising model: Teaching an old problem new tricks. Tech. rep., D-Wave Systems.
David M. Blei , Andrew Y. Ng , Michael I. Jordan, Latent dirichlet allocation, The Journal of Machine Learning Research, 3, p.993-1022, 3/1/2003
Zdravko I. Botev , Dirk P. Kroese, Efficient Monte Carlo simulation via the generalized splitting method, Statistics and Computing, v.22 n.1, p.1-16, January   2012[doi>10.1007/s11222-010-9201-4]
Brochu, E., Cora, V. M., and de Freitas, N. 2009. A tutorial on Bayesian optimization of expensive cost functions. Tech. rep. TR-2009-023, University of British Columbia, Department of Computer Science.
Bull, A. D. 2011. Convergence rates of efficient global optimization algorithms. Tech. rep., arXiv:1101.3501v2.
F. Cérou , P. Moral , T. Furon , A. Guyader, Sequential Monte Carlo for rare event estimation, Statistics and Computing, v.22 n.3, p.795-808, May       2012[doi>10.1007/s11222-011-9231-6]
Diggle, P. J., Tawn, J. A., and Moyeed, R. A. 1998. Model-based geostatistics.J. Roy. Stat. Soc. Ser. C (Applied Statistics) 47,3, 299--350.
Duane, S., Kennedy, A. D., Pendleton, B. J., and Roweth, D. 1987. Hybrid Monte Carlo.Phys. Lett. B 195,2, 216--222.
Earl, D. J. and Deem, M. W. 2005. Parallel tempering: Theory, applications, and new perspectives.Phys. Chem. Chem. Phys. 7, 3910--3916.
Finkel, D. E. 2003.DIRECT Optimization Algorithm User Guide. Center for Research in Scientific Computation, North Carolina State University.
Freitas, N. D., Wang, Y., Mahdaviani, M., and Lang, D. 2005. Fast Krylov methods for N-body learning. InAdvances in Neural Information Processing Systems. MIT Press, 251--258.
Geyer, C. J. 1991. Markov Chain Monte Carlo maximum likelihood. InComputer Science and Statistics: Proceedings of the 23rd Symposium on the Interface. 156--163.
Girolami, M. and Calderhead, B. 2011. Riemann manifold Langevin and Hamiltonian Monte Carlo methods.J. Roy. Stat. Soc. Ser. B (Statistical Methodology) 73,2, 123--214.
Glover, F. 1989. Tabu search -- Part I.ORSA J. Comput. 1, 190--206.
Robert B. Gramacy , Herbert K. H. Lee , William G. Macready, Parameter space exploration with Gaussian process trees, Proceedings of the twenty-first international conference on Machine learning, p.45, July 04-08, 2004, Banff, Alberta, Canada[doi>10.1145/1015330.1015367]
Jim Gubernatis , Naoomichi Hatano, The multicanonical Monte Carlo method, Computing in Science and Engineering, v.2 n.2, p.95-102, March-April 2000[doi>10.1109/MCISE.2000.5427643]
Haario, H., Saksman, E., and Tamminen, J. 2001. An adaptive Metropolis algorithm.Bernoulli 7,2, 223--242.
N. Halko , P. G. Martinsson , J. A. Tropp, Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions, SIAM Review, v.53 n.2, p.217-288, May 2011[doi>10.1137/090771806]
Firas Hamze , Nando de Freitas, From fields to trees, Proceedings of the 20th conference on Uncertainty in artificial intelligence, p.243-250, July 07-11, 2004, Banff, Canada
Hamze, F. and de Freitas, N. 2005. Hot coupling: A particle approach to inference and normalization on pairwise undirected graphs.Adv. Neural Inf. Proc. Syst. 18, 491--498.
Hamze, F. and de Freitas, N. 2007. Large-flip importance sampling. InUncertainty in Artificial Intelligence. 167--174.
Hamze, F. and de Freitas, N. 2010. Intracluster moves for constrained discrete-space MCMC. InUncertainty in Artificial Intelligence. 236--243.
Hinton, G. and Salakhutdinov, R. 2006. Reducing the dimensionality of data with neural networks.Science 313,5786, 504--507.
Hoffman, M., Brochu, E., and de Freitas, N. 2011. Portfolio allocation for Bayesian optimization. InUncertainty in Artificial Intelligence. 327--336.
Holger Hoos , Thomas Sttzle, Stochastic Local Search: Foundations & Applications, Morgan Kaufmann Publishers Inc., San Francisco, CA, 2004
Hopfield, J. J. 1984. Neurons with graded response have collective computational properties like those of two-state neurons.Proc. Nat. Acad. Sci. 81,10, 3088--3092.
Hyvarinen, A., Hurri, J., and Hoyer, P. 2009.Natural Image Statistics. Springer.
Kindermann, R. and Snell, J. L. 1980.Markov Random Fields and Their Applications. American Mathematical Society.
Kück, H. and de Freitas, N. 2005. Learning about individuals from group statistics. InUncertainty in Artificial Intelligence. 332--339.
Honglak Lee , Roger Grosse , Rajesh Ranganath , Andrew Y. Ng, Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations, Proceedings of the 26th Annual International Conference on Machine Learning, p.609-616, June 14-18, 2009, Montreal, Quebec, Canada[doi>10.1145/1553374.1553453]
Jun S. Liu, Monte Carlo Strategies in Scientific Computing, Springer Publishing Company, Incorporated, 2008
Liu, J. S., Zhang, J. L., Palumbo, M. J., and Lawrence, C. E. 2003. Bayesian clustering with variable and transformation selections.Bayesian Stat. 7, 249--275.
Daniel James Lizotte, Practical bayesian optimization, University of Alberta, Edmonton, Alta., 2008
Mahendran, N., Wang, Z., Hamze, F., and de Freitas, N. 2011. Bayesian optimization for adaptive MCMC. Tech. rep., arXiv:1110.6497v1.
Marinari, E., Parisi, G., and Ruiz-Lorenzo, J. 1997. Numerical simulations of spin glass systems.Spin Glasses and Random Fields, 59--98.
Marlin, B., Swersky, K., Chen, B., and de Freitas, N. 2010. Inductive principles for restricted Boltzmann machine learning. InArtificial Intelligence and Statistics. 509--516.
Benedict C. May , Nathan Korda , Anthony Lee , David S. Leslie, Optimistic Bayesian sampling in contextual-bandit problems, The Journal of Machine Learning Research, 13, p.2069-2106, 3/1/2012
Roland Memisevic , Geoffrey E. Hinton, Learning to represent spatial transformations with factored higher-order boltzmann machines, Neural Computation, v.22 n.6, p.1473-1492, June 2010[doi>10.1162/neco.2010.01-09-953]
Močkus, J. 1982. The Bayesian approach to global optimization. InSystem Modeling and Optimization. Vol. 38. Springer Berlin/Heidelberg, 473--481.
Munoz, J. D., Novotny, M. A., and Mitchell, S. J. 2003. Rejection-free Monte Carlo algorithms for models with continuous degrees of freedom.Phys. Rev. E 67.
Neal, R. M. 2010. MCMC using Hamiltonian dynamics.Handbook of Markov Chain Monte Carlo 54, 113--162.
Newman, M. and Barkema, G. 1999.Monte Carlo Methods in Statistical Physics. Oxford University Press.
Michael A. Osborne , Roman Garnett , Stephen J. Roberts, Active Data Selection for Sensor Networks with Faults and Changepoints, Proceedings of the 2010 24th IEEE International Conference on Advanced Information Networking and Applications, p.533-540, April 20-23, 2010[doi>10.1109/AINA.2010.36]
Ranzato, M., Mnih, V., and Hinton, G. 2010. How to generate realistic images using gated MRF’s. InAdvances in Neural Information Processing Systems. 2002--2010.
Carl Edward Rasmussen , Christopher K. I. Williams, Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning), The MIT Press, 2005
Christian P. Robert , George Casella, Monte Carlo Statistical Methods (Springer Texts in Statistics), Springer-Verlag New York, Inc., Secaucus, NJ, 2005
Roberts, G. O. and Rosenthal, J. S. 2009. Examples of adaptive MCMC.J. Computat. Graph. Stat. 18,2, 349--367.
Rosenbluth, M. N. and Rosenbluth, A. W. 1955. Monte Carlo calculation of the average extension of molecular chains.J. Chem. Phys. 23, 356--359.
Rue, H., Martino, S., and Chopin, N. 2009. Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations.Journal Of The Royal Statistical Society Series B 71,2, 319--392.
Ruslan Salakhutdinov , Iain Murray, On the quantitative analysis of deep belief networks, Proceedings of the 25th international conference on Machine learning, p.872-879, July 05-09, 2008, Helsinki, Finland[doi>10.1145/1390156.1390266]
Santner, T. J., Williams, B., and Notz, W. 2003.The Design and Analysis of Computer Experiments. Springer.
Schonlau, M., Welch, W. J., and Jones, D. R. 1998. Global versus local search in constrained optimization of computer models.Lecture Notes-Monograph Series 34, 11--25.
Siepmann, J. I. and Frenkel, D. 1992. Configurational bias Monte Carlo: a new sampling scheme for flexible chains.Molec. Phys.: An Int. J. Interface Between Chem. Phys. 75,1, 59--70.
P. Smolensky, Information processing in dynamical systems: foundations of harmony theory, Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations, MIT Press, Cambridge, MA, 1986
Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. 2010. Gaussian process optimization in the bandit setting: No regret and experimental design. InProceedings of the International Conference on Machine Learning.
Swendsen, R. H. and Wang, J.-S. 1987. Nonuniversal critical dynamics in Monte Carlo simulations.Phys. Rev. Lett. 58,2, 86--88.
Swersky, K., Chen, B., Marlin, B., and de Freitas, N. 2010. A tutorial on stochastic approximation algorithms for training restricted Boltzmann machines and deep belief nets. InProceedings of the Information Theory and Applications Workshop. 1--10.
Shien-Shin Tham , Arnaud Doucet , Kotagiri Ramamohanarao, Sparse Bayesian Learning for Regression and Classification using Markov Chain Monte Carlo, Proceedings of the Nineteenth International Conference on Machine Learning, p.634-641, July 08-12, 2002
Matti Vihola, Short communication: Grapham: Graphical models with adaptive random walk Metropolis algorithms, Computational Statistics & Data Analysis, v.54 n.1, p.49-54, January, 2010[doi>10.1016/j.csda.2009.09.001]
Wang, F. and Landau, D. P. 2001. Efficient, multiple-range random walk algorithm to calculate the density of states.Phys. Rev. Lett. 86, 2050--2053.
D. J. A. Welsh, Complexity: knots, colourings and counting, Cambridge University Press, New York, NY, 1993
Ye, K. Q. 1998. Orthogonal column Latin hypercubes and their application in computer experiments.J. ASA 93,444, 1430--1439.
