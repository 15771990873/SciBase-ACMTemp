Pieter Abbeel , Andrew Y. Ng, Apprenticeship learning via inverse reinforcement learning, Proceedings of the twenty-first international conference on Machine learning, p.1, July 04-08, 2004, Banff, Alberta, Canada[doi>10.1145/1015330.1015430]
Aguirregabiria, V. and Mira, P. 2002. Swapping the nested fixed point algorithm: A class of estimators for discrete Markov decision models.Econometrica 70, 1519--1543.
Albert, J. and Chib, S. 1993. Bayesian analysis of binary and polychotomous response data.J. Amer. Statis. Assn. 88, 422, 669--679.
Bertsekas, D. 2005.Dynamic Programming and Optimal ControlVol. 1. 3rd Ed. Athena Scientific, Belmont, MA.
Dimitri P. Bertsekas, Dynamic Programming and Optimal Control, Vol. II, Athena Scientific, 2007
Dimitri P. Bertsekas , John N. Tsitsiklis, Neuro-Dynamic Programming, Athena Scientific, 1996
Chopin, N. 2002. A sequential particle filter method for static models.Biometrika 89, 3, 539--552.
Nicolas Chopin, Fast simulation of truncated Gaussian distributions, Statistics and Computing, v.21 n.2, p.275-288, April     2011[doi>10.1007/s11222-009-9168-1]
Adam Coates , Pieter Abbeel , Andrew Y. Ng, Apprenticeship learning for helicopter control, Communications of the ACM, v.52 n.7, July 2009[doi>10.1145/1538788.1538812]
Del Moral, P., Doucet, A., and Jasra, A. 2006. Sequential Monte Carlo samplers.Roy. Statis. Soc. Ser. B 68, 3, 411--436.
Geweke, J. and Keane, M. 1996. Bayesian inference for dynamic discrete choice models without the need for dynamic programming. Working Paper 564, Federal Reserve Bank of Minneapolis.
Geweke, J. and Keane, M. 2000. Bayesian inference for dynamic discrete choice models without the need for dynamic programming. InSimulation-Based Inference in Econometrics: Methods and Applications, Cambridge University Press, Cambridge, UK, 100--131.
Geweke, J., Keane, M., and Runkle, D. 1994. Alternative computational approaches to inference in the multinomial probit model. InReview of Economics and Statistics, 609--632.
Gotz, G. and McCall, J. 1980. Estimation in sequential decision making models: A methodological note.Econ. Lett. 6, 131--136.
Hobert, J. 2011. The data augmentation algorithm: Theory and methodology. InHandbook of Markov Chain Monte Carlo, Chapman & Hall/CRC Handbooks of Modern Statistical Methods. 253--293.
Hobert, J. and Marchev, D. 2008. A theoretical comparison of data augmentation, marginal augmentation and PX-DA algorithms.Ann. Statis. 36, 2, 532--554.
Hotz, J. and Miller, R. 1993. Conditional choice probabilities and estimation of dynamic models.Rev. Econ. Stud. 60, 497--529.
Imai, K. and van Dyk, D. 2005. A Bayesian analysis of the multinomial probit model using marginal data augmentation.J. Econ. 124, 311--334.
Imai, S., Jain, N., and Ching, A. 2009. Bayesian estimation of dynamic discrete choice models.Econometrica 77, 6, 1865--1899.
Liu, J. and Wu, Y. 1999. Parameter expansion for data augmentation.J. Amer. Statis. Assn. 94, 1264--1274.
McCulloch, R., Polson, N., and Rossi, P. 2000. A Bayesian analysis of the multinomial probit model with fully identified parameters.J. Economet. 99, 172--193.
McCulloch, R. and Rossi, P. 1994. An exact likelihood analysis of the multinomial probit model.J. Economet. 64, 207--240.
Meng, X.-L. and van Dyk, D. 1999. Seeking efficient data augmentation schemes via conditional and marginal augmentation.Biometrika 86, 301--320.
Andrew Y. Ng , Stuart J. Russell, Algorithms for Inverse Reinforcement Learning, Proceedings of the Seventeenth International Conference on Machine Learning, p.663-670, June 29-July 02, 2000
Agostino Nobile, A hybrid Markov chain for the Bayesian analysis of the multinomial probit model, Statistics and Computing, v.8 n.3, p.229-242, August 1998[doi>10.1023/A:1008905311214]
Roy, V. 2012. Spectral analytic comparisons for data augmentation.Statis. Probab. Lett. 82, 1, 103--108.
Rust, J. 1987. Optimal replacement of GMC bus engines: An empirical model of Harold Zurcher.Econometrica 55, 999--1033.
John Rust, Maximum likelihood estimation of discrete control processes, SIAM Journal on Control and Optimization, v.26 n.5, p.1006-1024, September 1988[doi>10.1137/0326056]
Nestor A. Schmajuk , B. Silvano Zanutto, Escape, avoidance, and imitation: a neural network approach, Adaptive Behavior, v.6 n.1, p.63-129, June 1997[doi>10.1177/105971239700600103]
Schweitzer, P. J. and Seidmann, A. 1985. Generalized polynomial approximations in markovian decision processes.J. Math. Anal. Appl. 110, 2, 568--582.
Tanner, M. and Wong, W. 1987. The calculation of posterior distributions by data augmentation (with discussion).J. Amer. Stat. Assn. 82, 528--550.
Tsitsiklis, J. and Roy, B. V. 1994. Feature-based methods for large scale dynamic programming. Tech. rep. LIDS-P 2277, Laboratory for Information and Decision Systems. Massachusetts Institute of Technology.
Watkins, C. 1987.Learning from delayed rewards. Ph.D thesis, University of Cambridge.
Wolpin, K. 1984. An estimable dynamic stochastic model of fertility and child mortality.J. Polit. Econ. 92, 852--874.
