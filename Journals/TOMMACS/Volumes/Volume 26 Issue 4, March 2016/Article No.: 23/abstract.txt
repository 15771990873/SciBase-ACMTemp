Given the continued integration of intermittent renewable generators in electrical power grids, connection overloads are of increasing concern for grid operators. The risk of an overload due to injection variability can be described mathematically as a barrier-crossing probability of a function of a multidimensional stochastic process. Crude Monte Carlo is a well-known technique to estimate probabilities, but it may be computationally too intensive in this case as typical modern power grids rarely exhibit connection overloads. In this article, we derive an approximate rate function for the overload probability using results from large deviations theory. Based on this large deviations approximation, we apply a rare event simulation technique called splitting to estimate overload probabilities more efficiently than Crude Monte Carlo simulation.We show on example power grids with up to 11 stochastic power injections that for a fixed accuracy, Crude Monte Carlo would require tens to millions as many samples as the proposed splitting technique required. We investigate the balance between accuracy and workload of three splitting schemes, each based on a different approximation of the rate function. We justify the workload increase of large-deviation-based splitting compared to naive splitting—that is, splitting based on merely the Euclidean distance to the rare event set. For a fixed accuracy, naive splitting requires over 60 times as much CPU time as large-deviation-based splitting, illustrating its computational advantage. In these examples, naive splitting—unlike large-deviation-based splitting—requires even more CPU time than CMC simulation, illustrating its pitfall.