There have been many proposals for randomizations of digital nets. Some of those proposals greatly reduce the computational burden of random scrambling. This article compares the sampling variance under different scrambling methods. Some scrambling methods adversely affect the variance, even to the extent of deteriorating the rate at which variance converges to zero. Surprisingly, a new scramble proposed here, has the effect of improving the rate at which the variance converges to zero, but so far, only for one dimensional integrands. The mean squaredL2discrepancy is commonly used to study scrambling schemes. In this case, it does not distinguish among some scrambles with different convergence rates for the variance.