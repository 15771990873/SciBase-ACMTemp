LetX= {X(t)}t ≥ 0be a stochastic process with a stationary versionX*. It is investigated when it is possible to generate by simulation a versionX˜ofXwith lower initial bias thanXitself, in the sense that eitherX˜is strictly stationary (has the same distribution asX*) or the distribution ofX˜is close to the distribution ofX*. Particular attention is given to regenerative processes and Markov processes with a finite, countable, or general state space. The results are both positive and negative, and indicate that the tail of the distribution of the   cycle length&tgr;plays a critical role. The negative results essentially state that without some information on this tail, no a priori computable bias reduction is possible; in particular, this is the case for the class of all Markov processes with a countably infinite state space. On the contrary, the positive results give algorithms for simulatingX˜for various classes of processes with some special structure on&tgr;. In particular, one can generateX˜as strictly stationary for finite state Markov chains, Markov chains satisfying a Doeblin-type minorization, and regenerative processes with the cycle length&tgr;bounded or having a stationary age distribution that can be generated by   simulation.