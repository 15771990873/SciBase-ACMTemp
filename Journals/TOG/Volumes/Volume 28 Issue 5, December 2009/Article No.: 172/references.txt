Adolphs, R. 2002. Neural systems for recognizing emotion.Current Opinion in Neurobiology 12, 2, 169--177.
Albrecht, I., Haber, J., and peter Seidel, H. 2002. Automatic generation of non-verbal facial expressions from speech. InComputer Graphics International, 283--293.
Okan Arikan , D. A. Forsyth, Interactive motion generation from examples, ACM Transactions on Graphics (TOG), v.21 n.3, July 2002[doi>10.1145/566654.566606]
Jernej Barbič , Alla Safonova , Jia-Yu Pan , Christos Faloutsos , Jessica K. Hodgins , Nancy S. Pollard, Segmenting motion capture data into distinct behaviors, Proceedings of Graphics Interface 2004, p.185-194, May 17-19, 2004, London, Ontario, Canada
Beskow, J. 2003.Talking Heads - Models and Applications for Multimodal Speech Synthesis. PhD thesis, KTH Stockholm.
Boersma, P. 1993. Accurate short-term analysis of the fundamental frequency and the harmonics-to-noise ratio of a sampled sound. InProceedings of the Institute of Phonetic Sciences, vol. 17, 97--110.
Boersma, P. 2001. Praat, a system for doing phonetics by computer.Glot International 5, 9--10, 314--345.
Matthew Brand, Voice puppetry, Proceedings of the 26th annual conference on Computer graphics and interactive techniques, p.21-28, July 1999[doi>10.1145/311535.311537]
Christoph Bregler , Michele Covell , Malcolm Slaney, Video Rewrite: driving visual speech with audio, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, p.353-360, August 1997[doi>10.1145/258734.258880]
Justine Cassell , Catherine Pelachaud , Norman Badler , Mark Steedman , Brett Achorn , Tripp Becket , Brett Douville , Scott Prevost , Matthew Stone, Animated conversation: rule-based generation of facial expression, gesture & spoken intonation for multiple conversational agents, Proceedings of the 21st annual conference on Computer graphics and interactive techniques, p.413-420, July 1994[doi>10.1145/192161.192272]
Justine Cassell , Hannes Högni Vilhjálmsson , Timothy Bickmore, BEAT: the Behavior Expression Animation Toolkit, Proceedings of the 28th annual conference on Computer graphics and interactive techniques, p.477-486, August 2001[doi>10.1145/383259.383315]
Justine Cassell, Embodied conversational interface agents, Communications of the ACM, v.43 n.4, p.70-78, April 2000[doi>10.1145/332051.332075]
Erika Chuang , Christoph Bregler, Mood swings: expressive speech animation, ACM Transactions on Graphics (TOG), v.24 n.2, p.331-347, April 2005[doi>10.1145/1061347.1061355]
Tony Ezzat , Gadi Geiger , Tomaso Poggio, Trainable videorealistic speech animation, Proceedings of the 29th annual conference on Computer graphics and interactive techniques, July 23-26, 2002, San Antonio, Texas[doi>10.1145/566570.566594]
Ajo Fod , Maja J. Matarić , Odest Chadwicke Jenkins, Automated Derivation of Primitives for Movement Classification, Autonomous Robots, v.12 n.1, p.39-54, January 2002[doi>10.1023/A:1013254724861]
Björn Hartmann , Maurizio Mancini , Catherine Pelachaud, Formational Parameters and Adaptive Prototype Instantiation for MPEG-4 Compliant Gesture Synthesis, Proceedings of the Computer Animation, p.111, June 19-21, 2002
Carlos Jensen , Shelly D. Farnham , Steven M. Drucker , Peter Kollock, The effect of communication modality on cooperation in online environments, Proceedings of the SIGCHI conference on Human Factors in Computing Systems, p.470-477, April 01-06, 2000, The Hague, The Netherlands[doi>10.1145/332040.332478]
Ju, E., and Lee, J. 2008. Expressive facial gestures from motion capture data.Computer Graphics Forum 27, 2, 381--388.
Kendon, A. 2004.Gesture - Visible Action as Utterance. Cambridge University Press, New York, NY, USA.
Kipp, M., Neff, M., and Albrecht, I. 2007. An annotation scheme for conversational gestures: how to economically capture timing and form.Language Resources and Evaluation 41, 3--4 (December), 325--339.
Stefan Kopp , Ipke Wachsmuth, Synthesizing multimodal utterances for conversational agents: Research Articles, Computer Animation and Virtual Worlds, v.15 n.1, p.39-52, March 2004[doi>10.1002/cav.v15:1]
Lucas Kovar , Michael Gleicher , Frédéric Pighin, Motion graphs, ACM Transactions on Graphics (TOG), v.21 n.3, July 2002[doi>10.1145/566654.566605]
Krauss, R. M., Dushay, R. A., Chen, Y., and Rauscher, F. 1995. The communicative value of conversational hand gestur.Journal of Experimental Social Psychology 31, 6, 533--552.
Jehee Lee , Jinxiang Chai , Paul S. A. Reitsma , Jessica K. Hodgins , Nancy S. Pollard, Interactive control of avatars animated with human motion data, ACM Transactions on Graphics (TOG), v.21 n.3, July 2002[doi>10.1145/566654.566607]
Yan Li , Heung-Yeung Shum, Learning dynamic audio-visual mapping with input-output Hidden Markov models, IEEE Transactions on Multimedia, v.8 n.3, p.542-549, June 2006[doi>10.1109/TMM.2006.870732]
Yan Li , Tianshu Wang , Heung-Yeung Shum, Motion texture: a two-level statistical model for character motion synthesis, Proceedings of the 29th annual conference on Computer graphics and interactive techniques, July 23-26, 2002, San Antonio, Texas[doi>10.1145/566570.566604]
Loehr, D. 2004.Gesture and Intonation. PhD thesis, Georgetown University.
Maeran, O., Piuri, V., and Storti Gajani, G. 1997. Speech recognition through phoneme segmentation and neural classification.Instrumentation and Measurement Technology Conference, 1997. IMTC/97. Proceedings. 'Sensing, Processing, Networking.', IEEE 2(May), 1215--1220.
A. Majkowska , V. B. Zordan , P. Faloutsos, Automatic splicing for hand and body animations, Proceedings of the 2006 ACM SIGGRAPH/Eurographics symposium on Computer animation, September 02-04, 2006, Vienna, Austria
McNeill, D. 1992.Hand and Mind: What Gestures Reveal About Thought. University Of Chicago Press.
McNeill, D. 2005.Gesture and Thought. University Of Chicago Press, November.
Montepare, J., Koff, E., Zaitchik, D., and Albert, M. 1999. The use of body movements and gestures as cues to emotions in younger and older adults.Journal of Nonverbal Behavior 23, 2, 133--152.
Louis-Philippe Morency , Candace Sidner , Christopher Lee , Trevor Darrell, Head gestures for perceptual interfaces: The role of context in improving recognition, Artificial Intelligence, v.171 n.8-9, p.568-585, June, 2007[doi>10.1016/j.artint.2007.04.003]
Meinard Müller , Tido Röder , Michael Clausen, Efficient content-based retrieval of motion capture data, ACM SIGGRAPH 2005 Papers, July 31-August 04, 2005, Los Angeles, California[doi>10.1145/1186822.1073247]
Michael Neff , Michael Kipp , Irene Albrecht , Hans-Peter Seidel, Gesture modeling and animation based on a probabilistic re-creation of speaker style, ACM Transactions on Graphics (TOG), v.27 n.1, p.1-24, March 2008[doi>10.1145/1330511.1330516]
Junho Park , Hanseok Ko, Real-Time Continuous Phoneme Recognition System Using Class-Dependent Tied-Mixture HMM With HBT Structure for Speech-Driven Lip-Sync, IEEE Transactions on Multimedia, v.10 n.7, p.1299-1306, November 2008[doi>10.1109/TMM.2008.2004908]
Ken Perlin , Athomas Goldberg, Improv: a system for scripting interactive actors in virtual worlds, Proceedings of the 23rd annual conference on Computer graphics and interactive techniques, p.205-216, August 1996[doi>10.1145/237170.237258]
Ken Perlin, Layered compositing of facial expression, ACM SIGGRAPH 97 Visual Proceedings: The art and interdisciplinary programs of SIGGRAPH '97, p.226-227, August 03-08, 1997, Los Angeles, California, USA[doi>10.1145/259081.259313]
Rabiner, L. 1989. A tutorial on hidden markov models and selected applications in speech recognition.Proceedings of the IEEE 77, 2, 257--286.
Ramshaw, L. A., and Marcus, M. P. 1995. Text chunking using transformation-based learning. InProceedings of the Third Workshop on Very Large Corpora, 82--94.
Sargin, M. E., Erzin, E., Yemez, Y., Tekalp, A. M., Erdem, A., Erdem, C., and Ozkan, M. 2007. Prosody-driven head-gesture animation. InICASSP '07: IEEE International Conference on Acoustics, Speech, and Signal Processing.
Scherer, K. R., Banse, R., Wallbott, H. G., and Goldbeck, T. 1991. Vocal cues in emotion encoding and decoding.Motivation and Emotion 15, 2, 123--148.
Schröder, M. 2004.Speech and Emotion Research: An overview of research frameworks and a dimensional approach to emotional speech synthesis. PhD thesis, Phonus 7, Research Report of the Institute of Phonetics, Saarland University.
Ken Shoemake, Animating rotation with quaternion curves, Proceedings of the 12th annual conference on Computer graphics and interactive techniques, p.245-254, July 1985[doi>10.1145/325334.325242]
Eftychios Sifakis , Andrew Selle , Avram Robinson-Mosher , Ronald Fedkiw, Simulating speech with a physics-based facial muscle model, Proceedings of the 2006 ACM SIGGRAPH/Eurographics symposium on Computer animation, September 02-04, 2006, Vienna, Austria
Matthew Stone , Doug DeCarlo , Insuk Oh , Christian Rodriguez , Adrian Stere , Alyssa Lees , Chris Bregler, Speaking with hands: creating animated conversational characters from recordings of human performance, ACM SIGGRAPH 2004 Papers, August 08-12, 2004, Los Angeles, California[doi>10.1145/1186562.1015753]
Terken, J. 1991. Fundamental frequency and perceived prominence of accented syllables.The Journal of the Acoustical Society of America 89, 4, 1768--1777.
Adrien Treuille , Yongjoon Lee , Zoran Popović, Near-optimal character animation with continuous control, ACM SIGGRAPH 2007 papers, August 05-09, 2007, San Diego, California[doi>10.1145/1275808.1276386]
Wallbot, H. G. 1998. Bodily expression of emotion.European Journal of Social Psychology 28, 6, 879--896.
Jing Wang , Bobby Bodenheimer, Synthesis and evaluation of linear motion transitions, ACM Transactions on Graphics (TOG), v.27 n.1, p.1-15, March 2008[doi>10.1145/1330511.1330512]
Ward, J. H. 1963. Hierarchical grouping to optimize an objective function.Journal of the American Statistical Association 58, 301, 236--244.
Xue, J., Borgstrom, J., Jiang, J., Bernstein, L., and Alwan, A. 2006. Acoustically-driven talking face synthesis using dynamic bayesian networks.IEEE International Conference on Multimedia and Expo(July), 1165--1168.
