Box2D, 2015. Box2d: A 2d physics engine for games, Jan. http://box2d.org.
Lucian Busoniu , Robert Babuska , Bart De Schutter , Damien Ernst, Reinforcement Learning and Dynamic Programming Using Function Approximators, CRC Press, Inc., Boca Raton, FL, 2010
Stelian Coros , Philippe Beaudoin , Kang Kang Yin , Michiel van de Pann, Synthesis of constrained walking skills, ACM Transactions on Graphics (TOG), v.27 n.5, December 2008[doi>10.1145/1409060.1409066]
Stelian Coros , Philippe Beaudoin , Michiel van de Panne, Robust task-based control policies for physics-based characters, ACM Transactions on Graphics (TOG), v.28 n.5, December 2009[doi>10.1145/1618452.1618516]
Stelian Coros , Philippe Beaudoin , Michiel van de Panne, Generalized biped walking control, ACM Transactions on Graphics (TOG), v.29 n.4, July 2010[doi>10.1145/1778765.1781156]
Stelian Coros , Andrej Karpathy , Ben Jones , Lionel Reveret , Michiel van de Panne, Locomotion skills for simulated quadrupeds, ACM Transactions on Graphics (TOG), v.30 n.4, July 2011[doi>10.1145/2010324.1964954]
Martin de Lasa , Igor Mordatch , Aaron Hertzmann, Feature-based locomotion controllers, ACM Transactions on Graphics (TOG), v.29 n.4, July 2010[doi>10.1145/1778765.1781157]
Yaakov Engel , Shie Mannor , Ron Meir, Reinforcement learning with Gaussian processes, Proceedings of the 22nd international conference on Machine learning, p.201-208, August 07-11, 2005, Bonn, Germany[doi>10.1145/1102351.1102377]
Fonteneau, R., Murphy, S. A., Wehenkel, L., and Ernst, D. 2013. Batch mode reinforcement learning based on the synthesis of artificial trajectories.Annals of operations research 208, 1, 383--416.
T. Geijtenbeek , N. Pronost, Interactive Character Animation Using Simulated Physics: A State-of-the-Art Review, Computer Graphics Forum, v.31 n.8, p.2492-2515, December 2012[doi>10.1111/j.1467-8659.2012.03189.x]
Sehoon Ha , C. Karen Liu, Iterative Training of Dynamic Skills Inspired by Human Coaching Techniques, ACM Transactions on Graphics (TOG), v.34 n.1, p.1-11, November 2014[doi>10.1145/2682626]
Sehoon Ha , Yuting Ye , C. Karen Liu, Falling and landing motion control for character animation, ACM Transactions on Graphics (TOG), v.31 n.6, November 2012[doi>10.1145/2366145.2366174]
Hansen, N. 2006. The cma evolution strategy: A comparing review. InTowards a New Evolutionary Computation, 75--102.
Sumit Jain , Yuting Ye , C. Karen Liu, Optimization-based interactive motion synthesis, ACM Transactions on Graphics (TOG), v.28 n.1, p.1-12, January 2009[doi>10.1145/1477926.1477936]
Taesoo Kwon , Jessica Hodgins, Control systems for human running using an inverted pendulum model and a reference motion capture sequence, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, July 02-04, 2010, Madrid, Spain
Lange, S., Gabel, T., and Riedmiller, M. 2012. Batch reinforcement learning. InReinforcement Learning.Springer, 45--73.
Jehee Lee , Kang Hoon Lee, Precomputing avatar behavior from human motion data, Graphical Models, v.68 n.2, p.158-174, March 2006[doi>10.1016/j.gmod.2005.03.004]
Yongjoon Lee , Seong Jae Lee , Zoran Popović, Compact character controllers, ACM Transactions on Graphics (TOG), v.28 n.5, December 2009[doi>10.1145/1618452.1618515]
Yongjoon Lee , Kevin Wampler , Gilbert Bernstein , Jovan Popović , Zoran Popović, Motion fields for interactive character locomotion, ACM Transactions on Graphics (TOG), v.29 n.6, December 2010[doi>10.1145/1882261.1866160]
Yoonsang Lee , Sungeun Kim , Jehee Lee, Data-driven biped control, ACM Transactions on Graphics (TOG), v.29 n.4, July 2010[doi>10.1145/1778765.1781155]
Levine, S., and Koltun, V. 2014. Learning complex neural network policies with trajectory optimization. InProc. ICML 2014, 829--837.
Sergey Levine , Jack M. Wang , Alexis Haraux , Zoran Popović , Vladlen Koltun, Continuous character control with low-dimensional embeddings, ACM Transactions on Graphics (TOG), v.31 n.4, p.1-10, July 2012[doi>10.1145/2185520.2185524]
Libin Liu , KangKang Yin , Michiel van de Panne , Baining Guo, Terrain runner: control, parameterization, composition, and planning for highly dynamic motions, ACM Transactions on Graphics (TOG), v.31 n.6, November 2012[doi>10.1145/2366145.2366173]
Adriano Macchietto , Victor Zordan , Christian R. Shelton, Momentum control for balance, ACM Transactions on Graphics (TOG), v.28 n.3, August 2009[doi>10.1145/1531326.1531386]
James McCann , Nancy Pollard, Responsive characters from motion fragments, ACM Transactions on Graphics (TOG), v.26 n.3, July 2007[doi>10.1145/1276377.1276385]
Igor Mordatch , Martin de Lasa , Aaron Hertzmann, Robust physics-based locomotion using low-dimensional planning, ACM Transactions on Graphics (TOG), v.29 n.4, July 2010[doi>10.1145/1778765.1778808]
Muja, M., and Lowe, D. G. 2009. Fast approximate nearest neighbors with automatic algorithm configuration. InVISAPP (1), 331--340.
Dirk Ormoneit , Śaunak Sen, Kernel-Based Reinforcement Learning, Machine Learning, v.49 n.2-3, p.161-178, November-December 2002[doi>10.1023/A:1017928328829]
Marc H. Raibert , Jessica K. Hodgins, Animation of dynamic legged locomotion, ACM SIGGRAPH Computer Graphics, v.25 n.4, p.349-358, July 1991[doi>10.1145/127719.122755]
Ross, S., Gordon, G., and Bagnell, A. 2011. A reduction of imitation learning and structured prediction to noregret online learning.Journal of Machine Learning Research 15, 627--635.
A. James Stewart , James F. Cremer, Beyond keyframing: an algorithmic approach to animation, Proceedings of the conference on Graphics interface '92, p.273-281, September 1992, Vancouver, British Columbia, Canada
Jie Tan , Yuting Gu , C. Karen Liu , Greg Turk, Learning bicycle stunts, ACM Transactions on Graphics (TOG), v.33 n.4, July 2014[doi>10.1145/2601097.2601121]
Adrien Treuille , Yongjoon Lee , Zoran Popović, Near-optimal character animation with continuous control, ACM Transactions on Graphics (TOG), v.26 n.3, July 2007[doi>10.1145/1276377.1276386]
van Hasselt, H., and Wiering, M. A. 2007. Reinforcement learning in continuous action spaces. InApproximate Dynamic Programming and Reinforcement Learning, 2007. ADPRL 2007. IEEE International Symposium on, IEEE, 272--279.
van Hasselt, H. 2012. Reinforcement learning in continuous state and action spaces. InReinforcement Learning.Springer, 207--251.
Jack M. Wang , David J. Fleet , Aaron Hertzmann, Optimizing walking controllers, ACM Transactions on Graphics (TOG), v.28 n.5, December 2009[doi>10.1145/1618452.1618514]
Xiaolin Wei , Jianyuan Min , Jinxiang Chai, Physically valid statistical models for human motion generation, ACM Transactions on Graphics (TOG), v.30 n.3, p.1-10, May 2011[doi>10.1145/1966394.1966398]
Yuting Ye , C. Karen Liu, Optimal feedback control for character animation using an abstract model, ACM Transactions on Graphics (TOG), v.29 n.4, July 2010[doi>10.1145/1778765.1778811]
KangKang Yin , Kevin Loken , Michiel van de Panne, SIMBICON: simple biped locomotion control, ACM Transactions on Graphics (TOG), v.26 n.3, July 2007[doi>10.1145/1276377.1276509]
KangKang Yin , Stelian Coros , Philippe Beaudoin , Michiel van de Panne, Continuation methods for adapting simulated skills, ACM Transactions on Graphics (TOG), v.27 n.3, August 2008[doi>10.1145/1360612.1360680]
Victor Brian Zordan , Jessica K. Hodgins, Motion capture-driven simulations that hit and react, Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium on Computer animation, July 21-22, 2002, San Antonio, Texas[doi>10.1145/545261.545276]
