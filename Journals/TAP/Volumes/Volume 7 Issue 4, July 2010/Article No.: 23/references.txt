Abelin, A. 2007. Emotional McGurk effectâ€”An experiment. In Proceedings of the 7th International Conference on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems.
Brainard, D. H. 1997. The psychophysics toolbox. Spatial Vis. 10, 433--436.
Chion, M. 1994. Audio-Vision: Sound on Screen. Columbia University Press.
Dixon, N. F. and Spitz, L. 1980. The detection of auditory visual desynchrony. Percep. 9, 719--721.
Ekman, P., Friesen, W. V., and Ellsworth, P. 1972. Emotion in the Human Face: Guidelines for Research and an Integration of Findings. Pergamon Press.
Garofolo, J., Lamel, L., Fisher, W., Fiscus, F., Pallett, D., and Dahlgren, N. 1993. Darpa timit acoustic-phonetic continuous speech corpus. Published on CD-ROM: NIST Speech Disc 1-1.1, Oct. 1990 NISTIR 4930, National Institute of Standards and Technology, Gaithersburg, MD.
Grant, K. W. and Greenberg, S. 2001. Speech intelligibility derived from asynchronous processing of auditory-visual information. In Proceedings of the Auditory-Visual Speech Processing Conference.
Grant, K. W., van Wassenhove, V., and Poeppel, D. 2003. Discriminatory of auditory-visual synchrony. In Proceedings of the Auditory-Visual Speech Processing Conference.
Huang, E., Sisk, J., Kirk, T., Coryell, G., and Stewart, J. 2007. Searching for an ideal live video streaming technology. http://www.iupui.edu/~nmstream/live/introduction.php.
Lass, N. J. and Harvey, L. A. 1976. An investigation of speaker photograph identification. J. Acoust. Soc. Amer. 59, 1232--1236.
Mason, A. and Salmon, R. 2008. Factors affecting perception of audio-video synchronization in television. In Proceedings of the Audio Engineering Society Convention. Audio Engineering Society.
McGurk, H. and MacDonald, J. 1976. Hearing lips and seeing voices. Nature 264, 746--748.
Munhall, K. G., Gribble, P., Sacco, L., and Ward, M. 1996. Temporal constraints on the McGurk effect. Percept. Psychophys. 58, 351--362.
Pelli, D. G. 1997. The videotoolbox software for visual psychophysics: Transforming numbers into movies. Spatial Vis. 10, 437--442.
Phillips, G. 2010. Personal communication.
Sakamoto, S., Tanaka, A., Tsumura, K., and Suzuki, Y. 2007. Effect of speed difference between time-expanded speech and talker's moving image on word or sentence intelligibility. In Proceedings of the Auditory-Visual Speech Processing Conference.
Spill, H. 2010. Personal communication.
Sumby, W. H. and Pollack, I. 1954. Visual contribution to speech intelligibility in noise. J. Acoust. Soc. Amer. 26, 212--215.
Summerfield, Q. 1987. Some Preliminaries to a Comprehensive Account of Audio-Visual Speech Perception. Lawrence Erlbaum Associates, London.
Summerfield, Q. 1992. Lip reading and audio-visual speech perception. Philosoph. Trans. Biol. Sci. 335, 1273, 71--78.
Theobald, B.-J., Bangham, A., Matthews, I., and Cawley, G. 2003. Evaluation of a talking head based on appearance models. In Proceedings of the 7th International Conference on Audio Visual Speech Processing.
Tinwell, A. and Grimshaw, M. 2009. Survival horror games: An uncanny modality. In Thinking After Dark.
Tuckman, J., Chrisafis, A., Hooper, J., Watts, J., Smee, J., and Ramesh, R. 2006. To dub you have to be as good an actor. Or better. http://www.guardian.co.uk/film/2006/nov/03/3.
van Wassenhove, V., Grant, K. W., and Poeppel, D. 2007. Temporal window of integration in bimodal speech. Neuropsychologica 45, 3, 598--607.
