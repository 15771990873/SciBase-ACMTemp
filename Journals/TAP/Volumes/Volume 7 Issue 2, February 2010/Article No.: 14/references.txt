Bigand, E., Vieillard, S., Madurell, F., Marozeau, J., and Dacquet, A. 2005. Multidimensional scaling of emotional responses to music: The effect of musical expertise and of the duration of the excerpts. Cogn. Emotion 19, 8, 1113--1139.
Roberto Bresin , Anders Friberg, Emotional Coloring of Computer-Controlled Music Performances, Computer Music Journal, v.24 n.4, p.44-63, December 2000[doi>10.1162/014892600559515]
Antonio Camurri , Gualtiero Volpe , Giovanni De Poli , Marc Leman, Communicating Expressiveness and Affect in Multimodal Interactive Systems, IEEE MultiMedia, v.12 n.1, p.43-53, January 2005[doi>10.1109/MMUL.2005.2]
Canazza, S., De Poli, G., Drioli, C., Rodá, A., and Vidolin, A. 2004. Modeling and control of expressiveness in music performance. Proc. IEEE 92, 4, 286--701.
Canazza, S., De Poli, G., Rodá, A., and Vidolin, A. 2003. An abstract control space for communication of sensory expressive intentions in music performance. J. New Music Res. 32, 3, 281--294.
Carroll, J. and Chang, J. 1970. Analysis of individual differences in multidimensional scaling via an n-way generalization of “eckart-young” decomposition. Psychometrika 35, 283--319.
Diane Chi , Monica Costa , Liwei Zhao , Norman Badler, The EMOTE model for effort and shape, Proceedings of the 27th annual conference on Computer graphics and interactive techniques, p.173-182, July 2000[doi>10.1145/344779.352172]
Dannenberg, R., Thom, B., and Watson, D. 1997. A machine learning approach to musical style recognition. In Proceedings of the International Computer Music Conference (ICMC'97). CMA, San Francisco, 344--347.
De Poli, G. 2004. Methodologies for expressiveness modelling of and for music performance. J. New Music Res. 33, 3, 189--202.
De Poli, G. and Rocchesso, D. 2002. Computational models for musical sounds sources. In G. Assayag, H. Feichtinger, and J. Rodrigues Eds., Music and Mathematics, A Diderot Mathematical Forum, Springer-Verlag, Berlin, 243--288.
Friberg, A., Frydén, L., Bodin, L. G., and Sundberg, J. 1991. Performance rules for computer-controlled contemporary keyboard music. Comput. Music J. 15, 2, 49--55.
Friberg, A., Schoonderwaldt, E., Juslin, P., and Bresin, R. 2002. Automatic real-time extraction of musical expression. In Proceedings of the International Computer Music Conference (ICMC'02). CMA, San Francisco, 365--367.
Gabrielsson, A. 1995. Expressive intention and performance. In R. Steinberg Ed., Music and the Mind Machine, Springer-Verlag, Berlin, 35--37.
Gabrielsson, A. 1999. The performance of music. In D. Deutsch Ed., The Psychology of Music 2nd Ed., Academic Press, San Diego, CA, 501--602.
Gibson, J. J. 1979. The Ecological Approach to Visual Perception. Houghton Mifflin, Boston.
Greenacre, M. 1984. Theory and Application of Correspondence Analysis. Academic Press, London.
Hanslick, E. 1957. On the Beautiful in Music (1854). Macmillan.
Hashimoto, S. and Suzuki, K. 2004. Robotic interface for embodied interaction via dance and musical performance. In Proc. IEEE 92, 656--671.
Hsieh, C. H. and Luciani, A. 2005. Physically-based particle modeling for dance verbs. In Proceedings of the Graphicon Conference. 85--92.
Juslin, P. N. 2001. Communicating emotion in music performance: A review and a theoretical framework. In P. N. Juslin and J. A. Sloboda Eds., Music and Emotion: Theory and Research, Oxford University Press, Oxford, UK, 303--333.
Juslin, P. N. and Sloboda, J. A. 2001. Music and Emotion: Theory and Research. Oxford University Press, Oxford, UK.
Leman, M. 2000. Visualization and calculation of roughness of acoustical musical signals using the synchronization index model (SIM). In Proceedings of the of the COST G-6 Conference on Digital Audio Effects (DAFX-00). http://profs.sci.univr.it/~dafx/Final-Papers/pdf/Leman_DAFXFinalPaper.pdf.
Marc Leman, Embodied Music Cognition and Mediation Technology, The MIT Press, 2007
Lie Lu , D. Liu , Hong-Jiang Zhang, Automatic mood detection and tracking of music audio signals, IEEE Transactions on Audio, Speech, and Language Processing, v.14 n.1, p.5-18, December 2006[doi>10.1109/TSA.2005.860344]
Lesaffre, M. L., Tanghe, K., Baets, B. D., Meyer, H. D., and Martens, J.-P. 2003. User-dependent taxonomy of musical features as a conceptual framework for musical audio mining technology. In Proceedings of the Stockholm Music Acoustics Conference (SMAC'03).
L. Mion , G. De Poli, Score-Independent Audio Features for Description of Music Expression, IEEE Transactions on Audio, Speech, and Language Processing, v.16 n.2, p.458-466, February 2008[doi>10.1109/TASL.2007.913743]
Palmer, C. 1997. Music performance. Ann. Rev. Psych. 48, 115--38.
Repp, B. H. 1990. Patterns of expressive timing in performances of a Beethoven minuet by nineteen famous pianists. J. Acoust. Soc. Am. 88, 622--641.
Repp, B. H. 1992. Diversity and commonality in music performance: An analysis of timing microstructure in Schumann's “träumerei.” J. Acoust. Soc. Am. 92, 2546--2568.
Peter Rousseeuw, Silhouettes: a graphical aid to the interpretation and validation of cluster analysis, Journal of Computational and Applied Mathematics, v.20 n.1, p.53-65, Nov. 1987[doi>10.1016/0377-0427(87)90125-7]
Russell, J. A. 1980. A circumplex model of affect. J. Personality Social Psych. 39, 1161--1178.
Serra, X. 1997. Musical sound modeling with sinusoids plus noise. In C. Roads, S. T. Pope, A. Piccialli, and G. De Poli Eds., Musical Signal Processing, Swets & Zeitlinger, The Netherlands, 91--122.
Todd, N. P. 1985. A model of expressive timing in tonal music. Music Percept. 3, 33--58.
Todd, N. P. 1992. The dynamics of dynamics: A model of musical expression. J. Acoust. Soc. Am. 91, 6, 3540--3550.
Varela, F., Thompson, E., and Rosch, E. 1991. The Embodied Mind. MIT Press, Cambridge, MA.
Vines, B. W., Krumhansl, C. L., Wanderley, M. M., and Levitin, D. J. 2006. Cross-modal interactions in the perception of musical performance. Cognition 101, 1, 80--103.
Widmer, G. and Goebl, W. 2004. Computational models of expressive music performance: The state of the art. J. New Music Res. 33, 211--224.
