Humans have the ability to identify objects under varying lighting conditions with extraordinary accuracy. We investigated the behavioral aspects of this ability and compared it to the performance of the illumination cones (IC) model of Belhumeur and Kriegman [1998]. In five experiments, observers learned 10 faces under a small subset of illumination directions. We then tested observers' recognition ability under different illuminations. Across all experiments, recognition performance was found to be dependent on the distance between the trained and tested illumination directions. This effect was modulated by the nature of the trained illumination directions. Generalizations from frontal illuminations were different than generalizations from extreme illuminations. Similarly, the IC model was also sensitive to whether the trained images were near-frontal or extreme. Thus, we find that the nature of the images in the training set affects the accuracy of an object's representation under variable lighting for both humans and the model. Beyond this general correspondence, the microstructure of the generalization patterns for both humans and the IC model were remarkably similar, suggesting that the two systems may employ related algorithms.