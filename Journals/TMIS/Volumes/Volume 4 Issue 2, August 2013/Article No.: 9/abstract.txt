Computer-mediated deception is prevalent and may have serious consequences for individuals, organizations, and society. This article investigates several metrics as predictors of deception in synchronous chat-based environments, where participants must often spontaneously formulate deceptive responses. Based on cognitive load theory, we hypothesize that deception influences response time, word count, lexical diversity, and the number of times a chat message is edited. Using a custom chatbot to conduct interviews in an experiment, we collected 1,572 deceitful and 1,590 truthful chat-based responses. The results of the experiment confirm that deception is positively correlated with response time and the number of edits and negatively correlated to word count. Contrary to our prediction, we found that deception is not significantly correlated with lexical diversity. Furthermore, the age of the participant moderates the influence of deception on response time. Our results have implications for understanding deceit in chat-based communication and building deception-detection decision aids in chat-based systems.