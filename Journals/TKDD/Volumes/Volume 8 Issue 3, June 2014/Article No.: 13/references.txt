Trine Julie Abrahamsen , Lars Kai Hansen, A Cure for Variance Inflation in High Dimensional Kernel Principal Component Analysis, The Journal of Machine Learning Research, 12, p.2027-2044, 2/1/2011
A. Agarwal and J. Duchi. 2011. The generalization ability of online algorithms for dependent data. IEEE Transactions on Information Theory 59, 573--587.
R. Alexander, S. Ohad, and S. Karthik. 2012. Making gradient descent optimal for strongly convex stochastic optimization. In Proceedings of the International Conference on Machine Learning. 449--456.
R. Ali and R. Benjamin. 2007. Random features for large-scale kernel machines. In Advances in Neural Information Processing Systems, Vol. 20. 1177--1184.
Antoine Bordes , Seyda Ertekin , Jason Weston , Léon Bottou, Fast Kernel Classifiers with Online and Active Learning, The Journal of Machine Learning Research, 6, p.1579-1619, 12/1/2005
P. L. Bartlett, V. Dani, T. P. Hayes, S. Kakade, A. Rakhlin, and A. Tewari. 2008. High-probability regret bounds for bandit online linear optimization. In Proceedings of the Annual Conference on Learning Theory. 335--342.
R. Bekkerman. 2004. Automatic categorization of email into folders: Benchmark experiments on Enron and SRI corpora. Computer Science Department Faculty Publication Series. 218.
Léon Bottou , Olivier Chapelle , Dennis DeCoste , Jason Weston, Large-Scale Kernel Machines (Neural Information Processing), The MIT Press, 2007
Giovanni Cavallanti , Nicolò Cesa-Bianchi , Claudio Gentile, Tracking the best hyperplane with a simple budget Perceptron, Machine Learning, v.69 n.2-3, p.143-167, December  2007[doi>10.1007/s10994-007-5003-0]
N. Cesa-Bianchi , A. Conconi , C. Gentile, On the generalization ability of on-line learning algorithms, IEEE Transactions on Information Theory, v.50 n.9, p.2050-2057, September 2004[doi>10.1109/TIT.2004.833339]
Chih-Chung Chang , Chih-Jen Lin, LIBSVM: A library for support vector machines, ACM Transactions on Intelligent Systems and Technology (TIST), v.2 n.3, p.1-27, April 2011[doi>10.1145/1961189.1961199]
A. Cotter, J. Keshet, and N. Srebro. 2011. Explicit approximations of the Gaussian kernel. arXiv preprint arXiv:1109.4603.
A. Cotter, S.-SW. Shalev-Shwartz, and N. Srebro. 2013. Learning optimally sparse support vector machines. In Proceedings of the International Conference on Machine Learning. 266--274.
K. Crammer, M. Dredze, J. Blitzer, and F. Pereira. 2008. Batch performance for an online price. In Proceedings of the NIPS 2007 Workshop on Efficient Machine Learning.
I. Dagan, Y. Karov, and D. Roth. 1997. Mistake-driven learning in text categorization. In Proceedings of the 2nd Conference on Empirical Methods in Natural Language Processing. 55--63.
Ofer Dekel , Shai Shalev-Shwartz , Yoram Singer, The Forgetron: A Kernel-Based Perceptron on a Budget, SIAM Journal on Computing, v.37 n.5, p.1342-1372, January 2008[doi>10.1137/060666998]
Petros Drineas , Michael W. Mahoney, On the Nyström Method for Approximating a Gram Matrix for Improved Kernel-Based Learning, The Journal of Machine Learning Research, 6, p.2153-2175, 12/1/2005
John Duchi , Yoram Singer, Efficient Online and Batch Learning Using Forward Backward Splitting, The Journal of Machine Learning Research, 10, p.2899-2934, 12/1/2009
Yoav Freund , Robert E. Schapire, Large Margin Classification Using the Perceptron Algorithm, Machine Learning, v.37 n.3, p.277-296, Dec. 1999[doi>10.1023/A:1007662407062]
E. Hazan and S. Kale. 2011. Beyond the regret minimization barrier: An optimal algorithm for stochastic strongly-convex optimization. Journal of Machine Learning Research Proceedings 19, 421--436.
Chih-Wei Hsu , Chih-Jen Lin, A comparison of methods for multiclass support vector machines, IEEE Transactions on Neural Networks, v.13 n.2, p.415-425, March 2002[doi>10.1109/72.991427]
S. Sathiya Keerthi , Olivier Chapelle , Dennis DeCoste, Building Support Vector Machines with Reduced Classifier Complexity, The Journal of Machine Learning Research, 7, p.1493-1515, 12/1/2006
J. Kivinen , A.J. Smola , R.C. Williamson, Online learning with kernels, IEEE Transactions on Signal Processing, v.52 n.8, p.2165-2176, August 2004[doi>10.1109/TSP.2004.830991]
V. Koltchinskii. 2011. Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Problems. Vol. 2033. Springer.
Sanjiv Kumar , Mehryar Mohri , Ameet Talwalkar, Sampling methods for the Nyström method, The Journal of Machine Learning Research, v.13 n.1, p.981-1006, January 2012
John Langford , Lihong Li , Tong Zhang, Sparse Online Learning via Truncated Gradient, The Journal of Machine Learning Research, 10, p.777-801, 12/1/2009
Pavan Kumar Mallapragada , Rong Jin , Anil Jain, Non-parametric mixture models for clustering, Proceedings of the 2010 joint IAPR international conference on Structural, syntactic, and statistical pattern recognition, August 18-20, 2010, Cesme, Izmir, Turkey
O. L. Mangasarian , David R. Musicant, Large Scale Kernel Regression via Linear Programming, Machine Learning, v.46 n.1-3, p.255-269, 2002[doi>10.1023/A:1012422931930]
Francesco Orabona , Joseph Keshet , Barbara Caputo, The projectron: a bounded kernel-based Perceptron, Proceedings of the 25th international conference on Machine learning, p.720-727, July 05-09, 2008, Helsinki, Finland[doi>10.1145/1390156.1390247]
E. Osuna and F. Girosi. 1998. Reducing the run-time complexity of support vector machines. In Proceedings of the International Conference on Pattern Recognition. 271--283.
A. Rahimi and B. Recht. 2008. Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning. In Advances in Neural Information Processing Systems, Vol. 21. 1313--1320.
S. Ross and J. A. Bagnell. 2011. Stability conditions for online learnability. arXiv preprint arXiv:1108.3154.
B. Scholkopf , S. Mika , C. J.C. Burges , P. Knirsch , K. -R. Muller , G. Ratsch , A. J. Smola, Input space versus feature space in kernel-based methods, IEEE Transactions on Neural Networks, v.10 n.5, p.1000-1017, September 1999[doi>10.1109/72.788641]
B. Schölkopf, P. Simard, V. Vapnik, and A. J. Smola. 1997. Improving the accuracy and speed of support vector machines. In Advances in Neural Information Processing Systems, Vol. 9. 375--381.
Shai Shalev-Shwartz , Ohad Shamir , Nathan Srebro , Karthik Sridharan, Learnability, Stability and Uniform Convergence, The Journal of Machine Learning Research, 11, p.2635-2670, 3/1/2010
Shai Shalev-Shwartz , Yoram Singer , Nathan Srebro, Pegasos: Primal Estimated sub-GrAdient SOlver for SVM, Proceedings of the 24th international conference on Machine learning, p.807-814, June 20-24, 2007, Corvalis, Oregon[doi>10.1145/1273496.1273598]
O. Shamir and T. Zhang. 2013. Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes. In Proceedings of the International Conference on Machine Learning.
S. Smale and D. X. Zhou. 2009. Geometry on probability spaces. Constructive Approximation 30, 3, 311--323.
Sören Sonnenburg , Gunnar Rätsch , Christin Schäfer , Bernhard Schölkopf, Large Scale Multiple Kernel Learning, The Journal of Machine Learning Research, 7, p.1531-1565, 12/1/2006
Ingo Steinwart , Andreas Christmann, Support Vector Machines, Springer Publishing Company, Incorporated, 2008
V. Vapnik. 1998. Statistical Learning Theory. Wiley, New York.
C. K. I. Williams and M. Seeger. 2001. Using the Nyström method to speed up kernel machines. In Advances in Neural Information Processing Systems, Vol. 13. 682--688.
Mingrui Wu , Bernhard Schölkopf , Gökhan Bakır, A Direct Method for Building Sparse Kernel Learning Algorithms, The Journal of Machine Learning Research, 7, p.603-624, 12/1/2006
J. W. Xu, P. P. Pokharel, K. H. Jeong, and J. C. Principe. 2006. An explicit construction of a reproducing Gaussian kernel Hilbert space. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing. V.
C. Yang, R. Duraiswami, and L. Davis. 2005. Efficient kernel machines using the improved fast Gauss transform. In Advances in Neural Information Processing Systems, Vol. 17. 1561--1568.
T. Yang, Y. F. Li, M. Mahdavi, R. Jin, and Z.-H. Zhou. 2012. Nyström method vs random Fourier features: A theoretical and empirical comparison. In Advances in Neural Information Processing Systems, Vol. 25. 485--493.
Kai Zhang , James T. Kwok, Density-weighted nyström method for computing large kernel eigensystems, Neural Computation, v.21 n.1, p.121-146, Jan. 2009[doi>10.1162/neco.2009.11-07-651]
L. Zhang, J. Yi, R. Jin, M. Lin, and X. He. 2013. Online kernel learning with a near optimal sparsity bound. In Proceedings of the International Conference on Machine Learning. 621--629.
P. Zhao, J. Wang, P. Wu, R. Jin, and S. C. H. Hoi. 2012. Fast bounded online gradient descent algorithms for scalable kernel-based online learning. In Proceedings of the International Conference on Machine Learning. 169--176.
J. Zhu and T. Hastie. 2005. Kernel logistic regression and the import vector machine. Journal of Computational and Graphical Statistics 14, 1, 185--205.
M. Zinkevich. 2003. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the International Conference on Machine Learning. 928--936.
