Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy calledk-anonymity has gained popularity. In ak-anonymized dataset, each record is indistinguishable from at leastkâˆ’ 1 other records with respect to certain identifying attributes.In this article, we show using two simple attacks that ak-anonymized dataset has some subtle but severe privacy problems. First, an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. This is a known problem. Second, attackers often have background knowledge, and we show thatk-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks, and we propose a novel and powerful privacy criterion called &ell;-diversity that can defend against such attacks. In addition to building a formal foundation for &ell;-diversity, we show in an experimental evaluation that &ell;-diversity is practical and can be implemented efficiently.