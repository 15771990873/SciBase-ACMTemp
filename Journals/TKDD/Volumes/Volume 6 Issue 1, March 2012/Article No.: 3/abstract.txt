Anomalies are data points that are few and different. As a result of these properties, we show that, anomalies are susceptible to a mechanism calledisolation. This article proposes a method called Isolation Forest (iForest), which detects anomalies purely based on the concept of isolation without employing any distance or density measure---fundamentally different from all existing methods.As a result,iForest is able to exploit subsampling (i) to achieve a low linear time-complexity and a small memory-requirement and (ii) to deal with the effects of swamping and masking effectively. Our empirical evaluation shows thatiForest outperforms ORCA, one-class SVM, LOF and Random Forests in terms of AUC, processing time, and it is robust against masking and swamping effects.iForest also works well in high dimensional problems containing a large number of irrelevant attributes, and when anomalies are not available in training sample.