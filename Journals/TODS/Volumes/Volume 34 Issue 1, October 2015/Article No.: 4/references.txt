Y. Bengio and J.-S. Senecal, and others. 2003. Quick Training of Probabilistic Neural Nets by Importance Sampling.
Y. Bengio , J. -S. Senecal, Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model, IEEE Transactions on Neural Networks, v.19 n.4, p.713-722, April 2008[doi>10.1109/TNN.2007.912312]
Jiang Bian , Bin Gao , Tie-Yan Liu, Knowledge-Powered Deep Learning for Word Embedding, Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases, September 15-19, 2014, Nancy, France[doi>10.1007/978-3-662-44848-9_9]
David M. Blei , Andrew Y. Ng , Michael I. Jordan, Latent dirichlet allocation, The Journal of Machine Learning Research, 3, p.993-1022, 3/1/2003
A. Bordes, J. Weston, R. Collobert, Y. Bengio, and others. 2011. Learning structured embeddings of knowledge bases. In AAAI.
J. W. Chapman. 1998. Language prediction skill, phonological recoding ability, and beginning reading. Reading and Spelling: Development and Disorders, 33.
Ronan Collobert , Jason Weston, A unified architecture for natural language processing: deep neural networks with multitask learning, Proceedings of the 25th international conference on Machine learning, p.160-167, July 05-09, 2008, Helsinki, Finland[doi>10.1145/1390156.1390177]
Ronan Collobert , Jason Weston , Léon Bottou , Michael Karlen , Koray Kavukcuoglu , Pavel Kuksa, Natural Language Processing (Almost) from Scratch, The Journal of Machine Learning Research, 12, p.2493-2537, 2/1/2011
Mathias Creutz , Krista Lagus, Unsupervised models for morpheme segmentation and morphology learning, ACM Transactions on Speech and Language Processing (TSLP), v.4 n.1, p.1-34, January 2007[doi>10.1145/1187415.1187418]
L. Deng, X. He, and J. Gao. 2013. Deep stacking networks for information retrieval. In ICASSP. 3153--3157.
L. C. Ehri. 2005. Learning to read words: Theory, findings, and issues. Scientific Studies of Reading 9, 2, 167--188.
L. C. Ehri, R. Barr, M. L. Kamil, P. Mosenthal, and P. D. Pearson. 1991. Development of the ability to read words. Handbook of Reading Research 2, 383--417.
Lev Finkelstein , Evgeniy Gabrilovich , Yossi Matias , Ehud Rivlin , Zach Solan , Gadi Wolfman , Eytan Ruppin, Placing search in context: the concept revisited, Proceedings of the 10th international conference on World Wide Web, p.406-414, May 01-05, 2001, Hong Kong, Hong Kong[doi>10.1145/371920.372094]
X. Glorot, A. Bordes, and Y. Bengio. 2011. Domain adaptation for large-scale sentiment classification: A deep learning approach. In Proceedings of the 28th International Conference on Machine Learning (ICML’11). 513--520.
U. Goswami. 1986. Children’s use of analogy in learning to read: A developmental study. Journal of Experimental Child Psychology. 42, 1, 73--83.
Michael U. Gutmann , Aapo Hyvärinen, Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics, The Journal of Machine Learning Research, v.13 n.1, p.307-361, January 2012
G. E. Hinton , J. L. McClelland , D. E. Rumelhart, Distributed representations, Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations, MIT Press, Cambridge, MA, 1986
Thomas Hofmann, Probabilistic latent semantic analysis, Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence, p.289-296, July 30-August 01, 1999, Stockholm, Sweden
Eric H. Huang , Richard Socher , Christopher D. Manning , Andrew Y. Ng, Improving word representations via global context and multiple word prototypes, Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers, July 08-14, 2012, Jeju Island, Korea
F. M. Liang. 1983. Word Hy-phen-a-tion by Com-put-er (Hyphenation, Computer). Stanford University, Stanford, CA, USA.
M.-T. Luong, R. Socher, and C. D. Manning. 2013. Better word representations with recursive neural networks for morphology. CoNLL-2013. 104.
T. Mikolov. 2012. Statistical Language Models Based on Neural Networks. Ph.D. Dissertation. Brno University of Technology.
T. Mikolov, K. Chen, G. Corrado, and J. Dean. 2013a. Efficient estimation of word representations in vector space (ICLR’13).
T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. 2013b. Distributed representations of words and phrases and their compositionality. In NIPS. 3111--3119.
A. Mnih and G. E. Hinton. 2008. A scalable hierarchical distributed language model. In NIPS. 1081--1088.
A. Mnih and K. Kavukcuoglu. 2013. Learning word embeddings efficiently with noise-contrastive estimation. In NIPS. 2265--2273.
A Mnih and Y. W. Teh. 2012. A fast and simple algorithm for training neural probabilistic language models. In ICML. Omnipress, New York, NY, 1751--1758.
F. Morin and Y. Bengio. 2005. Hierarchical probabilistic neural network language model. In AISTATS. 246--252.
A. El-Desoky Mousa, H.-K. J. Kuo, L. Mangu, and H. Soltau. 2013. Morpheme-based feature-rich language models using deep neural networks for lvcsr of egyptian arabic. In Proceedings of the 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 8435--8439.
S. Qiu, Q. Cui, J. Bian, B. Gao, and T.-Y. Liu. 2014. Co-learning of word representations and morpheme representations. In Proc. of COLING.
R. Socher, D. Chen, C. D. Manning, and A. Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In NIPS. 926--934.
R. Socher, C. C. Lin, A. Y. Ng, and C. D. Manning. 2011. Parsing natural scenes and natural language with recursive neural networks. In Proceedings of the 28th International Conference on Machine Learning (ICML’11). 129--136.
H. Sperr, J. Niehues, and A. Waibel. 2013. Letter n-gram-based input encoding for continuous space language models. In Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality. 30--39.
Joseph Turian , Lev Ratinov , Yoshua Bengio, Word representations: a simple and general method for semi-supervised learning, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, p.384-394, July 11-16, 2010, Uppsala, Sweden
P. D. Turney. 2013. Distributional semantics beyond words: Supervised learning of analogy and paraphrase. TACL, 353--366.
Peter D. Turney , Patrick Pantel, From frequency to meaning: vector space models of semantics, Journal of Artificial Intelligence Research, v.37 n.1, p.141-188, January 2010
J. Weston, A. Bordes, O. Yakhnenko, and N. Usunier. 2013. Connecting language and knowledge bases with embedding models for relation extraction. arXiv preprint arXiv:1307.7973.
M. Yu and M. Dredze. 2014. Improving lexical embeddings with semantic knowledge. In Association for Computational Linguistics (ACL). 545--550.
