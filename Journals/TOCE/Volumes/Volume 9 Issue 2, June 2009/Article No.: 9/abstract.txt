This article reviews successful educational experiences in using program and algorithm visualizations (PAVs). First, we survey a total of 18 PAV systems that were subject to 33 evaluations. We found that half of the systems have only been tested for usability, and those were shallow inspections. The rest were evaluated with respect to their educational effectiveness. Script-based systems seem to be well suited for the viewing, responding, and changing engagement levels, while compiler-based systems do well for the construction and presenting engagement levels. Finally, we analyze additional PAV features of successful evaluations and hypothesize that they are relevant.