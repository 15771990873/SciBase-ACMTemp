Through analysis and experiments, this paper investigates two-phase waiting algorithms to minimize the cost of waiting for synchronization in large-scale multiprocessors. In a two-phase algorithm, a thread first waits by polling a synchronization variable. If the cost of polling reaches a limitLpolland further waiting is necessary, the thread is blocked, incurring an additional fixed cost,B. The choice ofLpollis a critical determinant of the performance of two-phase algorithms. We focus on methods for statically determiningLpollbecause the run-time overhead of dynamically determiningLpollcan be comparable to  the cost of blocking in large-scale multiprocessor systems with lightweight threads.Our experiments show thatalways-block(Lpoll= 0) is a good waiting algorithm with performance that is usually close to the best of the algorithms compared. We show that even better performance can be achieved with a static choice ofLpollbased on knowledge of likely wait-time distributions. Motivated by the observation that different synchronization types exhibit different wait-time distributions, we prove that a static choice ofLpollcan yield close to optimal on-line performance against an adversary that is restricted to choosing wait times from a fixed family  of probability distributions. This result allows us to make an optimal static choice ofLpollbased on synchronization type. For exponentially distributed wait times, we prove that settingLpoll= 1n(e-1)Bresults in a waiting cost that is no more thane/(e-1)times the cost of an optimal off-line algorithm. For uniformly distributed wait times, we prove that settingLpoll=1/2(square root of 5 -1)Bresults in a waiting cost that is no more than (square root of 5 + 1)/2 (the golden ratio) times the cost of an optimal off-line algorithm. Experimental measurements of several parallel applications on the Alewife multiprocessor simulator  corroborate our theoretical findings.