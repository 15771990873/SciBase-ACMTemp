Ali, S. O. and Peynircioǧu;, Z. F.2006. Songs and emotions: Are lyrics and melodies equal partners.Psychol. Music 34, 4, 511--534.
Allamanche, E., Herre, J., Helmuth, O., Fröba, B., Kasten, T., and Cremer, M.2001. Content-based identification of audio material using MPEG-7 low level description. InProceedings of the International Conference on Music on Information Retrieval. 197--204.
K. Anderson , P. W. McOwan, A real-time automated system for the recognition of human facial expressions, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, v.36 n.1, p.96-105, February 2006[doi>10.1109/TSMCB.2005.854502]
S. Arifin , P. Cheung, Affective Level Video Segmentation by Utilizing the Pleasure-Arousal-Dominance Information, IEEE Transactions on Multimedia, v.10 n.7, p.1325-1341, November 2008[doi>10.1109/TMM.2008.2004911]
Benetos, E., Kotti, M., and Kotropoulos, C.2007. Large scale musical instrument identification. InProceedings of the International Conference on Music Information Retrieval. http://www.ifs.tuwien.ac.at/mir/muscle/del/audio_tools.html#SoundDescrToolbox.
Bigand, E., Vieillard, S., Madurell, F., Marozeau, J., and Dacquet, A.2005. Multidimensional scaling of emotional responses to music: The effect of musical expertise and of the duration of the excerpts.Cognition Emotion 19, 8, 1113--1139.
Bischoff, K., Firan, C. S., Paiu, R., Nejdl, W., Laurier, C., and Sordo, M.2009. Music mood and theme classification a hybrid approach. InProceedings of the International Conference on Music Information Retrieval. 657--662.
Stephen Boyd , Lieven Vandenberghe, Convex Optimization, Cambridge University Press, New York, NY, 2004
Cabrera, D.1999. Psysound: A computer program for psycho-acoustical analysis. InProceedings of the Australian Acoustic Society Conference. 47--54. http://psysound.wikidot.com/.
Rui Cai , Chao Zhang , Chong Wang , Lei Zhang , Wei-Ying Ma, MusicSense: contextual music recommendation using emotional allocation modeling, Proceedings of the 15th international conference on Multimedia, September 25-29, 2007, Augsburg, Germany[doi>10.1145/1291233.1291369]
Arturo Camacho , John G. Harris, Swipe: a sawtooth waveform inspired pitch estimator for speech and music, University of Florida, Gainesville, FL, 2007
Campbell, W. M., Campbell, J. P., Reynolds, D. A., Singer, E., and Torres-Carrasquillo, P. A.2006. Support vector machines for speaker and language recognition.Comput. Speech Lang. 20, 2--3, 210--229.
Cao, C. and Li, M.2009. Thinkit’s submissions for MIREX2009 audio music classification and similarity tasks. InProceedings of the International Conference on Music Information Retreival.
Casey, M. A., Veltkamp, R., Goto, M., Leman, M., Rhodes, C., and Slaney, M.2008. Content-based music information retrieval: Current directions and future challenges.IEEE 96, 4, 668--696.
Chih-Chung Chang , Chih-Jen Lin, LIBSVM: A library for support vector machines, ACM Transactions on Intelligent Systems and Technology (TIST), v.2 n.3, p.1-27, April 2011[doi>10.1145/1961189.1961199]
Chin-Han Chen , Ming-Fang Weng , Shyh-Kang Jeng , Yung-Yu Chuang, Emotion-based music visualization using photos, Proceedings of the 14th international conference on Advances in multimedia modeling, January 09-11, 2008, Kyoto, Japan
Jun-Cheng Chen , Wei-Ta Chu , Jin-Hau Kuo , Chung-Yi Weng , Ja-Ling Wu, Tiling slideshow, Proceedings of the 14th annual ACM international conference on Multimedia, October 23-27, 2006, Santa Barbara, CA, USA[doi>10.1145/1180639.1180653]
Cheng, H.-T., Yang, Y.-H., Lin, Y.-C., and Chen, H.-H.2009. Multimodal structure segmentation and analysis of music using audio and textual information. InProceedings of the IEEE International Symposium on Circuits and Systems. 1677--1680.
Cheng, H.-T., Yang, Y.-H., Lin, Y.-C., Liao, I.-B., and Chen, H.-H.2008. Automatic chord recognition for music classification and retrieval. InProceedings of the IEEE International Conference on Multimedia and Expo.1505--1508.
Cohen, R. and Swerdlik, M.2002.Psychological Testing and Assessment: An Introduction to Tests and Measurement. Mayfield Publishing Company, Mountain View, CA.
William W. Cohen , Robert E. Schapire , Yoram Singer, Learning to order things, Journal of Artificial Intelligence Research, v.10 n.1, p.243-270, January 1999
Collier, G.2007. Beyond valence and activity in the emotional connotations of music.Psychol. Music 35, 1, 110--131.
Corinna Cortes , Vladimir Vapnik, Support-Vector Networks, Machine Learning, v.20 n.3, p.273-297, Sept. 1995[doi>10.1023/A:1022627411411]
Cowie, R., Douglas-Cowie, E., Savvidou, S., McMahon, E., Sawey, M., and Schröer, M.2000. Feeltrace: An instrument for recording perceived emotion in real time. InProceedings of the ISCA Tutorial and Research Workshop on Speech and Emotion. 19--24.
Davis, S. and Mermelstein, P.1980. Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences.IEEE Trans. Acoustics, Speech and Signal Processing 28, 4, 357--366.
Dietz, R. and Lang, A.1999. Affective agents: Effects of agent affect on arousal, attention, liking and learning. InProceedings of the International Conference on Cognitive Technology.
Dornbush, S., Fisher, K., Mckay, K., Prikhodko, A., and Segall, Z.2005. XPOD: A human activity and emotion aware mobile music player. InProceedings of the International Conference on Mobile Technology, Applications and Systems. 1--6.
Richard O. Duda , Peter E. Hart , David G. Stork, Pattern Classification (2nd Edition), Wiley-Interscience, 2000
Peter Dunker , Stefanie Nowak , André Begau , Cornelia Lanz, Content-based mood classification for photos and music: a generic multi-modal classification framework and evaluation approach, Proceedings of the 1st ACM international conference on Multimedia information retrieval, October 30-31, 2008, Vancouver, British Columbia, Canada[doi>10.1145/1460096.1460114]
Eerola, T., Toiviainen, P., and Krumhansl, C. L.2002. Real-time prediction of melodies: Continuous predictability judgments and dynamic models. InProceedings of the International Conference on Music Perception and Cognition. 473--476.
Eerola, T., Lartillot, O., and Toiviainen, P.2009. Prediction of multidimensional emotional ratings in music from audio using multivariate regression models. InProceedings of the International Conference on Music Information Retrieval. 621--626.
Ekman, P.1992. An argument for basic emotions.Cognition Emotion 6, 3, 169--200.
Farnsworth, P. R.1954. A study of the Hevner adjective list.J. Aesthetics Art Criticism 13, 97--103.
Yazhong Feng , Yueting Zhuang , Yunhe Pan, Popular music retrieval by detecting mood, Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, July 28-August 01, 2003, Toronto, Canada[doi>10.1145/860435.860508]
Fernandez, R. and Picard, R. W.2005. Classical and novel discriminant features for affect recognition from speech. InProceedings of the INTERSPEECH Conference.
Fornari, J. and Eerola, T.2008. The pursuit of happiness in music: Retrieving valence with high-level musical descriptors. InProceedings of the Computer Music Modeling and Retrieval.
Fornäs, J.2006. Songs and emotions: Are lyrics and melodies equal partners.Psychol. Music 34, 4, 511--534.
Fujihara, H. and Goto, M.2007. A music information retrieval system based on singing voice timbre. InProceedings of the International Conference on Music Information Retrieval.
Fujihara, H., Kitahara, T., Goto, M., Komatani, K., Ogata, T., and Okuno, H. G.2005. Singer identification based on accompaniment sound reduction and reliable frame selection. InProceedings of the International Conference on Music Information Retrieval.
Gabrielsson, A.2002. Emotion perceived and emotion felt: Same or different?Musicae Scientiae(special issue), 123--147.
Gabrielsson, A. and Lindström, E.2001. The influence of musical structure on emotional expression. InMusic and Emotion: Theory and Research, P. N. Juslin and J. A. Sloboda Eds., Oxford University Press, Oxford, UK.
Theodoros Giannakopoulos , Aggelos Pikrakis , Sergios Theodoridis, A dimensional approach to emotion recognition of speech from movies, Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, p.65-68, April 19-24, 2009[doi>10.1109/ICASSP.2009.4959521]
Gómez, E.2006. Tonal description of music audio signal. Ph.D. dissertation, Universitat Pompeu Fabra, Barcelona.
Goto, M.2004. A real-time music-scene-description system: Predominant-f0 estimation for detecting melody and bass lines in real-world audio signals.Speech Communication 43, 311--329.
Goto, M., Hashiguchi, H., Nishimura, T., and Oka, R.2003. RWC music database: Music genre database and musical instrument sound database. InProceedings of the International Conference on Music Information Retrieval. 229--230.
Grubbs, F. E.1969. Procedures for detecting outlying observations in samples.Technometrics 11, 1, 1--21.
Han, B.-J., Rho, S., Dannenberg, R. B., and Hwang, E.2009. SMERS: Music emotion recognition using support vector regression. InProceedings of the International Conference on Music Information Retrieval. 651--656.
A. Hanjalic , Li-Qun Xu, Affective video content representation and modeling, IEEE Transactions on Multimedia, v.7 n.1, p.143-154, February 2005[doi>10.1109/TMM.2004.840618]
Hargreaves, D. J.1986.The Developmental Psychology of Music. Cambridge University Press, Cambridge, UK.
Hevner, K.1935. Expression in music: A discussion of experimental studies and theories.Psychol. Review 48, 2, 186--204.
Thomas Hofmann, Probabilistic latent semantic indexing, Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, p.50-57, August 15-19, 1999, Berkeley, California, USA[doi>10.1145/312624.312649]
Hsu, D. C.-W. and Hsu, J. Y.-J.2006. LyQ: An emotion-aware music player. InProceedings of the AAAI Workshop on Computational Aesthetics: Artificial Intelligence Approaches to Beauty and Happiness.
Hu, X. and Downie, J. S.2007. Exploring mood metadata: Relationships with genre, artist and usage metadata. InProceedings of the International Conference on Music Information Retrieval.
Hu, X., Downie, J. S., Laurier, C., Bay, M., and Ehmann, A. F.2008. The 2007 MIREX audio mood classification task: Lessons learned. InProceedings of the International Conference on Music Information Retrieval. 462--467.
Hu, X., Sanghvi, V., Vong, B., On, P. J., Leong, C., and Angelica, J.2008. Moody: A web-based music mood classification and recommendation system. InProceedings of the International Conference on Music Information Retrieval.
Hu, X., Downie, J. S., and Ehmann, A. F.2009. Lyric text mining in music mood classification. InProceedings of the International Conference on Music Information Retrieval.
Hu, Y., Chen, X., and Yang, D.2009. Lyric-based song emotion detection with affective lexicon and fuzzy clustering method. InProceedings of the International Conference on Music Information Retrieval.
Huq, A., Bello, J. P., Sarroff, A., Berger, J., and Rowe, R.2009. Sourcetone: An automated music emotion recognition system. InProceedings of the International Conference on Music Information Retrieval.
Huq, A., Bello, J. P., and Rowe, R.2010. Automated music emotion recognition: A systematic evaluation.J. New Music Res. 39, 3, 227--244.
Huron, D.2000. Perceptual and cognitive applications in music information retrieval. InProceedings of the International Conference on Music Information Retrieval.
Huron, D.2006.Sweet Anticipation: Music and the Psychology of Expectation. MIT Press, Cambridge, MA.
Alejandro Jaimes , Nicu Sebe, Multimodal human computer interaction: a survey, Proceedings of the 2005 international conference on Computer Vision in Human-Computer Interaction, October 21, 2005, Beijing, China[doi>10.1007/11573425_1]
Alejandro Jaimes , Nicu Sebe , Daniel Gatica-Perez, Human-centered computing: a multimedia perspective, Proceedings of the 14th annual ACM international conference on Multimedia, October 23-27, 2006, Santa Barbara, CA, USA[doi>10.1145/1180639.1180829]
Jargreaves, D. J. and North, A. C.1997.The Social Psychology of Music. Oxford University Press, Oxford, UK.
Jiang, D. N., Lu, L., Zhang, H. J., Tao, J. H., and Cai, L. H.2002. Music type classification by spectral contrast features. InProceedings of the IEEE International Conference on Multimedia Expo.113--116.
Jonghwa Kim , Elisabeth André, Emotion Recognition Based on Physiological Changes in Music Listening, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.30 n.12, p.2067-2083, December 2008[doi>10.1109/TPAMI.2008.26]
Juslin, P. N.2000. Cue utilization in communication of emotion in music performance: Relating performance to perception.J. Exp. Psychol.: Human Percep. Perform. 16, 6, 1797--1813.
Juslin, P. N. and Laukka, P.2004. Expression, perception, and induction of musical emotions: A review and a questionnaire study of everyday listening.J. New Music Res. 33, 3, 217--238.
Juslin, P. N. and Sloboda, J. A.2001.Music and Emotion: Theory and Research. Oxford University Press, Oxford, UK.
Karl F. MacDorman, S. O. and Ho, C.-C.2007. Automatic emotion prediction of song excerpts: Index construction, algorithm design, and empirical comparison.J. New Music Res. 36, 4, 281--299.
Katayose, H., Imai, M., and Inokuchi, S.1998. Sentiment extraction in music. InProceedings of the International Conference on Pattern Recognition. 1083--1087.
Kim, Y. E., Schmidt, E., and Emelle, L.2008. Moodswings: A collaborative game for music mood label collection. InProceedings of the International Conference on Music Information Retrieval. 231--236.
Kim, Y. E., Schmidt, E. M., Migneco, R., Morton, B. G., Richardson, P., Scott, J., Speck, J. A., and Turnbull, D.2010. Music emotion recognition: A state of the art review. InProceedings of the International Conference on Music Information Retrieval.
A. Klapuri, Sound onset detection by applying psychoacoustic knowledge, Proceedings of the Acoustics, Speech, and Signal Processing, 1999. on 1999 IEEE International Conference, p.3089-3092, March 15-19, 1999[doi>10.1109/ICASSP.1999.757494]
M. D. Korhonen , D. A. Clausi , M. E. Jernigan, Modeling emotional content of music using system identification, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, v.36 n.3, p.588-599, June 2005[doi>10.1109/TSMCB.2005.862491]
Krumhansl, C.2002. Music: A link between cognition and emotion.Current Directions Psychol. Sci. 11, 2, 45--50.
Laar, B.2006. Emotion detection in music, a survey. InProceedings of the Twente Student Conference on IT.
M. Lagrange , L. G. Martins , J. Murdoch , G. Tzanetakis, Normalized Cuts for Predominant Melodic Source Separation, IEEE Transactions on Audio, Speech, and Language Processing, v.16 n.2, p.278-290, February 2008[doi>10.1109/TASL.2007.909260]
Lamere, P.2008. Social tagging and music information retrieval.J. New Music Res. 37, 2, 101--114.
Lang, P. J.1995. The emotion probe.Amer. Psychol. 50, 5, 372--290.
Lartillot, O. and Toiviainen, P.2007. MIR in Matlab (II): A toolbox for musical feature extraction from audio. InProceedings of the International Conference on Music Information Retrieval. 127--130. http://users.jyu.fi/~lartillo/mirtoolbox/.
Laurier, C. and Herrera, P.2007. Audio music mood classification using support vector machine. InProceedings of the International Conference on Music Information Retrieval.
Laurier, C. and Herrera, P.2008. Mood cloud: A real-time music mood visualization tool. InProceedings of the Computer Music Modeling and Retrieval.
Laurier, C., Sordo, M., Serrà, J., and Herrera, P.2004. Digital music interaction concepts: A user study. InProceedings of the International Conference on Music Information Retrieval. 415--420.
Cyril Laurier , Jens Grivolla , Perfecto Herrera, Multimodal Music Mood Classification Using Audio and Lyrics, Proceedings of the 2008 Seventh International Conference on Machine Learning and Applications, p.688-693, December 11-13, 2008[doi>10.1109/ICMLA.2008.96]
Laurier, C., Sordo, M., and Herrera, P.2009. Mood cloud 2.0: Music mood browsing based on social networks. InProceedings of the International Conference on Music Information Retrieval.
Laurier, C., Sordo, M., Serrà, J., and Herrera, P.2009. Music mood representations from social tags. InProceedings of the International Conference on Music Information Retrieval. 381--386.
Law, E. L. M., von Ahn, L., Dannenberg, R. B., and Crawford, M.2007. TagATune: A game for music and sound annotation. InProceedings of the International Conference on Music Information Retrieval.
Lazarus, R. S.1991.Emotion and Adaptation. Oxford University Press, Oxford, UK.
Lee, J. H. and Downie, J. S.2004. Survey of music information needs, uses, and seeking behaviours: Preliminary findings. InProceedings of the International Conference on Music Information Retrieval. 441--446.
Lee, C.-M. and Narayanan, S. S.2005. Toward detecting emotions in spoken dialogs.IEEE Trans. Speech Audio Process. 13, 2, 293--303.
Leman, M., Vermeulen, V., Voogdt, L. D., Moelants, D., and Lesaffre, M.2005. Prediction of musical affect using a combination of acoustic structural cues.J. New Music Res. 34, 1, 39--67.
Levy, M. and Sandler, M.2007. A semantic space for music derived from social tags. InProceedings of the International Conference on Music Information Retrieval. 411--416.
Michael S. Lew , Nicu Sebe , Chabane Djeraba , Ramesh Jain, Content-based multimedia information retrieval: State of the art and challenges, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP), v.2 n.1, p.1-19, February 2006[doi>10.1145/1126004.1126005]
David D. Lewis , Yiming Yang , Tony G. Rose , Fan Li, RCV1: A New Benchmark Collection for Text Categorization Research, The Journal of Machine Learning Research, 5, p.361-397, 12/1/2004
Li, T. and Ogihara, M.2003. Detecting emotion in music. InProceedings of the International Conference on Music Information Retrieval. 239--240.
Li, T. and Ogihara, M.2004. Content-based music similarity search and emotion detection. InProceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing. 17--21.
Lin, Y.-P., Wang, C.-H., Wu, T.-L., Jeng, S.-K., and Chen, J.-H.2008. Support vector machine for EEG signal classification during listening to emotional music. InProceedings of the IEEE International Workshop on Multimedia Signal Processing. 127--130.
Yu-Ching Lin , Yi-Hsuan Yang , Homer H. Chen , I-Bin Liao , Yeh-Chin Ho, Exploiting genre for music emotion classification, Proceedings of the 2009 IEEE international conference on Multimedia and Expo, p.618-621, June 28-July 03, 2009, New York, NY, USA
Lin, Y.-P., Jung, T.-P., and Chen, J.-H.2009. EEG dynamics during music appreciation. InProceedngs of the IEEE International Conference on Engineering in Medicine and Biology Society.
Yuan-Pin Lin , Chi-Hong Wang , Tien-Lin Wu , Shyh-Kang Jeng , Jyh-Horng Chen, EEG-based emotion recognition in music listening: A comparison of schemes for multiclass support vector machine, Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, p.489-492, April 19-24, 2009[doi>10.1109/ICASSP.2009.4959627]
Liu, D., Lu, L., and Zhang, H.-J.2003. Automatic music mood detection from acoustic music data. InProceedings of the International Conference on Music Information Retrieval. 81--87.
Liu, C. C., Yang, Y.-H., Wu, P.-H., and Chen, H. H.2006. Detecting and classifying emotion in popular music. InProceedings of the Joint International Conference on Information Sciences. 996--999.
Steven R. Livingstone , Andrew R. Brown, Dynamic response: real-time adaptation for music emotion, Proceedings of the second Australasian conference on Interactive entertainment, p.105-111, November 23-25, 2005, Sydney, Australia
Lennart Ljung, System identification (2nd ed.): theory for the user, Prentice Hall PTR, Upper Saddle River, NJ, 1999
Lie Lu , D. Liu , Hong-Jiang Zhang, Automatic mood detection and tracking of music audio signals, IEEE Transactions on Audio, Speech, and Language Processing, v.14 n.1, p.5-18, December 2006[doi>10.1109/TSA.2005.860344]
Lu, Q., Chen, X., Yang, D., and Wang, J.2010. Boosting for multi-modal music emotion classification. InProceedings of the International Conference on Music Information Retrieval.
MacDorman, K. F., Ough, S., and Ho, C.-C.2007. Automatic emotion prediction of song excerpts: Index construction, algorithm design, and empirical comparison.J. New Music Res. 36, 4, 281--299.
Namunu C. Maddage , Changsheng Xu , Mohan S. Kankanhalli , Xi Shao, Content-based music structure analysis with applications to music semantics understanding, Proceedings of the 12th annual ACM international conference on Multimedia, October 10-16, 2004, New York, NY, USA[doi>10.1145/1027527.1027549]
Mandel, M. I. and Ellis, D. P. W.2007. A web-based game for collecting music metadata. InProceedings of the International Conference on Music Information Retrieval.
McKay, C., McEnnis, D., and Fujinaga, I.2006. A large publicly accessible prototype audio database for music research. InProceedings of the International Conference on Music Information Retrieval. 160--163.
Meyers, O. C.2007. A mood-based music classification and exploration system. M.S. thesis, Massachusetts Institute of Technology.
Montgomery, D. C., Runger, G. C., and Hubele, N. F.1998.Engineering Statistics. Wiley, New York, NY.
Brandon G. Morton , Jacquelin A. Speck , Erik M. Schmidt , Youngmoo. E. Kim, Improving music emotion labeling using human computation, Proceedings of the ACM SIGKDD Workshop on Human Computation, July 25-25, 2010, Washington DC[doi>10.1145/1837885.1837899]
Nielsen, F. V.1986. Musical ‘tension’ and related concepts. InSemiotic Web, 491--513.
T. L. Nwe , H. Li, Exploring Vibrato-Motivated Acoustic Features for Singer Identification, IEEE Transactions on Audio, Speech, and Language Processing, v.15 n.2, p.519-530, February 2007[doi>10.1109/TASL.2006.876756]
Tin Lay Nwe , Haizhou Li, Singing voice detection using perceptually-motivated features, Proceedings of the 15th international conference on Multimedia, September 25-29, 2007, Augsburg, Germany[doi>10.1145/1291233.1291299]
Osgood, C. E., Suci, G. J., and Tannenbaum, P. H.1957.The Measurement of Meaning. University of Illinois Press, Urbana, IL.
Ovadia, S.2004. Ratings and rankings: Reconsidering the structure of values and their measurement.Int. J. Social Res. Method. 7, 5, 403--414.
Pampalk, E.2004. A Matlab toolbox to compute music similarity from audio. InProceedings of the International Conference on Music Information Retrieval. http://www.ofai.at/~elias.pampalk/ma/.
Peeters, G.2008. A generic training and classification system for MIREX08 classification tasks: Audio music mood, audio genre, audio artist and audio tag. InProceedings of the International Conference on Music Information Retrieval.
Rosalind W. Picard , Elias Vyzas , Jennifer Healey, Toward Machine Emotional Intelligence: Analysis of Affective Physiological State, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.23 n.10, p.1175-1191, October 2001[doi>10.1109/34.954607]
Platt, J. C.1999.Probabilities for Support Vector Machines. MIT Press, Cambridge, MA.
Plutchik, R.1980.Emotion: A Psychoevolutionary Synthesis. Harper & Row, New York, NY.
Carl Edward Rasmussen , Christopher K. I. Williams, Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning), The MIT Press, 2005
Sasank Reddy , Jeff Mascia, Lifetrak: music in tune with your life, Proceedings of the 1st ACM international workshop on Human-centered multimedia, October 27-27, 2006, Santa Barbara, California, USA[doi>10.1145/1178745.1178754]
Remington, N. A., Fabrigar, L. R., and Visser, P. S.2000. Reexamining the circumplex model of affect.J. Personality Social Psychol. 79, 286--300.
Repp, B. H.1998. A microcosm of musical expression. i. quantitative analysis of pianists’ timing in the initial measures of chopin’s etude in e major.J. Acoustic. Soc. Amer. 104, 1085--1100.
Rigg, M. G.1964. The mood effects of music: A comparison of data from four investigators.J. Psychol. 58, 427--438.
Ross, R. T.1938. A statistics for circular scales.J. Edu. Psychol. 29, 384--389.
Russell, J. A.1980. A circumplex model of affect.J. Personal. Social Psychol. 39, 6, 1161--1178.
Russell, J. A.2003. Core affect and the psychological construction of emotion.Psychol. Review 110, 1, 145--172.
Russell, J. A., Weiss, A., and G. A, M.1989. Affect grid: A single-item scale of pleasure and arousal.J. Personal. Social Psychol. 57, 3, 493--502.
Scaringella, N., Zoia, G., and Mlynek, D.2006. Automatic genre classification of music content: A survey.IEEE Signal Process. Mag. 23, 2, 133--141.
Schmidt, E. M. and Kim, Y. E.2009. Projection of acoustic features to continuous valence-arousal mood. InProceedings of the International Conference on Music Information Retrieval.
Erik M. Schmidt , Douglas Turnbull , Youngmoo E. Kim, Feature selection for content-based, time-varying musical emotion regression, Proceedings of the international conference on Multimedia information retrieval, March 29-31, 2010, Philadelphia, Pennsylvania, USA[doi>10.1145/1743384.1743431]
Bernhard Schölkopf , Alex J. Smola , Robert C. Williamson , Peter L. Bartlett, New Support Vector Algorithms, Neural Computation, v.12 n.5, p.1207-1245, May 2000[doi>10.1162/089976600300015565]
Schubert, E.1999. Measurement and time series analysis of emotion in music. Ph.D. dissertion, School of Music Education, University of New South Wales, Sydney, Australia.
Schubert, E.2001. Correlation analysis of continuous response to music: Correcting for the effects of serial correlation.Musicae Scientiae, 213--236.
Schubert, E.2003. Update of the Hevner adjective checklist.Perceptual Motor Skills 96, 1117--1122.
Björn Schuller , Florian Eyben , Gerhard Rigoll, Tango or Waltz?: putting ballroom dance style into tempo detection, EURASIP Journal on Audio, Speech, and Music Processing, 2008, p.1-12, January 2008[doi>10.1155/2008/846135]
Schuller, B., Steidl, S., and Batliner, A.2009. The INTERSPEECH 2009 Emotion Challenge. InProceedings of the INTERSPEECH Conference.
Björn Schuller , Johannes Dorfner , Gerhard Rigoll, Determination of nonprototypical valence and arousal in popular music: features and performances, EURASIP Journal on Audio, Speech, and Music Processing, 2010, p.1-9, January 2010[doi>10.1155/2010/735854]
Schuller, B., Hage, C., Schuller, D., and Rigoll, G.2010. Mister D. J., cheer me up!: Musical and textual features for automatic mood classification.J. New Music Res. 39, 1, 13--34.
Fabrizio Sebastiani, Machine learning in automated text categorization, ACM Computing Surveys (CSUR), v.34 n.1, p.1-47, March 2002[doi>10.1145/505282.505283]
Sen, A. and Srivastava, M.1990.Regression Analysis: Theory, Methods, and Applications. Springer, New York, NY.
Bo Shao , Tao Li , Mitsunori Ogihara, Quantify music artist similarity based on style and mood, Proceedings of the 10th ACM workshop on Web information and data management, October 30-30, 2008, Napa Valley, California, USA[doi>10.1145/1458502.1458522]
Jialie Shen , Bin Cui , John Shepherd , Kian-Lee Tan, Towards efficient automated singer identification in large music databases, Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, August 06-11, 2006, Seattle, Washington, USA[doi>10.1145/1148170.1148184]
Skowronek, J., McKinney, M. F., and van de Par, S.2006. Ground truth for automatic music mood classification. InProceedings of the International Conference on Music Information Retrieval. 395--396.
Skowronek, J., McKinney, M. F., and van de Par, S.2007. A demonstrator for automatic music mood estimation. InProceedings of the International Conference on Music Information Retrieval.
Sloboda, J. A. and Juslin, P. N.2001. Psychological perspectives on music and emotion. InMusic and Emotion: Theory and Research, P. N. Juslin and J. A. Sloboda Eds., Oxford University Press, Oxford, UK.
Solomatine, D. and Shrestha, D.2004. AdaBoost.RT: A boosting algorithm for regression problems. InProceedings of the IEEE International Joint Conference Neural Networks. 1163--1168.
Thayer, R. E.1989.The Biopsychology of Mood and Arousal. Oxford University Press, Oxford, UK.
Toiviainen, P. and Krumhansl, C. L.2003. Measuring and modeling real-time responses to music: The dynamics of tonality induction.Perception 32, 6, 741--766.
Tolonen, T. and Karjalainen, M.2000. A computationally efficient multipitch analysis model.IEEE Trans. Speech Audio Process. 8, 6, 708--716.
Tolos, M., Tato, R., and Kemp, T.2005. Mood-based navigation through large collections of musical data. InProceedings of the IEEE Consumer Communications & Network Conference.71--75.
Trohidis, K., Tsoumakas, G., Kalliris, G., and Vlahavas, I.2008. Multi-label classification of music into emotions. InProceedings of the International Conference on Music Information Retrieval. 325--330.
Wei-Ho Tsai , Hsin-Min Wang, Automatic singer recognition of popular music recordings via estimation and modeling of solo vocal signals, IEEE Transactions on Audio, Speech, and Language Processing, v.14 n.1, p.330-341, December 2006[doi>10.1109/TSA.2005.854091]
Turnbull, D., Liu, R., Barrington, L., and Lanckriet, G.2007. A game-based approach for collecting semantic annotations of music. InProceedings of the International Conference on Music Information Retrieval.
D. Turnbull , L. Barrington , D. Torres , G. Lanckriet, Semantic Annotation and Retrieval of Music and Sound Effects, IEEE Transactions on Audio, Speech, and Language Processing, v.16 n.2, p.467-476, February 2008[doi>10.1109/TASL.2007.913750]
Tzanetakis, G.2007. MARSYAS submissions to MIREX 2007. InProceedings of the International Conference on Music Information Retrieval.
Tzanetakis, G. and Cook, P.2002. Musical genre classification of audio signals.IEEE Trans. Speech Audio Process. 10, 5, 293--302. http://marsyas.sness.net/.
van Zaanen, M. and Kanters, P.2010. Automatic mood classification using tf*idf based on lyrics. InProceedings of the International Conference on Music Information Retrieval.
Vercoe, G. S.2006. Moodtrack: practical methods for assembling emotion-driven music. M.S. thesis, MIT, Cambridge, MA.
Ververidis, D. and Kotropoulos, C.2006. Emotional speech recognition: Resources, features, and methods.Speech Comm. 48, 9, 1162--1181.
Hee Lin Wang , Loong-Fah Cheong, Affective understanding in film, IEEE Transactions on Circuits and Systems for Video Technology, v.16 n.6, p.689-704, September 2006[doi>10.1109/TCSVT.2006.873781]
Wang, M.-Y., Zhang, N.-Y., and Zhu, H.-C.2004. User-adaptive music emotion recognition. InProceedings of the IEEE International Conference on Signal Processing. 1352--1355.
Whissell, C. M., Fournier, M., Pelland, R., Weir, D., and Makarec, K.21986. A dictionary of affect in language: IV. reliability, validity, and applications.Perceptual Motor Skills 62, 875--888.
Alicja A. Wieczorkowska, Towards extracting emotions from music, Proceedings of the Second international conference on Intelligent Media Technology for Communicative Intelligence, p.228-238, September 13-14, 2004, Warsaw, Poland[doi>10.1007/11558637_23]
Wieczorkowska, A., Synak, P., and Raś, Z. W.2006. Multi-label classification of emotions in music. InProceedings of the International Conference on Intelligent Information Processing and Web Mining. 307--315.
Wu, T.-L. and Jeng, S.-K.2006. Automatic emotion classification of musical segments. InProceedings of the International Conference on Music Perception and Cognition.
Wu, T.-L. and Jeng, S.-K.2007. Regrouping of expressive terms for musical qualia. InProceedings of the International Workshop on Computer Music Audio Technology.
Tien-Lin Wu , Shyh-Kang Jeng, Probabilistic estimation of a novel music emotion model, Proceedings of the 14th international conference on Advances in multimedia modeling, January 09-11, 2008, Kyoto, Japan
Tien-Lin Wu , Hsuan-Kai Wang , Chien-Chang Ho , Yuan-Pin Lin , Ting-Ting Hu , Ming-Fang Weng , Li-Wei Chan , Chang-Hua Yang , Yi-Hsuan Yang , Yi-Ping Hung , Yung-Yu Chuang , Hsin-Hsi Chen , Homer H. Chen , Jyh-Horng Chen , Shyh-Kang Jeng, Interactive content presentation based on expressed emotion and physiological feedback, Proceedings of the 16th ACM international conference on Multimedia, October 26-31, 2008, Vancouver, British Columbia, Canada[doi>10.1145/1459359.1459554]
Xiao, Z., Dellandrea, E., Dou, W., and Chen, L.2008. What is the best segment duration for music mood analysis. InProceedings of the IEEE International Workshop on Content-Based Multimedia Indexing. 17--24.
Yang, D. and Lee, W.-S.2004. Disambiguating music emotion using software agents. InProceedings of the International Conference onMusic Information Retrieval.
Yi-Hsuan Yang , H. H. Chen, Prediction of the Distribution of Perceived Music Emotions Using Discrete Samples, IEEE Transactions on Audio, Speech, and Language Processing, v.19 n.7, p.2184-2196, September 2011[doi>10.1109/TASL.2011.2118752]
Yi-Hsuan Yang , H. H. Chen, Ranking-Based Emotion Recognition for Music Organization and Retrieval, IEEE Transactions on Audio, Speech, and Language Processing, v.19 n.4, p.762-774, May 2011[doi>10.1109/TASL.2010.2064164]
Yi-Hsuan Yang , Homer H. Chen, Music Emotion Recognition, CRC Press, Inc., Boca Raton, FL, 2011
Yi-Hsuan Yang , Chia-Chu Liu , Homer H. Chen, Music emotion classification: a fuzzy approach, Proceedings of the 14th annual ACM international conference on Multimedia, October 23-27, 2006, Santa Barbara, CA, USA[doi>10.1145/1180639.1180665]
Yi-Hsuan Yang , Ya-Fan Su , Yu-Ching Lin , Homer H. Chen, Music emotion recognition: the role of individuality, Proceedings of the international workshop on Human-centered multimedia, September 28-28, 2007, Augsburg, Bavaria, Germany[doi>10.1145/1290128.1290132]
Yi-Hsuan Yang , Yu-Ching Lin , Homer Chen, Personalized music emotion recognition, Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, July 19-23, 2009, Boston, MA, USA[doi>10.1145/1571941.1572109]
Yi-Hsuan Yang , Yu-Ching Lin , Ya-Fan Su , H. H. Chen, A Regression Approach to Music Emotion Recognition, IEEE Transactions on Audio, Speech, and Language Processing, v.16 n.2, p.448-457, February 2008[doi>10.1109/TASL.2007.911513]
Yi Hsuan Yang , Yu Ching Lin , Heng Tze Cheng , Homer H. Chen, Mr. Emo: music retrieval in the emotion plane, Proceedings of the 16th ACM international conference on Multimedia, October 26-31, 2008, Vancouver, British Columbia, Canada[doi>10.1145/1459359.1459550]
Yi-Hsuan Yang , Yu-Ching Lin , Heng-Tze Cheng , I-Bin Liao , Yeh-Chin Ho , Homer H. Chen, Toward Multi-modal Music Emotion Classification, Proceedings of the 9th Pacific Rim Conference on Multimedia: Advances in Multimedia Information Processing, December 09-13, 2008, Tainan, Taiwan[doi>10.1007/978-3-540-89796-5_8]
Chan-Chang Yeh , Shian-Shyong Tseng , Pei-Chin Tsai , Jui-Feng Weng, Building a personalized music emotion prediction system, Proceedings of the 7th Pacific Rim conference on Advances in Multimedia Information Processing, p.730-739, November 02-04, 2006, Hangzhou, China[doi>10.1007/11922162_84]
Min-Ling Zhang , Zhi-Hua Zhou, ML-KNN: A lazy learning approach to multi-label learning, Pattern Recognition, v.40 n.7, p.2038-2048, July, 2007[doi>10.1016/j.patcog.2006.12.019]
Shiliang Zhang , Qingming Huang , Qi Tian , Shuqiang Jiang , Wen Gao, i.MTV: an integrated system for mtv affective analysis, Proceedings of the 16th ACM international conference on Multimedia, October 26-31, 2008, Vancouver, British Columbia, Canada[doi>10.1145/1459359.1459541]
Zhang, S., Tian, Q., Jiang, S., Huang, Q., and Gao, W.2008. Affective MTV analysis based on arousal and valence features. InProceedings of the IEEE International Conference on Multimedia and Expo.1369--1372.
Shiliang Zhang , Qi Tian , Qingming Huang , Wen Gao , Shipeng Li, Utilizing affective analysis for efficient movie browsing, Proceedings of the 16th IEEE international conference on Image processing, November 07-10, 2009, Cairo, Egypt
