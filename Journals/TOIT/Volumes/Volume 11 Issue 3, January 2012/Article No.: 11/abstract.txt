Social trust and recommendation services are the most popular social rating systems today for service providers to learn about the social opinion or popularity of a product, item, or service, such as a book on Amazon, a seller on eBay, a story on Digg or a movie on Netflix. Such social rating systems are very convenient and offer alternative learning environments for decision makers, but they open the door for attackers to manipulate the social rating systems by selfishly promoting or maliciously demoting certain items. Although a fair amount of effort has been made to understand various risks and possible defense mechanisms to counter such attacks, most of the existing work to date has been devoted to studying specific types of attacks and their countermeasures. In this article, we argue that vulnerabilities in social rating systems and their countermeasures should be examined and analyzed in a systematic manner. We first give an overview of the common vulnerabilities and attacks observed in some popular social rating services. Next, we describe three types of attack strategies in two types of social rating systems, including a comprehensive theoretical analysis of their attack effectiveness and attack costs. Three context-aware countermeasures are then presented: (i) hiding user-item relationships, (ii) using confidence weight to distinguish popular and unpopular items, and (iii) incorporating time windows in trust establishment. We also provide an in-depth discussion on how these countermeasures can be used effectively to improve the robustness and trustworthiness of the social rating services.