Streaming applications, which are abundant in many disciplines such as multimedia, networking, and signal processing, require efficient processing of a seemingly infinite sequence of input data. In the context of streaming software synthesis from data flow graphs, we study the inherent trade-off between memory requirement and compilation runtime, under a given task firing schedule. We utilize postscheduling analysis granularity to control the amount of details in characterization of buffer's spatio-temporal footprints. Subsequently, we transform the buffer allocation problem to two-dimensional packing of polygons, where complexity of the packing problem (e.g., polygon shapes) is determined by the analysis granularity. We develop an evolutionary packing optimization algorithm which readily yields buffer allocations. Experimental results highlight the trade-off between complexity of the analysis and the total buffer size of generated implementations. In addition, they show dramatic improvements in total buffer size, if one is willing to pay the additional cost in optimization runtime.