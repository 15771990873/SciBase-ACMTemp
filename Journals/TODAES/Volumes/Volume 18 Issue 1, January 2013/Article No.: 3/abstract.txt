Voltage scaling has been a prevalent method of saving energy for energy-constrained applications. However, current technology trends which shrink transistors sizes exacerbate process variation effects in voltage-scaled systems. Large variations in transistor parameters result in high variation in performance and power across the chip. These effects, if ignored at the design, stage, will result in unpredictable behavior when deployed in the field. In this article, we leverage the benefits of voltage scaling methodology for obtaining energy efficiency and compensate for the loss in throughput by exploiting parallelism present in the various DSP designs. We show that such a hybrid method consumes 8&percnt;--77&percnt; less power, compared to simple dynamic voltage scaling over different throughputs. We study this system architecture in two different workload environments: static and dynamic. We show that to achieve the highest level of energy efficiency, the number of cores and the operating voltages vary widely between a BASE design versus a process variation-aware (PVA) design. We further demonstrate that the PVA design enjoys an average of 26.9&percnt; and 51.1&percnt; reduction in energy consumption for the static and dynamic designs, respectively. Since different cores will have a wide range of speeds at operating voltages close to near/sub-thresholds due to process variation, we gather characteristic behavior of each core. With knowledge of the core speeds, we can further increase the energy efficiency. Furthermore, in this article, we show that of this methodology will be 49.3&percnt; more energy efficient, compared to that building the system with no knowledge about the characteristics of each core.