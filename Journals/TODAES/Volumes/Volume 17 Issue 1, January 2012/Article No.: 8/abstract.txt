With VLSI circuit feature size scaling down, it is becoming more difficult and expensive to achieve a desired level of yield. Error-tolerance employs defective chips that occasionally produce erroneous yet acceptable results in targeted applications, and has been proposed as one way to increase effective yield. These chips are characterized by criteria set by specific applications. Error rate, an upper-bound on how frequent errors occur at an output, is one such criterion. In this article we focus on the following problem: given a combinational logic circuit that is defective, and hence occasionally produces an erroneous output, how can we determine the error rate of each output line by using ones counting? The results of this work can also be used for runtime error estimation in aging systems and in environments where soft-errors are produced.