An evidence-based account of trust is essential for an appropriate treatment of application-level interactions among autonomous and adaptive parties. Key examples include social networks and service-oriented computing. Existing approaches either ignore evidence or only partially address the twin challenges of mapping evidence to trustworthiness and combining trust reports from imperfectly trusted sources. This article develops a mathematically well-formulated approach that naturally supports discounting and combining evidence-based trust reports.This article understands an agent Alice's trust in an agent Bob in terms of Alice's certainty in her belief that Bob is trustworthy. Unlike previous approaches, this article formulates certainty in terms of evidence based on a statistical measure defined over a probability distribution of the probability of positive outcomes. This definition supports important mathematical properties ensuring correct results despite conflicting evidence: (1) for a fixed amount of evidence, certainty increases as conflict in the evidence decreases and (2) for a fixed level of conflict, certainty increases as the amount of evidence increases. Moreover, despite a subtle definition of certainty, this work (3) establishes a bijection between evidence and trust spaces, enabling robust combination of trust reports and (4) provides an efficient algorithm for computing this bijection.