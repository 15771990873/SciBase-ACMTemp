Christopher Amato, Jilles Steeve Dibangoye, and Shlomo Zilberstein. 2009. Incremental policy generation for finite-horizon DEC-POMDPs. In Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS'09). 2--9.
Christopher Amato , Shlomo Zilberstein, Achieving goals in decentralized POMDPs, Proceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems, May 10-15, 2009, Budapest, Hungary
Bikramjit Banerjee. 2013. Pruning for Monte Carlo distributed reinforcement learning in decentralized POMDPs. In Proceedings of the 27th AAAI Conference on Artificial Intelligence. 88--94.
Bikramjit Banerjee, Jeremy Lyle, Landon Kraemer, and Rajesh Yellamraju. 2012. Sample bounded distributed reinforcement learning for decentralized POMDPs. In Proceedings of the 26th AAAI Conference on Artificial Intelligence. 1256--1262.
Daniel S. Bernstein , Robert Givan , Neil Immerman , Shlomo Zilberstein, The Complexity of Decentralized Control of Markov Decision Processes, Mathematics of Operations Research, v.27 n.4, p.819-840, November 2002[doi>10.1287/moor.27.4.819.297]
Lucian Busoniu. 2010. MARL Toolbox Ver. 1.3. Retrieved November 3, 2014, from http://busoniu.net/repository.php.
Lonnie Chrisman, Reinforcement learning with perceptual aliasing: the perceptual distinctions approach, Proceedings of the tenth national conference on Artificial intelligence, p.183-188, July 12-16, 1992, San Jose, California
Caroline Claus , Craig Boutilier, The dynamics of reinforcement learning in cooperative multiagent systems, Proceedings of the fifteenth national/tenth conference on Artificial intelligence/Innovative applications of artificial intelligence, p.746-752, July 1998, Madison, Wisconsin, USA
Leslie Pack Kaelbling , Michael L. Littman , Anthony R. Cassandra, Planning and acting in partially observable stochastic domains, Artificial Intelligence, v.101 n.1-2, p.99-134, May, 1998[doi>10.1016/S0004-3702(98)00023-X]
Jelle R. Kok, Pieter Jan't Hoen, Bram Bakker, and Nikos A. Vlassis. 2005. Utile coordination: Learning interdependencies among cooperative agents. In Proceedings of the IEEE Symposium on Computational Intelligence and Games (CIG'05). 29--36.
Andrew Kachites McCallum. 1995. Reinforcement Learning with Selective Perception and Hidden State. Ph.D. Dissertation. Department of Computer Science, University of Rochester, Rochester, NY.
Francisco S. Melo , Manuela Veloso, Decentralized MDPs with sparse interactions, Artificial Intelligence, v.175 n.11, p.1757-1789, July, 2011[doi>10.1016/j.artint.2011.05.001]
Nicolas Meuleau , Leonid Peshkin , Kee-Eung Kim , Leslie Pack Kaelbling, Learning finite-state controllers for partially observable environments, Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence, p.427-436, July 30-August 01, 1999, Stockholm, Sweden
R. Nair , M. Tambe , M. Yokoo , D. Pynadath , S. Marsella, Taming decentralized POMDPs: towards efficient policy computation for multiagent settings, Proceedings of the 18th international joint conference on Artificial intelligence, p.705-711, August 09-15, 2003, Acapulco, Mexico
Sven Seuken and Shlomo Zilberstein. 2007. Improved memory-bounded dynamic programming for decentralized POMDPs. In Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence (UAI'07). 344--351.
Guy Shani , Ronen I. Brafman , Solomon E. Shimony, Model-based online learning of POMDPs, Proceedings of the 16th European conference on Machine Learning, October 03-07, 2005, Porto, Portugal[doi>10.1007/11564096_35]
Edward J. Sondik. 1971. The Optimal Control of Partially Observable Markov Decision Processes. Ph.D. Dissertation. Stanford University, Stanford, CA.
Matthijs T. J. Spaan. 2013. Dec-POMDP Problem Domains. Retrieved November 3, 2014, from http://masplan.org/problem_domains.
Matthijs T. J. Spaan , Frans A. Oliehoek , Christopher Amato, Scaling up optimal heuristic search in Dec-POMDPs via incremental expansion, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, p.2027-2032, July 16-22, 2011, Barcelona, Catalonia, Spain[doi>10.5591/978-1-57735-516-8/IJCAI11-338]
Richard S. Sutton , Andrew G. Barto, Introduction to Reinforcement Learning, MIT Press, Cambridge, MA, 1998
Pradeep Varakantham, Jun Young Kwak, Matthew E. Taylor, Janusz Marecki, Paul Scerri, and Milind Tambe. 2009. Exploiting coordination locales in distributed POMDPs via social model shaping. In Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS'09). http://dblp.uni-trier.de/db/conf/aips/icaps2009.html#VarakanthamKTMST09.
Nikos Vlassis, A Concise Introduction to Multiagent Systems and Distributed Artificial Intelligence, Morgan and Claypool Publishers, 2007
Christopher J. C. H. Watkins , Peter Dayan,Technical Note:\cal Q-Learning, Machine Learning, v.8 n.3-4, p.279-292, May 1992[doi>10.1007/BF00992698]
Feng Wu, Shlomo Zilberstein, and Xiaoping Chen. 2010. Rollout sampling policy iteration for decentralized POMDPs. In Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence (UAI'10). 666--673.
H. Peyton Young. 2004. Strategic Learning and Its Limits. Oxford University Press.
Chongjie Zhang and Victor Lesser. 2011. Coordinated multi-agent reinforcement learning in networked distributed POMDPs. In Proceedings of the 25th AAI Conference on Artificial Intelligence (AAAI'11). 764--770.
