Abernethy, J., Hazan, E., and Rakhlin, A. 2008. Competing in the dark: An efficient algorithm for bandit linear optimization. In Proceedings of the Annual Conference on Learning Theory (COLT). 263--274.
Daniel Adelman , Adam J. Mersereau, Relaxations of Weakly Coupled Stochastic Dynamic Programs, Operations Research, v.56 n.3, p.712-727, May 2008[doi>10.1287/opre.1070.0445]
Ahmad, S. H. A., Liu, M., Javidi, T., Zhao, Q., and Krishnamachari, B. 2008. Optimality of myopic sensing in multi-channel opportunistic access. CoRR~abs/0811.0637.
Ansell, P. S., Glazebrook, K. D., Niño-Mora, J. E., and OìKeeffe, M. 2003. Whittle's index policy for a multi-class queueing system with convex holding costs. Math. Meth. Oper. Res. 57, 21--39.
Arrow, K. J., Blackwell, D., and Girshick, M. A. 1949. Bayes and minmax solutions of sequential decision problems. Econometrica 17, 213--244.
Asawa, M., and Teneketzis, D. 1996. Multi-armed bandits with switching penalties. IEEE Trans. Auto. Control 41, 3, 328--348.
Audibert, J.-Y., and Bubeck, S. 2009. Minimax policies for adversarial and stochastic bandits. In Proceedings of the Annual Conference on Learning Theorys (COLT).
Peter Auer, Using confidence bounds for exploitation-exploration trade-offs, The Journal of Machine Learning Research, 3, 3/1/2003
Peter Auer , Nicolò Cesa-Bianchi , Paul Fischer, Finite-time Analysis of the Multiarmed Bandit Problem, Machine Learning, v.47 n.2-3, p.235-256, May-June 2002[doi>10.1023/A:1013689704352]
Peter Auer , Nicolò Cesa-Bianchi , Yoav Freund , Robert E. Schapire, The Nonstochastic Multiarmed Bandit Problem, SIAM Journal on Computing, v.32 n.1, p.48-77, 2003[doi>10.1137/S0097539701398375]
Banks, J. S., and Sundaram, R. K. 1994. Switching costs and the Gittins index. Econometrica 62, 3, 687--694.
Amotz Bar-Noy , Randeep Bhatia , Joseph (Seffi) Naor , Baruch Schieber, Minimizing service and operation costs of periodic scheduling, Proceedings of the ninth annual ACM-SIAM symposium on Discrete algorithms, p.11-20, January 25-27, 1998, San Francisco, California, USA
Dimitri P. Bertsekas, Dynamic Programming and Optimal Control, Athena Scientific, 2001
Bertsimas, D., Gamarnik, D., and Tsitsiklis, J. 2002. Performance of multiclass Markovian queueing networks via piecewise linear Lyapunov functions. Ann. of Appl. Prob. 11, 4, 1384--1428.
Dimitris Bertsimas , José Niño-Mora, Conservation laws, extended polymatroids and multiarmed bandit problems; a polyhedral approach to indexable systems, Mathematics of Operations Research, v.21 n.2, p.257-306, May 1996[doi>10.1287/moor.21.2.257]
Dimitris Bertsimas , José Niño-Mora, Restless Bandits, Linear Programming Relaxations, and a Primal-Dual Index Heuristic, Operations Research, v.48 n.1, p.80-90, January 2000[doi>10.1287/opre.48.1.80.12444]
Brezzi, M., and Lai, T.-L. 2002. Optimal learning and experimentation in bandit problems. J. Econ. Dynam. Cont. 27, 1, 87--108.
Nicolò Cesa-Bianchi , Yoav Freund , David Haussler , David P. Helmbold , Robert E. Schapire , Manfred K. Warmuth, How to use expert advice, Journal of the ACM (JACM), v.44 n.3, p.427-485, May 1997[doi>10.1145/258128.258179]
Daniela Pucci De Farias , Nimrod Megiddo, Combining expert advice in reactive environments, Journal of the ACM (JACM), v.53 n.5, p.762-799, September 2006[doi>10.1145/1183907.1183911]
Faigle, U., Kern, W., and Still, G. 2002. Algorithmic Principles of Mathematical Programming. Kluwer, Dordrecht.
Abraham D. Flaxman , Adam Tauman Kalai , H. Brendan McMahan, Online convex optimization in the bandit setting: gradient descent without a gradient, Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms, January 23-25, 2005, Vancouver, British Columbia
Gittins, J. C., and Jones, D. M. 1972. A dynamic allocation index for the sequential design of experiments. Progress in Statistics (European Meeting of Statisticians).
Glazebrook, K. D., and Mitchell, H. M. 2002. An index policy for a stochastic scheduling model with improving/deteriorating jobs. Naval Res. Log. 49, 706--721.
Glazebrook, K. D., Mitchell, H. M., and Ansell, P. S. 2005. Index policies for the maintenance of a collection of machines by a set of repairmen. Europ. J. Oper. Res. 165, 1, 267--284.
Glazebrook, K. D., Ruiz-Hernandez, D., and Kirkbride, C. 2006. Some indexable families of restless bandit problems. Adv. Appl. Prob. 38, 643--672.
Ashish Goel , Sudipto Guha , Kamesh Munagala, Asking the right questions: model-driven optimization using probes, Proceedings of the twenty-fifth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, June 26-28, 2006, Chicago, IL, USA[doi>10.1145/1142351.1142380]
Katerina Goseva-Popstojanova , Kishor S. Trivedi, Stochastic Modeling Formalisms for Dependability, Performance and Performability, Performance Evaluation: Origins and Directions, p.403-422, January 01, 2000
Sudipto Guha , Kamesh Munagala, Approximation algorithms for budgeted learning problems, Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, June 11-13, 2007, San Diego, California, USA[doi>10.1145/1250790.1250807]
Sudipto Guha , Kamesh Munagala, Approximation Algorithms for Partial-Information Based Stochastic Control with Markovian Rewards, Proceedings of the 48th Annual IEEE Symposium on Foundations of Computer Science, p.483-493, October 21-23, 2007[doi>10.1109/FOCS.2007.12]
Sudipto Guha , Kamesh Munagala, Model-driven optimization using adaptive probes, Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, p.308-317, January 07-09, 2007, New Orleans, Louisiana
Guha, S., Munagala, K., and Sarkar, S. 2008. Information acquisition and exploitation in multichannel wireless networks. CoRR abs/0804.1724.
Sudipto Guha , Kamesh Munagala , Peng Shi, Approximation algorithms for restless bandit problems, Proceedings of the twentieth Annual ACM-SIAM Symposium on Discrete Algorithms, p.28-37, January 04-06, 2009, New York, New York
Hawkins, J. T. 2003. A Lagrangian decomposition approach to weakly coupled dynamic optimization problems and its applications. Ph.D. dissertation, Operations Research Center, Massachusetts Institute of Technology.
Leslie Pack Kaelbling , Michael L. Littman , Anthony R. Cassandra, Planning and acting in partially observable stochastic domains, Artificial Intelligence, v.101 n.1-2, p.99-134, May, 1998[doi>10.1016/S0004-3702(98)00023-X]
Sham M. Kakade , Michael Kearns, Trading in markovian price models, Proceedings of the 18th annual conference on Learning Theory, June 27-30, 2005, Bertinoro, Italy[doi>10.1007/11503415_41]
Kodialam, M. S., and Lakshman, T. V. 2007. Achievable rate region for wireless systems with time varying channels. In Proceedings of INFOCOM. 53--61.
Lai, T. L., and Robbins, H. 1985. Asymptotically efficient adaptive allocation rules. Adv. Appl. Math. 6, 4--22.
Nick Littlestone , Manfred K. Warmuth, The weighted majority algorithm, Information and Computation, v.108 n.2, p.212-261, Feb. 1, 1994[doi>10.1006/inco.1994.1009]
Liu, K., and Zhao, Q. 2008. A restless bandit formulation of multi-channel opportunistic access: Indexablity and index policy. Computing Research Repository, arXiv:0810.4658.
Carsten Lund , Mihalis Yannakakis, The Approximation of Maximum Subgraph Problems, Proceedings of the 20th International Colloquium on Automata, Languages and Programming, p.40-51, July 05-09, 1993
Kamesh Munagala , Peng Shi, The stochastic machine replenishment problem, Proceedings of the 13th international conference on Integer programming and combinatorial optimization, May 26-28, 2008, Bertinoro, Italy
Ny, J. L., Dahleh, M., and Feron, E. 2008. Multi-UAV dynamic routing with partial observations using restless bandits allocation indices. In Proceedings of the American Control Conference.
Christos H. Papadimitriou , John N. Tsitsiklis, The Complexity of Optimal Queuing Network Control, Mathematics of Operations Research, v.24 n.2, p.293-305, February 1999[doi>10.1287/moor.24.2.293]
Robbins, H. 1952. Some aspects of the sequential design of experiments. Bull. AMS 55, 527--535.
Slivkins, A., and Upfal, E. 2008. Adapting to a changing environment: The Brownian restless bandits. In (COLT). 343--354.
Smallwood, R., and Sondik, E. 1971. The optimal control of partially observable Markov processes over a finite horizon. Oper. Res. 21, 1071--88.
Sondik, E. J. 1978. The optimal control at partially observable Markov processes over the infinite horizon: Discounted costs. Oper. Res. 26, 2, 282--304.
Tsitsiklis, J. N. 1994. A short proof of the Gittins index theorem. Ann. Appl. Prob. 4, 1, 194--199.
Wald, A. 1947. Sequential Analysis. Wiley, New York.
Weber, R. R., and Weiss, G. 1990. On an index policy for restless bandits. J. Appl. Prob. 27, 3, 637--648.
Weiss, G. 1988. Branching bandit processes. Probab. Engng. Inform. Sci. 2, 269--278.
Whittle, P. 1981. Arm acquiring bandits. Ann. Probab. 9, 284--292.
Whittle, P. 1988. Restless bandits: Activity allocation in a changing world. Appl. Prob. 25, A, 287--298.
Zhao, Q., Krishnamachari, B., and Liu, K. 2007. On myopic sensing for multi-channel opportunistic access. CoRR abs/0712.0035.
Zinkevich, M. 2003. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the International Conference on Machine Learning (ICML). 928--936.
