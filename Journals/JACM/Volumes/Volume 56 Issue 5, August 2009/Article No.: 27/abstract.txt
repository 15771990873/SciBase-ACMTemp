The capability of theRandom Access Machine(RAM) to execute any instruction in constant time is not realizable, due to fundamental physical constraints on the minimum size of devices and on the maximum speed of signals. This work explores how well the ideal RAM performance can be approximated, for significant classes of computations, by machines whose building blocks have constant size and are connected at a constant distance.A novel memory structure is proposed, which ispipelined(can accept a new request at each cycle) andhierarchical, exhibiting optimal latencya(x) &equals;O(x1/d) to addressx, ind-dimensional realizations.In spite of block-transfer or other memory-pipeline capabilities, a number of previous machine models do not achieve a full overlap of memory accesses. These are examples of machines withexplicit data movement. It is shown that there aredirect-flowcomputations (without branches and indirect accesses) that require time superlinear in the number of instructions, on all such machines.To circumvent the explicit-data-movement constraints, theSpeculative Prefetcher(SP) and theSpeculative Prefetcher and Evaluator(SPE) processors are developed. Both processors can execute anydirect-flowprogram in linear time. The SPE also executes in linear time a class of loop programs that includes many significant algorithms. Even quicksort, a somewhat irregular, recursive algorithm admits a linear-time SPE implementation. A relation between instructions calledaddress dependenceis introduced, which limits memory-access overlap and can lead to superlinear time, as illustrated with the classical merging algorithm.