BAHADUR, R. 1960. Some approximations to the binomial distribution function. Ann. Math. Stat. 31, 43-54.
BAHADUR, R., AND RANGA-RAO, R. 1960. On deviations of the sample mean. Ann. Math. Stat. 31, 1015-1027.
Anselm Blumer , A. Ehrenfeucht , David Haussler , Manfred K. Warmuth, Learnability and the Vapnik-Chervonenkis dimension, Journal of the ACM (JACM), v.36 n.4, p.929-965, Oct. 1989[doi>10.1145/76359.76371]
CHOW,Y.S.,AND TEICHER, H. 1988. Probability Theory. Springer-Verlag, New York.
Andrzej Ehrenfeucht , David Haussler, A general lower bound on the number of examples needed for learning, Information and Computation, v.82 n.3, p.247-261, Sep. 1989[doi>10.1016/0890-5401(89)90002-3]
Claudio Gentile , David P. Helmbold, Improved lower bounds for learning from noisy examples: an information-theoretic approach, Proceedings of the eleventh annual conference on Computational learning theory, p.104-115, July 24-26, 1998, Madison, Wisconsin, USA[doi>10.1145/279943.279965]
JOGDEO, K., AND SAMUELS, S. M. 1968. Monotone convergence of binomial probabilities and a generalization of ramanujan's equation. Ann. Math. Sta. 39, 4, 1191-1195.
Michael Kearns , Ming Li, Learning in the presence of malicious errors, SIAM Journal on Computing, v.22 n.4, p.807-837, Aug. 1993[doi>10.1137/0222052]
Michael J. Kearns , Robert E. Schapire, Efficient distribution-free learning of probabilistic concepts, Journal of Computer and System Sciences, v.48 n.3, p.464-497, June 1994[doi>10.1016/S0022-0000(05)80062-5]
Michael J. Kearns , Robert E. Schapire , Linda M. Sellie, Toward Efficient Agnostic Learning, Machine Learning, v.17 n.2-3, p.115-141, Nov./Dec. 1994[doi>10.1007/BF00993468]
Philip D. Laird, Learning from good and bad data, Kluwer Academic Publishers, Norwell, MA, 1988
LITTLEWOOD, J. 1969. On the probability in the tail of a binomial distribution. Adv. Appl. Prob. 1, 43-72.
SAUER, N. 1972. On the density of families of sets. J. Combin. Th. A 13, 145-147.
SHELAH, S. 1972. A combinatorial problem; Stability and order for models and theories in infinitary languages. Pacific J. Math. 41, 247-261.
Hans Ulrich Simon, General bounds on the number of examples needed for learning probabilistic concepts, Journal of Computer and System Sciences, v.52 n.2, p.239-254, April 1996[doi>10.1006/jcss.1996.0019]
SIMON, H. U. 1996b. A general upper bound on the number of examples sufficient to learn in the presence of classification noise. Unpublished Manuscript.
L. G. Valiant, A theory of the learnable, Communications of the ACM, v.27 n.11, p.1134-1142, Nov. 1984[doi>10.1145/1968.1972]
Vladimir Vapnik, Estimation of Dependences Based on Empirical Data: Springer Series in Statistics (Springer Series in Statistics), Springer-Verlag New York, Inc., Secaucus, NJ, 1982
