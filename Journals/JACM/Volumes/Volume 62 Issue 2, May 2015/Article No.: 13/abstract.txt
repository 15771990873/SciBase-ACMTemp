Given a set ofnd-dimensional Boolean vectors with the promise that the vectors are chosen uniformly at random with the exception of two vectors that have Pearson correlation coefficient ρ (Hamming distanced&cdot; 1−ρ&frac;2), how quickly can one find the two correlated vectors&quest; We present an algorithm which, for any constant &eps;>0, and constant ρ>0, runs in expected timeO(n5&mins;ω&frac;4&mins;ω&plus;&eps;&plus;nd) <O(n1.62&plus;nd), where ω < 2.4 is the exponent of matrix multiplication. This is the first subquadratic--time algorithm for this problem for which ρ does not appear in the exponent ofn, and improves uponO(n2&mins;O(ρ)), given by Paturi et al. [1989], the Locality Sensitive Hashing approach of Motwani [1998] and the Bucketing Codes approach of Dubiner [2008].Applications and extensions of this basic algorithm yield significantly improved algorithms for several other problems.Approximate Closest Pair.For any sufficiently small constant &eps;>0, givennd-dimensional vectors, there exists an algorithm that returns a pair of vectors whose Euclidean (or Hamming) distance differs from that of the closest pair by a factor of at most 1&plus;&eps;, and runs in timeO(n2&mins;Θ(&sqrt;&eps;)). The best previous algorithms (including Locality Sensitive Hashing) have runtimeO(n2&mins;O(&eps;)).Learning Sparse Parities with Noise.Given samples from an instance of the learning parities with noise problem where each example has lengthn, the true parity set has size at mostk«n, and the noise rate is η, there exists an algorithm that identifies the set ofkindices in timenω&plus;&eps;&frac;3 kpoly(1&frac;1&mins;2η)<n0.8kpoly(1&frac;1&mins;2 η). This is the first algorithm with no dependence on η in the exponent ofn, aside from the trivialO&big;(n &choose; k)&big; &approx;O(nk) brute-force algorithm, and for large noise rates (η > 0.4), improves upon the results of Grigorescu et al. [2011] that give a runtime ofn(1&plus;(2 η)2&plus;o(1))k&frac;2poly(1&frac;1&mins;2η).Learningk-Juntas with Noise.Given uniformly random lengthnBoolean vectors, together with a label, which is some function of justk«nof the bits, perturbed by noise rate η, return the set of relevant indices. Leveraging the reduction of Feldman et al. [2009], our result for learningk-parities implies an algorithm for this problem with runtimenω&plus;&eps;&frac;3 kpoly(1&frac;1&mins;2η) <n0.8kpoly(1&frac;1&mins;2 η), which is the first runtime for this problem of the formnckwith an absolute constantc< 1.Learningk-Juntas without Noise.Given uniformly random lengthnBoolean vectors, together with a label, which is some function ofk«nof the bits, return the set of relevant indices. Using a modification of the algorithm of Mossel et al. [2004], and employing our algorithm for learning sparse parities with noise via the reduction of Feldman et al. [2009], we obtain an algorithm for this problem with runtimenω&plus; &eps;&frac;4 kpoly(n)<n0.6kpoly(n), which improves on the previous best ofnω&plus;1&frac;ωk&approx;n0.7kpoly(n)of Mossel et al. [2004].