We consider a failure-free, asynchronous message passing network withnlinks, where the processors are arranged on a ring or a chain. The processors are identically programmed but have distinct identities, taken from &lcub;0, 1,… ,M− 1&rcub;. We investigate the communication costs of three well studied tasks: Consensus, Leader, and MaxF (finding the maximum identity). We show that in chain and ring topologies, the message complexities of all three tasks are the same. Hence, we study a finer measure of complexity: the number of transmittedbitsrequired to solve a taskT, denotedBitC(T).We prove several new lower bounds (and some simple upper bounds) that imply the following results: For the two processors case,BitC(Consensus) &equals; 2 andBitC(Leader) &equals;BitC(MaxF) &equals; 2log2M±O(1), where the gap between the lower and upper bounds is almost always 1. For a chain,BitC(Consensus) &equals; Θ(n),BitC(Leader) &equals; Θ(n&plus; logM), andBitC(MaxF) &equals; Θ(nlogM). For the ring topology, we prove the lower bound of Ω(nlogM) for Leader, and (hence) MaxF.We consider also a chain where the intermediate processors have no identities. We prove thatBitC(Leader) &equals; Θ(nlogM), which is equal tontimes the bit complexity of the problem for two processors. For the specific case when the chain length is even, we prove thatBitC(Leader) &equals; Θ(n), for both above settings. In addition, we show that for any algorithm solving MaxF, there exists an input, for whicheveryexecution has the bit complexity Ω(nlogM) (this is not the case for Leader).In our proofs, we use both methods of distributed computing and of communication complexity theory, establishing new links between the two areas.