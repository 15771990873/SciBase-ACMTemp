Nearest neighbor searching is the problem of preprocessing a set ofnpoint points ind-dimensional space so that, given any query pointq, it is possible to report the closest point toqrapidly. In approximate nearest neighbor searching, a parameter &epsiv; > 0 is given, and a multiplicative error of (1 + &epsiv;) is allowed. We assume that the dimensiondis a constant and treatnand &epsiv; as asymptotic quantities. Numerous solutions have been proposed, ranging from low-space solutions having spaceO(n) and query timeO(logn+ 1/&epsiv;d−1) to high-space solutions having space roughlyO((nlogn)/&epsiv;d) and query timeO(log (n/&epsiv;)).We show that there is a single approach to this fundamental problem, which both improves upon existing results and spans the spectrum of space-time tradeoffs. Given a tradeoff parameter γ, where 2 ≤ γ ≤ 1/&epsiv;, we show that there exists a data structure of spaceO(nγd−1log(1/&epsiv;)) that can answer queries in timeO(log(nγ) + 1/(&epsiv;γ)(d−1)/2. When γ &equals; 2, this yields a data structure of spaceO(nlog (1/&epsiv;)) that can answer queries in timeO(logn+ 1/&epsiv;(d−1)/2). When γ &equals; 1/&epsiv;, it provides a data structure of spaceO((n/&epsiv;d−1)log(1/&epsiv;)) that can answer queries in timeO(log(n/&epsiv;)).Our results are based on a data structure called a (t,&epsiv;)-AVD, which is a hierarchical quadtree-based subdivision of space into cells. Each cell stores up totrepresentative points of the set, such that for any query pointqin the cell at least one of these points is an approximate nearest neighbor ofq. We provide new algorithms for constructing AVDs and tools for analyzing their total space requirements. We also establish lower bounds on the space complexity of AVDs, and show that, up to a factor ofO(log (1/&epsiv;)), our space bounds are asymptotically tight in the two extremes, γ &equals; 2 and γ &equals; 1/&epsiv;.